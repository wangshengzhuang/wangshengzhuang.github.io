<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[cut命令]]></title>
    <url>%2F2017%2F06%2F02%2FLinux%2F%E6%AF%8F%E5%A4%A9%E4%B8%80%E4%B8%AALinux%E5%91%BD%E4%BB%A4%2Fcut%2F</url>
    <content type="text"><![CDATA[1. 命令简介cut根据指定的定界符，切分文件，并将选中的列输出到标准输出。 2. 用法cut [选项]… [文件]… 打印输入行的选中的parts 到标准输出 3. 选项 4. 示例以密码/etc/passwd为例123456[root@xqzt ~]# tail -n 5 /etc/passwdnfsnobody:x:65534:65534:Anonymous NFS User:/var/lib/nfs:/sbin/nologingnome-initial-setup:x:992:990::/run/gnome-initial-setup/:/sbin/nologintcpdump:x:72:72::/:/sbin/nologinvboxadd:x:991:1::/var/run/vboxadd:/bin/falsewangshengzhuang:x:1000:1000:wangshengzhuang:/home/wangshengzhuang:/bin/bash 示例1：-f 指定字段打印用户名123456[root@xqzt ~]# tail -n 5 /etc/passwd |cut -d ":" -f 1,6,7nfsnobodygnome-initial-setuptcpdumpvboxaddwangshengzhuang 示例2：-f 指定多个字段打印用户名、home目录、shell123456[root@xqzt ~]# tail -n 5 /etc/passwd |cut -d ":" -f 1,6,7nfsnobody:/var/lib/nfs:/sbin/nologingnome-initial-setup:/run/gnome-initial-setup/:/sbin/nologintcpdump:/:/sbin/nologinvboxadd:/var/run/vboxadd:/bin/falsewangshengzhuang:/home/wangshengzhuang:/bin/bash 示例3: -f n-m打印第n-m个字段打印用户ID和组ID123456789101112[root@xqzt ~]# tail -n 5 /etc/passwd |cut -d ":" -f 3-465534:65534992:99072:72991:11000:1000[root@xqzt ~]# tail -n 5 /etc/passwd |cut -d ":" -f 3,465534:65534992:99072:72991:11000:1000 示例4： –output-delimiter指定输出使用新的分界符123456[root@xqzt ~]# tail -n 5 /etc/passwd |cut -d ":" -f 3,4 --output-delimiter=" | "65534 | 65534992 | 99072 | 72991 | 11000 | 1000 示例5：–complement 补全选中的部分打印除了密码、用户id 和组id 之外的所有列123456[root@xqzt ~]# tail -n 5 /etc/passwd |cut -d ":" -f 2-4 --complementnfsnobody:Anonymous NFS User:/var/lib/nfs:/sbin/nologingnome-initial-setup::/run/gnome-initial-setup/:/sbin/nologintcpdump::/:/sbin/nologinvboxadd::/var/run/vboxadd:/bin/falsewangshengzhuang:wangshengzhuang:/home/wangshengzhuang:/bin/bash 参考 cut命令]]></content>
      <categories>
        <category>Linux</category>
        <category>每天一个Linux命令</category>
      </categories>
      <tags>
        <tag>每天一个Linux命令</tag>
        <tag>cut</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dig命令]]></title>
    <url>%2F2017%2F06%2F01%2FLinux%2F%E6%AF%8F%E5%A4%A9%E4%B8%80%E4%B8%AALinux%E5%91%BD%E4%BB%A4%2Fdig%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[dig - DNS lookup utility 1. 命令简介dig命令是常用的域名查询工具，可以用来测试域名系统工作是否正常。 2. 安装1yum install bind-utils 3. 选项123456789@&lt;服务器地址&gt;：指定进行域名解析的域名服务器； -b：当主机具有多个IP地址，指定使用本机的哪个IP地址向域名服务器发送域名查询请求； -f&lt;文件名称&gt;：指定dig以批处理的方式运行，指定的文件中保存着需要批处理查询的DNS任务信息； -P：指定域名服务器所使用端口号；-t&lt;类型&gt;：指定要查询的DNS数据类型； -x：执行逆向域名查询； -4：使用IPv4； -6：使用IPv6； -h：显示指令帮助信息。 4. 例子例子1. 查询域名 123456789101112131415161718[root@mysql001 ~]# dig www.baidu.com; &lt;&lt;&gt;&gt; DiG 9.9.4-RedHat-9.9.4-38.el7_3.3 &lt;&lt;&gt;&gt; www.baidu.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 43094;; flags: qr aa rd ra ad; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0;; QUESTION SECTION:;www.baidu.com. IN A;; ANSWER SECTION:www.baidu.com. 0 IN A 183.232.231.173;; Query time: 2 msec;; SERVER: 192.168.0.1#53(192.168.0.1);; WHEN: Tue Jun 27 09:09:09 CST 2017;; MSG SIZE rcvd: 47 例子2. 指定域名服务器 123456789101112131415161718192021[root@mysql001 ~]# dig @223.5.5.5 www.baidu.com; &lt;&lt;&gt;&gt; DiG 9.9.4-RedHat-9.9.4-38.el7_3.3 &lt;&lt;&gt;&gt; @223.5.5.5 www.baidu.com; (1 server found);; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 60317;; flags: qr aa rd cd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 0;; WARNING: recursion requested but not available;; QUESTION SECTION:;www.baidu.com. IN A;; ANSWER SECTION:www.baidu.com. 300 IN A 111.13.100.91www.baidu.com. 300 IN A 111.13.100.92;; Query time: 6 msec;; SERVER: 223.5.5.5#53(223.5.5.5);; WHEN: Tue Jun 27 09:09:21 CST 2017;; MSG SIZE rcvd: 63]]></content>
      <categories>
        <category>Linux</category>
        <category>每天一个Linux命令</category>
      </categories>
      <tags>
        <tag>每天一个Linux命令</tag>
        <tag>dig</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cat命令]]></title>
    <url>%2F2017%2F05%2F31%2FLinux%2F%E6%AF%8F%E5%A4%A9%E4%B8%80%E4%B8%AALinux%E5%91%BD%E4%BB%A4%2Fcat%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[摘要: cat (concatenate，连接)命令将[文件]或标准输入组合输出到标准输出，如果没有指定文件，或者文件为”-“，则从标准输入读取。 1、命令简介cat (concatenate，连接)命令将[文件]或标准输入组合输出到标准输出，如果没有指定文件，或者文件为”-“，则从标准输入读取。 2、用法1cat [选项]... [文件]... 3、选项123456789101112-A, --show-all 等于-vET-b, --number-nonblank 对非空输出行编号-e 等于-vE-E, --show-ends 在每行结束处显示"$"-n, --number 对所有行编号，包括空行-s, --squeeze-blank 压缩多行空行为一空行-t 与-vT 等价-T, --show-tabs 将跳格(TAB)字符显示为^I-u (被忽略)-v, --show-nonprinting 使用^ 和M- 引用，除了LFD和 TAB 之外--help 显示此帮助信息并退出--version 显示版本信息并退出 4、示例示例1：显示文件内容1234[root@oracledb ~]# cat test1.log 201120122013 示例2：显示文件内容及行号123456789101112131415161718192021222324252627282930[root@oracledb ~]# cat -b test1.log 1 2011 2 2012 3 2013 4 2014 5 2015[root@oracledb ~]# cat -n test1.log 1 2011 2 2012 3 2013 4 5 6 2014 7 2015[root@oracledb ~]# cat -s test1.log 20112012201320142015[root@oracledb ~]# cat -ns test1.log 1 2011 2 2012 3 2013 4 5 2014 6 2015 示例3：-T选项12345678910[root@oracledb ~]# cat -T test1.log 201120122013^I行前面为tab20142015 示例4：顺序连接两个文件log1，log2 ，并将结果输出到log31[root@oracledb ~]# cat test1.log test2.log &gt;test3.log 示例5：将标准输入的内容定向输出到文件1[root@oracledb ~]# cat &gt;test4.log 按ctrl+D结束输入or EOF（End Of File） 12345678910111213[root@oracledb ~]# cat &gt;log.txt &lt;&lt;EOF&gt; Hello&gt; World&gt; Linux&gt; PWD=$(pwd)&gt; EOF[root@localhost test]# ls -l log.txt -rw-r--r-- 1 root root 37 10-28 17:07 log.txt[root@localhost test]# cat log.txt HelloWorldLinuxPWD=/opt/soft/test 示例6：tac (反向列示)12345678[root@oracledb ~]# cat test2.log 201620172018[root@oracledb ~]# tac test2.log 201820172016]]></content>
      <categories>
        <category>Linux</category>
        <category>每天一个Linux命令</category>
      </categories>
      <tags>
        <tag>每天一个Linux命令</tag>
        <tag>touch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[touch命令]]></title>
    <url>%2F2017%2F05%2F30%2FLinux%2F%E6%AF%8F%E5%A4%A9%E4%B8%80%E4%B8%AALinux%E5%91%BD%E4%BB%A4%2Ftouch%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[摘要: touch命令将每个文件的访问时间和修改时间改为当前时间。 1、命令简介touch命令将每个文件的访问时间和修改时间改为当前时间。 2、用法1touch [选项]... 文件... 3、选项123456789-a 只更改访问时间-c, --no-create 不创建任何文件-d, --date=字符串 使用指定字符串表示时间而非当前时间-f (忽略)-h, --no-dereference 会影响符号链接本身，而非符号链接所指示的目的地(当系统支持更改符号链接的所有者时，此选项才有用)-m 只更改修改时间-r, --reference=文件 使用指定文件的时间属性而非当前时间-t STAMP 使用[[CC]YY]MMDDhhmm[.ss] 格式的时间而非当前时间--time=WORD 使用WORD 指定的时间：access、atime、use 都等于-a选项的效果，而modify、mtime 等于-m 选项的效果 4、实例实例1：在当前目录下建立一个空文件a.log1234[root@oracledb dir1]# touch a.log[root@oracledb dir1]# ll总用量 0-rw-r--r-- 1 root root 0 4月 16 21:06 a.log 实例2：更新a.log的修改时间为当前时间1234567[root@oracledb dir1]# ll总用量 0-rw-r--r-- 1 root root 0 4月 16 21:06 a.log[root@oracledb dir1]# touch a.log [root@oracledb dir1]# ll总用量 0-rw-r--r-- 1 root root 0 4月 16 21:08 a.log 实例3：更新log1.log的时间和log2.log时间戳相同123456789[root@oracledb dir1]# ll总用量 0-rw-r--r-- 1 root root 0 4月 16 21:08 a.log-rw-r--r-- 1 root root 0 4月 16 21:12 b.log[root@oracledb dir1]# touch -r a.log b.log [root@oracledb dir1]# ll总用量 0-rw-r--r-- 1 root root 0 4月 16 21:08 a.log-rw-r--r-- 1 root root 0 4月 16 21:08 b.log 实例4：设定文件的时间戳12345678[root@oracledb dir1]# ll总用量 0-rw-r--r-- 1 root root 0 4月 16 21:08 a.log[root@oracledb dir1]# touch -t 201601011200.50 log.log[root@oracledb dir1]# ll总用量 0-rw-r--r-- 1 root root 0 4月 16 21:08 a.log-rw-r--r-- 1 root root 0 1月 1 12:00 log.log]]></content>
      <categories>
        <category>Linux</category>
        <category>每天一个Linux命令</category>
      </categories>
      <tags>
        <tag>每天一个Linux命令</tag>
        <tag>touch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mv命令]]></title>
    <url>%2F2017%2F05%2F29%2FLinux%2F%E6%AF%8F%E5%A4%A9%E4%B8%80%E4%B8%AALinux%E5%91%BD%E4%BB%A4%2Fmv%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[摘要: mv（Move file）将源文件重命名为目标文件，或将源文件移动至指定目录。 1、命令简介mv（Move file）将源文件重命名为目标文件，或将源文件移动至指定目录。。 2、用法123mv [选项]... [-T] 源文件 目标文件 或：mv [选项]... 源文件... 目录 或：mv [选项]... -t 目录 源文件... 3、选项1234567891011--backup[=CONTROL] 为每个已存在的目标文件创建备份-b 类似--backup 但不接受参数-f, --force 覆盖前不询问-i, --interactive 覆盖前询问-n, –nechoo-clobber 不覆盖已存在文件 如果您指定了-i、-f、-n 中的多个，仅最后一个生效。 --strip-trailing-slashes 去掉每个源文件参数尾部的斜线-S, --suffix=SUFFIX 替换常用的备份文件后缀-t, --target-directory=DIRECTORY 将所有参数指定的源文件或目录 移动至 指定目录-T, --no-target-directory 将目标文件视作普通文件处理-u, --update 只在源文件文件比目标文件新，或目标文件不存在时才进行移动-v, --verbose 详细显示进行的步骤 4、实例实例1：文件改名1[root@oracledb dir1]# mv a.txt b.txt 实例2：-v显示详细信息12[root@oracledb dir1]# mv -v b.txt a.txt"b.txt" -&gt; "a.txt" 实例3：将单个文件移动至目录1[root@oracledb dir1]# mv -v a.txt dir2/"a.txt" -&gt; "dir2/a.txt" 实例4：将多个文件移动至目录123[root@oracledb dir1]# mv -v a.txt b.txt dir2/"a.txt" -&gt; "dir2/a.txt""b.txt" -&gt; "dir2/b.txt" 123[root@oracledb dir1]# mv -vt dir2/ a.txt b.txt "a.txt" -&gt; "dir2/a.txt""b.txt" -&gt; "dir2/b.txt" 实例5：将文件a.txt改名为b.txt，如果a.txt已经存在，则询问是否覆盖123[root@oracledb dir1]# mv -vi a.txt b.txtmv：是否覆盖"b.txt"？ y"a.txt" -&gt; "b.txt" 实例6：将文件a.txt改名为b.txt，即使b.txt存在，也是直接覆盖掉。12[root@oracledb dir1]# mv -fv a.txt b.txt"a.txt" -&gt; "b.txt" 实例7：重命名dir1为dir2（dir2不存在）12[root@oracledb dir1]# mv -v dir1 dir2"dir1" -&gt; "dir2" 实例8：将dir1移动到dir2中（dir2存在）。12[root@oracledb dir1]# mv -v dir1 dir2"dir1" -&gt; "dir2/dir1" 实例9：文件被覆盖前做简单备份，前面加参数-b1234[root@oracledb dir1]# mv -vb a.txt b.txt "a.txt" -&gt; "b.txt" (备份："b.txt~")[root@oracledb dir1]# lsb.txt b.txt~ 实例10：只在源文件比目标文件新时才移动1234567[root@oracledb dir1]# ll总用量 0-rw-r--r-- 1 root root 0 4月 16 20:48 a.txt-rw-r--r-- 1 root root 0 4月 16 20:43 b.txt[root@oracledb dir1]# mv -uv b.txt a.txt [root@oracledb dir1]# mv -uv a.txt b.txt "a.txt" -&gt; "b.txt"]]></content>
      <categories>
        <category>Linux</category>
        <category>每天一个Linux命令</category>
      </categories>
      <tags>
        <tag>每天一个Linux命令</tag>
        <tag>mv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rm命令]]></title>
    <url>%2F2017%2F05%2F28%2FLinux%2F%E6%AF%8F%E5%A4%A9%E4%B8%80%E4%B8%AALinux%E5%91%BD%E4%BB%A4%2Frm%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[摘要: rm（Remove file 删除目录或文件）删除文件，对于链接文件，只是删除整个链接文件，而原有文件保持不变。 1、命令简介rm（Remove file 删除目录或文件）删除文件，对于链接文件，只是删除整个链接文件，而原有文件保持不变。 2、用法1rm [选项]... 文件.. 3、选项1234-f, –force 强制删除。忽略不存在的文件，不提示确认-i 在删除前需要确认-r, -R, --recursive 递归删除目录及其内容-v, –verbose 详细显示进行的步骤 4、实例实例1：删除文件，显示详细信息123[root@oracledb dir1]# rm -v b.txt rm：是否删除普通空文件 "b.txt"？y已删除"b.txt" 实例2：删除前确认123[root@oracledb dir1]# rm -vi a.txt rm：是否删除普通空文件 "a.txt"？y已删除"a.txt" 实例3：强制删除12[root@oracledb dir1]# rm -fv a.txt 已删除"a.txt" 实例4：递归删除12345[root@oracledb dir1]# rm -rfv dir2/已删除"dir2/a.txt"已删除"dir2/dir3/c.txt"已删除目录："dir2/dir3"已删除目录："dir2"]]></content>
      <categories>
        <category>Linux</category>
        <category>每天一个Linux命令</category>
      </categories>
      <tags>
        <tag>每天一个Linux命令</tag>
        <tag>rm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVM基础及在线扩容]]></title>
    <url>%2F2017%2F05%2F27%2FLinux%2FLinux%E5%9F%BA%E7%A1%80%2FLVM%E5%9F%BA%E7%A1%80%E5%8F%8A%E5%9C%A8%E7%BA%BF%E6%89%A9%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[本文主要介绍了LVM的基本概念及磁盘扩容操作。 一、 前言​ 每个Linux使用者在安装linux时都会遇到这样的困境：在为系统分区时，如何精确评估和分配各个硬盘分区的容量，因为系统管理员不但要考虑到当前某个分区需要的容量，还要预见该分区以后可能需要的容量的最大值。因为如果估计不准确，当遇到某个分区不够用时管理员可能甚至要备份整个系统、清除硬盘、重新对硬盘分区，然后恢复数据到新分区。 ​ 虽然现在有很多动态调整磁盘的工具可以使用，例如Partation Magic等等，但是它并不能完全解决问题，因为某个分区可能会再次被耗尽；另外一个方面这需要重新引导系统才能实现，对于很多关键的服务器，停机是不可接受的，而且对于添加新硬盘，希望一个能跨越多个硬盘驱动器的文件系统时，分区调整程序就不能解决问题。 ​ 因此完美的解决方法应该是在零停机前提下可以自如对文件系统的大小进行调整，可以方便实现文件系统跨越不同磁盘和分区。幸运的是Linux提供的逻辑盘卷管理（LVM，Logical Volume Manager）机制就是一个完美的解决方案。 ​ LVM是逻辑盘卷管理（Logical Volume Manager）的简称，它是Linux环境下对磁盘分区进行管理的一种机制，LVM是建立在硬盘和分区之上的一个逻辑层，来提高磁盘分区管理的灵活性。通过LVM系统管理员可以轻松管理磁盘分区，如：将若干个磁盘分区连接为一个整块的卷组（volume group），形成一个存储池。管理员可以在卷组上随意创建逻辑卷组（logical volumes），并进一步在逻辑卷组上创建文件系统。管理员通过LVM可以方便的调整存储卷组的大小，并且可以对磁盘存储按照组的方式进行命名、管理和分配，例如按照使用用途进行定义：“development”和“sales”，而不是使用物理磁盘名“sda”和“sdb”。而且当系统添加了新的磁盘，通过LVM管理员就不必将磁盘的文件移动到新的磁盘上以充分利用新的存储空间，而是直接扩展文件系统跨越磁盘即可。 二、使用LVM的好处传统的文件系统是基于分区的，一个文件系统对应一个分区。这种方式比较直观，但不易改动： 1.不同的分区相对独立，无相互联系，各分区空间非常易利用不平衡，空间不能充分利用； 2.当一个文件系统／分区已满时，无法对其扩充，只能采用重新分区／建立文件系统，非常麻烦；或把分区中的数据移到另一个更大的分区中；或采用符号连接的方式使用其他分区的空间。 3.如果要把硬盘上的多个分区合并在一起使用，只能采用再分区的方式，这个过程需要数据的备份和恢复。 当采用LVM时，情况有所不同： 1.硬盘的多个分区由LVM统一为卷组管理，能方便的加入或移走分区以扩大或减小卷组的可用容量，充分利用硬盘空间； 2.文件系统建立在逻辑卷上，而逻辑卷可根据需要改动大小(在卷组容量范围内)以满足需求； 3.当系统空间不足而加入新的硬盘时，不必把用户的数据从原硬盘迁移到新硬盘，而只须把新的分区加入卷组并扩充逻辑卷即可。 三、 LVM基本术语​ 前面谈到，LVM是在磁盘分区和文件系统之间添加的一个逻辑层，来为文件系统屏蔽下层磁盘分区布局，提供一个抽象的盘卷，在盘卷上建立文件系统。首先我们讨论以下几个LVM术语： 物理存储介质（The physical media）这里指系统的存储设备：硬盘，如：/dev/hda1、/dev/sda等等，是存储系统最低层的存储单元。 物理卷（physical volume）物理卷就是指硬盘分区或从逻辑上与磁盘分区具有同样功能的设备(如RAID)，是LVM的基本存储逻辑块，但和基本的物理存储介质（如分区、磁盘等）比较，却包含有与LVM相关的管理参数。 卷组（Volume Group）LVM卷组类似于非LVM系统中的物理硬盘，其由物理卷组成。可以在卷组上创建一个或多个“LVM分区”（逻辑卷），LVM卷组由一个或多个物理卷组成。 逻辑卷（logical volume）LVM的逻辑卷类似于非LVM系统中的硬盘分区，在逻辑卷之上可以建立文件系统(比如/home或者/usr等)。 PE（physical extent）每一个物理卷被划分为称为PE(Physical Extents)的基本单元，具有唯一编号的PE是可以被LVM寻址的最小单元。PE的大小是可配置的，默认为4MB。 LE（logical extent）逻辑卷也被划分为被称为LE(Logical Extents) 的可被寻址的基本单位。在同一个卷组中，LE的大小和PE是相同的，并且一一对应。 ​ 首先可以看到，物理卷（PV）被由大小等同的基本单元PE组成。 ​ 一个卷组由一个或多个物理卷组成， ​ 从上图可以看到，PE和LE有着一一对应的关系。逻辑卷建立在卷组上。逻辑卷就相当于非LVM系统的磁盘分区，可以在其上创建文件系统。 ​ 下图是磁盘分区、卷组、逻辑卷和文件系统之间的逻辑关系的示意图： ​ 和非LVM系统将包含分区信息的元数据保存在位于分区的起始位置的分区表中一样，逻辑卷以及卷组相关的元数据也是保存在位于物理卷起始处的VGDA(卷组描述符区域)中。VGDA包括以下内容： PV描述符、VG描述符、LV描述符、和一些PE描述符 。 ​ 系统启动LVM时激活VG，并将VGDA加载至内存，来识别LV的实际物理存储位置。当系统进行I/O操作时，就会根据VGDA建立的映射机制来访问实际的物理位置。 四、 安装LVM​ 首先确定系统中是否安装了lvm工具： 12# rpm –qa|grep lvmRPM version 4.11.3 如果命令结果输入类似于上例，那么说明系统已经安装了LVM管理工具；如果命令没有输出则说明没有安装LVM管理工具，则需要从网络下载或者从光盘装LVM rpm工具包。安装了LVM的RPM软件包以后，要使用LVM还需要配置内核支持LVM。RedHat默认内核是支持LVM的 五： LVM基本操作新建一个逻辑卷并挂载1.为运行的虚拟机增加一块磁盘，在虚拟机中fdisk -l，可以看到新增加磁盘sdb 2.创建物理卷PV 创建物理卷的命令为pvcreate，利用该命令将希望添加到卷组的分区或者整个磁盘创建为物理卷。 将整个磁盘创建为物理卷的命令为： 1pvcreate /dev/sdb 查看创建好的PV 123456789101112[root@mysql001 ~]# pvdisplay --- Physical volume --- PV Name /dev/sdb VG Name vg_name PV Size 10.00 GiB / not usable 4.00 MiB Allocatable yes PE Size 4.00 MiB Total PE 2559 Free PE 2559 Allocated PE 0 PV UUID NvZnOF-jtaG-KFcf-nlqg-0LJp-fzw8-qsO9EL 3.创建卷组VG （如果已近存在逻辑卷组，可以直接省去此步，直接到4，当然也可以继续创建） vgcreate命令第一个参数是指定该卷组的逻辑名：vg_name。后面参数是指定希望添加到该卷组的物理卷PV。vgcreate在创建卷组 vg_name以外，还设置使用大小为4 MB的PE（默认为4MB），这表示卷组上创建的所有逻辑卷都以 4 MB 为增量单位来进行扩充或缩减。由于内核原因，PE大小决定了逻辑卷的最大大小，4 MB 的PE决定了单个逻辑卷最大容量为 256 GB，若希望使用大于256G的逻辑卷则创建卷组时指定更大的PE。PE大小范围为8 KB 到 512 MB，并且必须总是 2 的倍数（使用-s指定，具体请参考man vgcreate）。 1vgcreate vg_name /dev/sdb 通过vgdisplay查看，可以看到包含2559个PE,大小 10.00 GiB，未分配的PE数 12345678910111213141516171819202122[root@mysql001 ~]# vgdisplay --- Volume group --- VG Name vg_name System ID Format lvm2 Metadata Areas 1 Metadata Sequence No 1 VG Access read/write VG Status resizable MAX LV 0 Cur LV 0 Open LV 0 Max PV 0 Cur PV 1 Act PV 1 VG Size 10.00 GiB PE Size 4.00 MiB Total PE 2559 Alloc PE / Size 0 / 0 Free PE / Size 2559 / 10.00 GiB VG UUID 0XdJE4-OJJy-R6R3-IsmZ-DnOT-9P2L-E80rSS 4.创建逻辑卷 1lvcreate -L 10G -n lvm_name vg_name -L指定最终大小大小，或者-l指定PE的个数均可 5.创建文件系统 1mkfs.xfs /dev/vg_name/lvm_name 6.挂载在系统直接使用(需要/etc/fstab) 123mount /dev/vg_name/lvm_name /mnt[root@mysql001 ~]# df -h |grep mnt/dev/mapper/vg_name-lvm_name 10G 33M 10G 1% /mnt 扩展逻辑卷大小1.新增磁盘vdc 2.创建物理卷 1pvcreate /dev/sdc 3.扩展物理卷至卷组vg_name 1vgextend vg_name /dev/sdc 查看新的VG 12345678910111213141516171819202122[root@mysql001 ~]# vgdisplay --- Volume group --- VG Name vg_name System ID Format lvm2 Metadata Areas 2 Metadata Sequence No 3 VG Access read/write VG Status resizable MAX LV 0 Cur LV 1 Open LV 1 Max PV 0 Cur PV 2 Act PV 2 VG Size 19.99 GiB PE Size 4.00 MiB Total PE 5118 Alloc PE / Size 2559 / 10.00 GiB Free PE / Size 2559 / 10.00 GiB VG UUID 0XdJE4-OJJy-R6R3-IsmZ-DnOT-9P2L-E80rSS 5.增加逻辑卷 1lvextend -L 19.5G /dev/vg_name/lvm_name -L指定要扩展到的目标大小，或者-l指定PE的个数均可，也可以使用+号，表示增加的大小 1lvextend -L +9.5G /dev/vg_name/lvm_name 6.调整文件系统大小 ext4 文件系统 1resize2fs /dev/vg_name/lvm_name 如果是xfs格式的文件系统 需要使用 xfs_growfs 1xfs_growfs /dev/vg_name/lvm_name 减小逻辑卷大小增加是先增容量，再resize，减小是先resize，再reduce 使用lvreduce即可缩小逻辑卷的容量，同样需要首先将文件系统卸载： 123umount /mntresize2fs -s -10G /dev/vg_name/lvm_namelvreduce -L -10G /dev/vg_name/lvm_name 删除逻辑卷删除逻辑卷以前首先需要将其卸载 12umount /mntlvremove /dev/vg_name/lvm_namebash 参考Linux逻辑盘卷管理LVM详解 http://wiki.tldp.org/LVM-HOWTO]]></content>
      <categories>
        <category>Linux</category>
        <category>Linux基础</category>
      </categories>
      <tags>
        <tag>LVM</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Supervisor简介、安装、配置]]></title>
    <url>%2F2017%2F05%2F26%2FLinux%2FSupervisor%2FSupervisor%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[本文主要介绍了supervisor的安装、使用。 1. 什么是supervisor Supervisor是一个Python开发的client/server系统，可以管理和监控类unix上面的进程。类似daemontools 什么情况下我们需要进程管理呢？就是执行一些需要以守护进程方式执行的程序，比如一个后台任务，如经常会碰到要写一些守护进程，简单做法放入后台： 1shell&gt; nohup python xxx.py &amp; 除此之外，Supervisor 还能很友好的管理程序在命令行上输出的日志，可以将日志重定向到自定义的日志文件中，还能按文件大小对日志进行分割。 2. 为啥用supervisor方便 为啥简单呢？因为咱们通常管理linux进程的时候，一般来说都需要自己编写一个能够实现进程start/stop/restart/reload功能的脚本，然后丢到/etc/init.d/下面。这么做有很多不好的地方，第一我们要编写这个脚本，这就很耗时耗力了。第二，当这个进程挂掉的时候，linux不会自动重启它的，想要自动重启的话，我们还要自己写一个监控重启脚本。而supervisor则可以完美的解决这些问题。supervisor管理进程，是通过fork/exec的方式把这些被管理的进程，当作supervisor的子进程来启动。这样的话，我们只要在supervisor的配置文件中，把要管理的进程的可执行文件的路径写进去就OK了。这样就省下了我们如同linux管理进程的时自己写控制脚本的麻烦了。第二，被管理进程作为supervisor的子进程，当子进程挂掉的时候，父进程可以准确获取子进程挂掉的信息的，所以当然也就可以对挂掉的子进程进行自动重启了，当然重启还是不重启，也要看你的配置文件里面有木有设置autostart=true了。 精确 Supervisord将进程作为子进程启动，因此可以一直知晓子进程的状态，可以方便查询。而基于pid文件文件获取进程状态有时候不靠谱 权限代理 某些进程需要root或者sudo权限运行，而又不方便把机器的root权限和sudo权限开放给用户的时候，普通用户可以借助supervisor的命令和web UI进行进程的启动和关闭 进程组 linux系统没有批量启动关闭进程的功能，我们想要停止多个进程，只能一个一个的去停止，要么就自己写个脚本去批量停止。Supervisor 允许赋予进程优先级，可以使用supervisorctl 的“start all”, and “restart all”，按照优先级顺序启动。并且进程可以分组，相关的进程可以作为一个单元启动。 3. supervisor特点 简单 :supervisor通过一个 INI-style的文件配置，简单易学。提供了许多诸如重启失败进程、自动日子归档的功能 中心化: 可以在在同一个地方启动 停止 监控子进程，进程可以单独控制，也可以分组控制，并提供命令行和web接口配置supervisor 高效: 通过 fork/exec启动子进程 可扩展: 提供了simple event notification protocol和XML-RPC interface，方便通过各种语言进行配置管理 兼容性强: 类Unix都支持，不支持windows，基于Python 作为一款已经被使用了十多年的软件，可用性已经被广泛证明 4. Supervisor 组成 supervisord：supervisord是supervisor的服务端程序。负责启动子程序，应答客户端命令，重启crash进程，子程序日志记录，对进程变化发送事件通知等 supervisorctl： 客户端命令行工具，可以连接服务器端，进行进程的启动、关闭、重启、状态查看等。重要的一点是，supervisorctl不仅可以连接到本机上的supervisord，还可以连接到远程的supervisord，当然在本机上面是通过UNIX socket连接的，远程是通过TCP socket连接的。supervisorctl和supervisord之间的通信，是通过xml_rpc完成的。 相应的配置在[supervisorctl]块里面 Web Server 可以在界面上管理进程的WEB UI, 通过[inet_http_server] section配置，默认http://localhost:9001/` XML-RPC Interface XML-RPC接口，提供XML-RPC服务来对子进程进行管理，监控，参照 XML-RPC API Documentation. 5 安装5.1 yum 安装(推荐)1yum install supervisor 会自动安装成服务形式，可以使用systemctl进行管理 5.2 使用Setuptools安装123wget -q http://peak.telecommunity.com/dist/ez_setup.pypython ez_setup.pyeasy_install supervisor 或者 12yum install python-setuptoolseasy_install supervisor 5.3 安装方式31234wget https://pypi.python.org/packages/80/37/964c0d53cbd328796b1aeb7abea4c0f7b0e8c7197ea9b0b9967b7d004def/supervisor-3.3.1.tar.gztar -zxvf supervisor-3.3.1.tar.gz cd supervisor-3.3.1python setup.py install 5.4生成配置文件yum 安装方式不需要此步骤，因为已经自动生产了supervisord.conf 和supervisord.d文件夹 安装完 supervisor 之后，可以运行echo_supervisord_conf 命令输出默认的配置项，也可以重定向到一个配置文件里： 1echo_supervisord_conf &gt; /etc/supervisord.conf 5.5启动1supervisord -c /etc/supervisord.conf 6. 配置文件/etc/supervisord.conf上面我们已经把 supervisrod 运行起来了，现在可以添加我们要管理的进程的配置文件。可以把所有配置项都写到 supervisord.conf 文件里，但并不推荐这样做，而是通过 include 的方式把不同的程序（组）写到不同的配置文件里。yum方式安装，会自动配置。 12[include]files = supervisord.d/*.ini ; 可以是 *.conf 或 *.ini /etc/supervisord.conf 参数说明 123456789101112131415161718192021222324252627282930313233[unix_http_server]file=/tmp/supervisor.sock ; UNIX socket 文件，supervisorctl 会使用;chmod=0700 ; socket 文件的 mode，默认是 0700;chown=nobody:nogroup ; socket 文件的 owner，格式： uid:gid ;[inet_http_server] ; HTTP 服务器，提供 web 管理界面;port=127.0.0.1:9001 ; Web 管理后台运行的 IP 和端口，如果开放到公网，需要注意安全性;username=user ; 登录管理后台的用户名;password=123 ; 登录管理后台的密码 [supervisord]logfile=/tmp/supervisord.log ; 日志文件，默认是 $CWD/supervisord.loglogfile_maxbytes=50MB ; 日志文件大小，超出会 rotate，默认 50MBlogfile_backups=10 ; 日志文件保留备份数量默认 10loglevel=info ; 日志级别，默认 info，其它: debug,warn,tracepidfile=/tmp/supervisord.pid ; pid 文件nodaemon=false ; 是否在前台启动，默认是 false，即以 daemon 的方式启动minfds=1024 ; 可以打开的文件描述符的最小值，默认 1024minprocs=200 ; 可以打开的进程数的最小值，默认 200 ; the below section must remain in the config file for RPC; (supervisorctl/web interface) to work, additional interfaces may be; added by defining them in separate rpcinterface: sections[rpcinterface:supervisor]supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface [supervisorctl]serverurl=unix:///tmp/supervisor.sock ; 通过 UNIX socket 连接 supervisord，路径与 unix_http_server 部分的 file 一致;serverurl=http://127.0.0.1:9001 ; 通过 HTTP 的方式连接 supervisord ; 包含其他的配置文件[include]files = /etc/supervisord.d/*.ini ; 可以是 *.conf 或 *.ini 7. 添加一个被管理的进程我们假如有一个hello.py 123456789import weburls = ( '/(.*)','hello' )app = web.application(urls, globals())class hello: def GET(self, name): return 'hello: ' + nameif __name__ == '__main__': app.run() 所以直接在命令行启动的方式可能是这样的：(需要先安装web.py easy_install web.py) 1python /opt/hello.py 现在编写一份配置文件/etc/supervisord.d/hello.ini来管理这个进程 12345678910111213[program:hello]directory = /opt ; 程序的启动目录command = python /opt/hello.py ; 启动命令，可以看出与手动在命令行启动的命令是一样的autostart = true ; 在 supervisord 启动的时候也自动启动startsecs = 5 ; 启动 5 秒后没有异常退出，就当作已经正常启动了autorestart = true ; 程序异常退出后自动重启startretries = 3 ; 启动失败自动重试次数，默认是 3user = xqzt ; 用哪个用户启动redirect_stderr = true ; 把 stderr 重定向到 stdout，默认 falsestdout_logfile_maxbytes = 20MB ; stdout 日志文件大小，默认 50MBstdout_logfile_backups = 20 ; stdout 日志文件备份数; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件）stdout_logfile = /var/log/supervisor/hello.log 一份配置文件至少需要一个 [program:x] 部分的配置，来告诉 supervisord 需要管理那个进程。[program:x] 语法中的 x 表示 program name，会在客户端（supervisorctl 或 web 界面）显示，在 supervisorctl 中通过这个值来对程序进行 start、restart、stop 等操作。 12supervisor&gt; statushello RUNNING pid 2809, uptime 0:00:06 8. 使用 supervisorctlSupervisorctl 是 supervisord 的一个命令行客户端工具，启动时需要指定与 supervisord 使用同一份配置文件，否则与 supervisord 一样按照顺序查找配置文件。supervisorctl 这个命令会进入 supervisorctl 的 shell 界面，然后可以执行不同的命令了，也可以直接在 bash 终端运行。 1234567891011121314# supervisorctl --helpsupervisorctl -- control applications run by supervisord from the cmd line.Usage: /usr/bin/supervisorctl [options] [action [arguments]]Options:-c/--configuration -- configuration file path (default /etc/supervisord.conf)-h/--help -- print usage message and exit-i/--interactive -- start an interactive shell after executing commands-s/--serverurl URL -- URL on which supervisord server is listening (default "http://localhost:9001").-u/--username -- username to use for authentication with server-p/--password -- password to use for authentication with server-r/--history-file -- keep a readline history (if readline is available) 输入help,可以查看支持的命令及用法 123456789101112supervisor&gt; helpdefault commands (type help &lt;topic&gt;):=====================================add clear fg open quit remove restart start stop update avail exit maintail pid reload reread shutdown status tail versionsupervisor&gt; help startstart &lt;name&gt; Start a processstart &lt;gname&gt;:* Start all processes in a groupstart &lt;name&gt; &lt;name&gt; Start multiple processes or groupsstart all Start all processes 常用命令 12345678910111213141516# 停止某一个进程，program_name 为 [program:x] 里的 xsupervisorctl stop program_name# 启动某个进程supervisorctl start program_name# 重启某个进程supervisorctl restart program_name# 结束所有属于名为 groupworker 这个分组的进程 (start，restart 同理)supervisorctl stop groupworker:# 结束 groupworker:name1 这个进程 (start，restart 同理)supervisorctl stop groupworker:name1# 停止全部进程，注：start、restart、stop 都不会载入最新的配置文件supervisorctl stop all# 载入最新的配置文件，停止原有进程并按新的配置启动、管理所有进程supervisorctl reload# 根据最新的配置文件，启动新配置或有改动的进程，配置没有改动的进程不会受影响而重启supervisorctl update 9. supervisor Web UI除了 supervisorctl 之外，还可以配置 supervisrod 启动 web 管理界面，这个 web 后台使用 Basic Auth 的方式进行身份认证。将supervisord.conf中[inet_http_server]部分做相应配置，在supervisorctl中reload即可启动web管理界面 1234[inet_http_server] ; HTTP 服务器，提供 web 管理界面port=172.17.84.64:9001 ; Web 管理后台运行的 IP 和端口，如果开放到公网，需要注意安全性username=user ; 登录管理后台的用户名password=123 ; 登录管理后台的密码 在浏览器中输入http://127.0.0.1:9001，可进入web管理界面 10. 将多个进程按组管理Supervisor 同时还提供了另外一种进程组的管理方式，通过这种方式，可以使用 supervisorctl 命令来管理一组进程。跟 [program:x] 的进程组不同的是，这里的进程是一个个的 [program:x] 。 123[group:thegroupname]programs=progname1,progname2 ; each refers to 'x' in [program:x] definitionspriority=999 ; the relative start priority (default 999) 当添加了上述配置后，progname1 和 progname2 的进程名就会变成 thegroupname:progname1 和 thegroupname:progname2 以后就要用这个名字来管理进程了，而不是之前的 progname1。 以后执行 supervisorctl stop thegroupname: 就能同时结束 progname1 和 progname2，执行 supervisorctl stop thegroupname:progname1 就能结束 progname1。如下所示 /etc/supervisord.d/hello.ini文件 12345678910111213141516[group:group1]programs=hello[program:hello]directory = /opt ; 程序的启动目录command = python /opt/hello.py ; 启动命令，可以看出与手动在命令行启动的命令是一样的autostart = true ; 在 supervisord 启动的时候也自动启动startsecs = 5 ; 启动 5 秒后没有异常退出，就当作已经正常启动了autorestart = true ; 程序异常退出后自动重启startretries = 3 ; 启动失败自动重试次数，默认是 3user = xqzt ; 用哪个用户启动redirect_stderr = true ; 把 stderr 重定向到 stdout，默认 falsestdout_logfile_maxbytes = 20MB ; stdout 日志文件大小，默认 50MBstdout_logfile_backups = 20 ; stdout 日志文件备份数; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件）; stdout_logfile = /var/log/supervisor/hello.log 进程状态 12[root@centos7 etc]# supervisorctl group1:hello RUNNING pid 2842, uptime 0:02:53 11. Subprocesses进程状态变化 参考官方文档]]></content>
      <categories>
        <category>Linux</category>
        <category>Supervisor</category>
      </categories>
      <tags>
        <tag>supervisor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nslookup命令]]></title>
    <url>%2F2017%2F05%2F25%2FLinux%2F%E6%AF%8F%E5%A4%A9%E4%B8%80%E4%B8%AALinux%E5%91%BD%E4%BB%A4%2Fnslookup%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[摘要: nslookup命令简介 1. 命令简介 nslookup命令是常用域名查询工具，就是查DNS信息用的命令。 2. 安装1yum install bind-utils 3. 工作模式nslookup有两种工作模式，即“交互模式”和“非交互模式”。在“交互模式”下，用户可以向域名服务器查询各类主机、域名的信息，或者输出域名中的主机列表。而在“非交互模式”下，用户可以针对一个主机或域名仅仅获取特定的名称或所需信息。 3.1. 交互模式进入交互模式，总共有两种方法。 第一种方法，直接输入nslookup命令，不加任何参数，则直接进入交互模式，此时nslookup会连接到默认的域名服务器（即/etc/resolv.conf的第一个dns地址）。 1234567891011$ nslookup&gt; www.baidu.comServer: 192.168.0.1 //上连的DNS服务器Address: 192.168.0.1#53 //上连的DNS服务器的IP地址与端口号Non-authoritative answer: //非权威答案，即从上连DNS服务器的本地缓存中读取出的值，而非实际去查询到的值www.baidu.com canonical name = www.a.shifen.com. //说明www.baidu.com有个别名叫www.a.shifen.comName: www.a.shifen.com //域名www.a.shifen.comAddress: 119.75.217.56 //对应的IP地址之一Name: www.a.shifen.comAddress: 119.75.218.77//对应的IP地址之二 如果想更换DNS, 使用Server 123456789101112131415161718[root@mysql001 ~]# nslookup&gt; www.baidu.comServer: 192.168.0.1Address: 192.168.0.1#53Name: www.baidu.comAddress: 183.232.231.172&gt; server 8.8.8.8Default server: 8.8.8.8Address: 8.8.8.8#53&gt; www.baidu.comServer: 8.8.8.8Address: 8.8.8.8#53Name: www.baidu.comAddress: 111.13.100.91Name: www.baidu.comAddress: 111.13.100.92 第二种方法，是支持选定不同域名服务器的。需要设置第一个参数为“-”，然后第二个参数是设置要连接的域名服务器主机名或IP地址。 123456789[root@mysql001 ~]# nslookup - 8.8.8.8&gt; www.baidu.comServer: 8.8.8.8Address: 8.8.8.8#53Name: www.baidu.comAddress: 111.13.100.92Name: www.baidu.comAddress: 111.13.100.91 3.2. 非交互模式直接在nslookup命令后加上所要查询的IP或主机名，那么就进入了非交互模式。当然，这个时候你也可以在第二个参数位置设置所要连接的域名服务器。 1234567891011121314151617[root@mysql001 ~]# nslookup www.baidu.com - 8.8.8.8Server: 8.8.8.8Address: 8.8.8.8#53Name: www.baidu.comAddress: 111.13.100.92Name: www.baidu.comAddress: 111.13.100.91[root@mysql001 ~]# nslookup www.baidu.com 8.8.8.8Server: 8.8.8.8Address: 8.8.8.8#53Name: www.baidu.comAddress: 111.13.100.91Name: www.baidu.comAddress: 111.13.100.92 4. 常见的DNS服务器推荐 DNS 地址 说明 Google DNS 8.8.8.8 114 DNS 114.114.114.114 国内用户量巨大的DNS，访问速度快，各省都有节点，同时满足电信、联通、移动各运营商用户，可以有效预防劫持 阿里DNS 223.5.5.5 223.6.6.6 全球数百台服务器组成的集群 稳定性好]]></content>
      <categories>
        <category>Linux</category>
        <category>每天一个Linux命令</category>
      </categories>
      <tags>
        <tag>每天一个Linux命令</tag>
        <tag>nslookup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cp命令]]></title>
    <url>%2F2017%2F05%2F24%2FLinux%2F%E6%AF%8F%E5%A4%A9%E4%B8%80%E4%B8%AALinux%E5%91%BD%E4%BB%A4%2Fcp%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[摘要: cp（Copy file）：将源文件复制至目标文件，或将多个源文件复制至目标目录。 1、命令简介cp（Copy file）：将源文件复制至目标文件，或将多个源文件复制至目标目录。 2、用法123cp [选项]... [-T] 源文件 目标文件 或：cp [选项]... 源文件... 目录 或：cp [选项]... -t 目录 源文件... 3、选项123456789101112131415161718192021222324252627282930 -a, --archive 等于-dR --preserve=all,与同时指定 -dpR 这三个选项效果一样，用于复制整个目录，包括目录中的子目录等都递归的复制，而且还要保持文件的访问模式，所有者，时间戳等属性与原文件一样。 --backup[=CONTROL 为每个已存在的目标文件创建备份 -b 类似--backup 但不接受参数 --copy-contents 在递归处理是复制特殊文件内容 -d 等于--no-dereference --preserve=links -f, --force 如果目标文件无法打开则将其移除并重试(当 -n 选项存在时则不需再选此项) -i, --interactive 覆盖前询问(使前面的 -n 选项失效),默认cp命令覆盖目标文件时是不会提示的，很多Linux发行版里的cp都被设置别名`cp -i`,其实作用就是给用户一个提醒。如果你不想被提示，那么请这样输入：\cp source target，或者使用cp命令的绝对路径/bin/cp -H 跟随源文件中的命令行符号链接 -l, --link 对源文件建立硬链接，而非复制文件-L, --dereference 总是跟随符号链接 -n, --no-clobber 不要覆盖已存在的文件(使前面的 -i 选项失效) -P, --no-dereference 不跟随源文件中的符号链接 -p 等于--preserve=模式,所有权,时间戳 --preserve[=属性列表 保持指定的属性(默认：模式,所有权,时间戳)，如果可能保持附加属性：环境、链接、xattr 等 -c same as --preserve=context --sno-preserve=属性列表 不保留指定的文件属性 --parents 复制前在目标目录创建来源文件路径中的所有目录 -R, -r, --recursive 递归复制目录及其子目录内的所有内容 --reflink[=WHEN] 控制克隆/CoW 副本。请查看下面的内如。 --remove-destination 尝试打开目标文件前先删除已存在的目的地文件 (相对于 --force 选项) --sparse=WHEN 控制创建稀疏文件的方式 --strip-trailing-slashes 删除参数中所有源文件/目录末端的斜杠 -s, --symbolic-link 只创建符号链接而不复制文件 -S, --suffix=后缀 自行指定备份文件的后缀 -t, --target-directory=目录 将所有参数指定的源文件/目录 复制至目标目录 -T, --no-target-directory 将目标目录视作普通文件 -u, --update 使用这项参数后只会在源文件的更改时间较目标文件更新时或是名称相互对应的目标文件并不存在时，才复制文件； -v, --verbose 详细显示命令执行的操作。 -x, --one-file-system 复制的文件或目录存放的文件系统，必须与cp指令执行时所处的文件系统相同，否则不复制，亦不处理位于其他分区的文件 -Z, --context=CONTEXT set security context of copy to CONTEXT 4、实例实例1：将文件a.txt复制成文件b.txt1[root@cent6 directory]# cp a.txt b.txt 实例2：将文件a.txt复制成文件b.txt，显示详细信息12[root@cent6 directory]# cp -v a.txt b.txt`a.txt' -&gt; `b.txt' 实例3：复制文件，只有源文件较目的文件的修改时间新时，才复制文件1[root@cent6 directory]# cp -uv a.txt c.txt 实例4：采用交互方式将文件a.txt复制成文件d.txt123[root@cent6 directory]# cp -iv a.txt d.txtcp: overwrite `d.txt'? y`a.txt' -&gt; `d.txt' 实例5：将文件a.txt复制成d.txt，因为目的文件已经存在，所以指定使用强制复制的模式12[root@cent6 directory]# cp -fv a.txt d.txt`a.txt' -&gt; `d.txt' 实例6：递归将目录dir1复制到目录dir2下面（此时dir2不存在）123456[root@cent6 directory]# cp -rv dir1 dir2`dir1' -&gt; `dir2'`dir1/c.txt' -&gt; `dir2/c.txt'`dir1/a.txt' -&gt; `dir2/a.txt'`dir1/b.txt' -&gt; `dir2/b.txt'`dir1/d.txt' -&gt; `dir2/d.txt' 实例7：递归将目录dir1复制到目录dir2下面（此时dir2已经存在）12345[root@cent6 directory]# cp -rv dir1 dir2`dir1/c.txt' -&gt; `dir2/dir1/c.txt'`dir1/a.txt' -&gt; `dir2/dir1/a.txt'`dir1/b.txt' -&gt; `dir2/dir1/b.txt'`dir1/d.txt' -&gt; `dir2/dir1/d.txt' 实例8：复制时保留文件属性123456789[root@cent6 directory]# lltotal 0-rwxrwxrwx 1 root root 0 Apr 16 16:54 a.txt[root@cent6 directory]# cp a.txt /tmp/a1.txt[root@cent6 directory]# cp -p a.txt /tmp/a2.txt[root@cent6 directory]# ll /tmptotal 12-rwxr-xr-x 1 root root 0 Apr 16 16:56 a1.txt-rwxrwxrwx 1 root root 0 Apr 16 16:54 a2.txt 实例9：复制时产生备份文件12345678[root@cent6 directory]# cp -bv a.txt /tmp/`a.txt' -&gt; `/tmp/a.txt'[root@cent6 directory]# cp -bv a.txt /tmp/`a.txt' -&gt; `/tmp/a.txt' (backup: `/tmp/a.txt~')[root@cent6 directory]# ll /tmptotal 0-rwxr-xr-x 1 root root 0 Apr 16 17:02 a.txt-rwxr-xr-x 1 root root 0 Apr 16 17:02 a.txt~ 实例10：创建文件的硬链接（有同样的inode），而不是拷贝它们1234567[root@oracledb dir1]# cp -l a.txt b.txt[root@oracledb dir1]# cp a.txt c.txt[root@oracledb dir1]# ls -li总用量 04718769 -rw-r--r-- 2 root root 0 4月 16 17:18 a.txt4718769 -rw-r--r-- 2 root root 0 4月 16 17:18 b.txt4718772 -rw-r--r-- 1 root root 0 4月 16 17:28 c.txt 实例11：复制的 a.txt 建立一个连结档 a_link.txt123456[root@cent6 directory]# cp -sv a.txt a_link.txt`a.txt' -&gt; `a_link.txt'[root@cent6 directory]# lltotal 0lrwxrwxrwx 1 root root 5 Apr 16 17:06 a_link.txt -&gt; a.txt-rwxrwxrwx 1 root root 0 Apr 16 16:54 a.txt 实例12:不随符号链接拷贝原文件12345678910[root@oracledb dir1]# ll总用量 0lrwxrwxrwx 1 root root 5 4月 16 17:30 a_link.txt -&gt; a.txt-rw-r--r-- 1 root root 0 4月 16 17:18 a.txt[root@oracledb dir1]# cp -P a_link.txt c.txt[root@oracledb dir1]# ll总用量 0lrwxrwxrwx 1 root root 5 4月 16 17:30 a_link.txt -&gt; a.txt-rw-r--r-- 1 root root 0 4月 16 17:18 a.txtlrwxrwxrwx 1 root root 5 4月 16 17:31 c.txt -&gt; a.txt 实例13:指定备份文件尾标12345[root@oracledb dir1]# cp -v -S _bak a.txt /tmp/"a.txt" -&gt; "/tmp/a.txt"[root@oracledb dir1]# cp -v -S _bak a.txt /tmp/cp：是否覆盖"/tmp/a.txt"？ y"a.txt" -&gt; "/tmp/a.txt" (备份："/tmp/a.txt_bak")]]></content>
      <categories>
        <category>Linux</category>
        <category>每天一个Linux命令</category>
      </categories>
      <tags>
        <tag>每天一个Linux命令</tag>
        <tag>cp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Sysbench进行MySQL压力测试]]></title>
    <url>%2F2017%2F05%2F23%2FMySQL%2F%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%2FSysbench%E8%BF%9B%E8%A1%8CMySQL%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[本文主要介绍了如何使用Sysbench进行MySQL压力测试。 安装完sysbench后,/usr/share/sysbench下对数据库压力测试的lua文件： 1234567891011121314151617181920211. bulk_insert.lua 批量写入操作2. oltp_delete.lua 写入和删除并行操作3. oltp_insert.lua 纯写入操作4. oltp_point_select.lua 只读操作，条件为唯一索引列5. oltp_read_only.lua 只读操作，包含聚合，去重等操作6. oltp_read_write.lua 读写混合操作，最常用的脚本7. oltp_update_index.lua 更新操作，通过主键进行更新8. oltp_update_non_index.lua 更新操作，不通过索引列9. oltp_write_only.lua 纯写操作，常用脚本，包括insert update delete10. select_random_points.lua 随机集合只读操作，常用脚本，聚集索引列的selete in操作11. select_random_ranges.lua 随机范围只读操作，常用脚本，聚集索引列的selete between操作 数据库测试分为3步：prepare(准备测试数据)，run(开始测试),cleanup(清除测试数据) ​ 参数解析： ​ –db-driver：用到的数据库类型 ​ –mysql-host：数据库的IP ​ –mysql-port：数据库的端口 ​ –mysql-socket：socket的路径 ​ –mysql-user：数据库用户名 ​ –mysql-password：用户密码 ​ –mysql-db：数据库名字，默认为sysbench，需要提前创建创好 ​ –tables：生成表的个数 ​ –table-size：每个表的行数 ​ –report-interval：每隔多久在屏幕打印一次信息 ​ –time：压测时间 ​ –threads：启动多少个线程，即模拟多少个用户 创建测试数据库 123CREATE DATABASE sample DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ciGRANT ALL PRIVILEGES ON sample.* TO 'app_user'@'%' IDENTIFIED BY 'admin_123' 准备测试数据： 在本地数据库的dba_test库中，初始化10张表（sbtest1~sbtest10），存储引擎是innodb，每张表50万数据。 1234567891011121314151617181920212223242526272829303132333435[root@localhost sysbench]# sysbench /usr/share/sysbench/oltp_read_write.lua --db-driver=mysql --mysql-host=10.10.14.10 --mysql-port=3306 --mysql-user=app_user --mysql-password=admin_123 --mysql-db=sample --tables=10 --table-size=500000 --time=120 --report-interval=10 --threads=100 preparesysbench 1.0.7 (using bundled LuaJIT 2.1.0-beta2)Initializing worker threads...Creating table 'sbtest4'...Creating table 'sbtest6'...Creating table 'sbtest5'...Creating table 'sbtest8'...Creating table 'sbtest1'...Creating table 'sbtest2'...Creating table 'sbtest9'...Creating table 'sbtest3'...Creating table 'sbtest10'...Creating table 'sbtest7'...Inserting 500000 records into 'sbtest5'Inserting 500000 records into 'sbtest6'Inserting 500000 records into 'sbtest8'Inserting 500000 records into 'sbtest9'Inserting 500000 records into 'sbtest4'Inserting 500000 records into 'sbtest10'Inserting 500000 records into 'sbtest1'Inserting 500000 records into 'sbtest3'Inserting 500000 records into 'sbtest2'Inserting 500000 records into 'sbtest7'Creating a secondary index on 'sbtest9'...Creating a secondary index on 'sbtest2'...Creating a secondary index on 'sbtest3'...Creating a secondary index on 'sbtest6'...Creating a secondary index on 'sbtest10'...Creating a secondary index on 'sbtest5'...Creating a secondary index on 'sbtest8'...Creating a secondary index on 'sbtest4'...Creating a secondary index on 'sbtest1'...Creating a secondary index on 'sbtest7'... 压测数据库： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485[root@localhost sysbench]# sysbench /usr/share/sysbench/oltp_read_write.lua --db-driver=mysql --mysql-host=10.10.14.10 --mysql-port=3306 --mysql-user=app_user --mysql-password=admin_123 --mysql-db=sample --tables=10 --table-size=500000 --time=120 --report-interval=10 --threads=100 preparesysbench 1.0.7 (using bundled LuaJIT 2.1.0-beta2)Initializing worker threads...Creating table 'sbtest4'...Creating table 'sbtest6'...Creating table 'sbtest5'...Creating table 'sbtest8'...Creating table 'sbtest1'...Creating table 'sbtest2'...Creating table 'sbtest9'...Creating table 'sbtest3'...Creating table 'sbtest10'...Creating table 'sbtest7'...Inserting 500000 records into 'sbtest5'Inserting 500000 records into 'sbtest6'Inserting 500000 records into 'sbtest8'Inserting 500000 records into 'sbtest9'Inserting 500000 records into 'sbtest4'Inserting 500000 records into 'sbtest10'Inserting 500000 records into 'sbtest1'Inserting 500000 records into 'sbtest3'Inserting 500000 records into 'sbtest2'Inserting 500000 records into 'sbtest7'Creating a secondary index on 'sbtest9'...Creating a secondary index on 'sbtest2'...Creating a secondary index on 'sbtest3'...Creating a secondary index on 'sbtest6'...Creating a secondary index on 'sbtest10'...Creating a secondary index on 'sbtest5'...Creating a secondary index on 'sbtest8'...Creating a secondary index on 'sbtest4'...Creating a secondary index on 'sbtest1'...Creating a secondary index on 'sbtest7'...[root@localhost sysbench]# sysbench /usr/share/sysbench/oltp_read_write.lua --db-driver=mysql --mysql-host=10.10.14.10 --mysql-port=3306 --mysql-user=app_user --mysql-password=admin_123 --mysql-db=sample --tables=10 --table-size=500000 --time=120 --report-interval=10 --threads=100 runsysbench 1.0.7 (using bundled LuaJIT 2.1.0-beta2)Running the test with following options:Number of threads: 100Report intermediate results every 10 second(s)Initializing random number generator from current timeInitializing worker threads...Threads started![ 10s ] thds: 100 tps: 1463.35 qps: 29420.80 (r/w/o: 20611.00/5872.80/2937.00) lat (ms,95%): 118.92 err/s: 0.40 reconn/s: 0.00[ 20s ] thds: 100 tps: 1606.45 qps: 32128.43 (r/w/o: 22493.22/6422.31/3212.90) lat (ms,95%): 102.97 err/s: 0.00 reconn/s: 0.00[ 30s ] thds: 100 tps: 1621.80 qps: 32395.26 (r/w/o: 22665.67/6486.49/3243.10) lat (ms,95%): 104.84 err/s: 0.20 reconn/s: 0.00[ 40s ] thds: 100 tps: 1587.60 qps: 31800.89 (r/w/o: 22270.26/6354.62/3176.01) lat (ms,95%): 106.75 err/s: 0.30 reconn/s: 0.00[ 50s ] thds: 100 tps: 1621.99 qps: 32449.93 (r/w/o: 22716.28/6489.07/3244.58) lat (ms,95%): 101.13 err/s: 0.40 reconn/s: 0.00[ 60s ] thds: 100 tps: 1668.01 qps: 33364.65 (r/w/o: 23354.81/6673.73/3336.12) lat (ms,95%): 97.55 err/s: 0.30 reconn/s: 0.00[ 70s ] thds: 100 tps: 1639.89 qps: 32784.79 (r/w/o: 22947.13/6557.88/3279.79) lat (ms,95%): 101.13 err/s: 0.10 reconn/s: 0.00[ 80s ] thds: 100 tps: 1658.80 qps: 33172.77 (r/w/o: 23223.95/6630.91/3317.91) lat (ms,95%): 99.33 err/s: 0.10 reconn/s: 0.00[ 90s ] thds: 100 tps: 1592.40 qps: 31900.02 (r/w/o: 22325.71/6388.90/3185.40) lat (ms,95%): 102.97 err/s: 0.40 reconn/s: 0.00[ 100s ] thds: 100 tps: 1621.90 qps: 32414.24 (r/w/o: 22690.53/6480.01/3243.70) lat (ms,95%): 101.13 err/s: 0.20 reconn/s: 0.00[ 110s ] thds: 100 tps: 1646.10 qps: 32945.10 (r/w/o: 23069.93/6582.08/3293.09) lat (ms,95%): 99.33 err/s: 0.60 reconn/s: 0.00[ 120s ] thds: 100 tps: 1594.00 qps: 31879.15 (r/w/o: 22311.53/6379.41/3188.20) lat (ms,95%): 104.84 err/s: 0.20 reconn/s: 0.00SQL statistics: queries performed: read: 2707040 write: 773344 other: 386688 total: 3867072 transactions: 193328 (1610.51 per sec.) queries: 3867072 (32214.55 per sec.) ignored errors: 32 (0.27 per sec.) reconnects: 0 (0.00 per sec.)General statistics: total time: 120.0398s total number of events: 193328Latency (ms): min: 11.97 avg: 62.08 max: 360.82 95th percentile: 102.97 sum: 12001678.41Threads fairness: events (avg/stddev): 1933.2800/32.79 execution time (avg/stddev): 120.0168/0.01 删除测试数据： 1sysbench /usr/share/sysbench/oltp_read_only.lua --db-driver=mysql --mysql-host=10.10.14.10 --mysql-port=3306 --mysql-user=app_user --mysql-password=admin_123 --mysql-db=sample --tables=10 --table-size=500000 --time=120 --report-interval=10 --threads=100 cleanup 参考sysbench 安装、使用和测试]]></content>
      <categories>
        <category>MySQL</category>
        <category>性能测试</category>
      </categories>
      <tags>
        <tag>Sysbench</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Sysbench进行CPU、 内存、 IO 、线程、 mutex压力测试]]></title>
    <url>%2F2017%2F05%2F22%2FMySQL%2F%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%2FSysbench%E8%BF%9B%E8%A1%8CCPU%20%E5%86%85%E5%AD%98%20IO%20%E7%BA%BF%E7%A8%8B%20mutex%E6%B5%8B%E8%AF%95%E4%BE%8B%E5%AD%90%2F</url>
    <content type="text"><![CDATA[本文主要介绍了如何使用Sysbench进行CPU、 内存、 IO 、线程、 mutex压力测试。 CPU测试sysbench cpu help 12345sysbench cpu helpsysbench 1.0.7 (using bundled LuaJIT 2.1.0-beta2)cpu options: --cpu-max-prime=N upper limit for primes generator [10000] 最大质数发生器数量。默认是10000 测试结果 12345678910111213141516171819202122232425262728293031➜ ~ sysbench cpu --cpu-max-prime=2000 runsysbench 1.0.7 (using bundled LuaJIT 2.1.0-beta2)Running the test with following options:Number of threads: 1Initializing random number generator from current timePrime numbers limit: 2000Initializing worker threads...Threads started!General statistics: total time: 10.0001s total number of events: 73827Latency (ms): min: 0.12 avg: 0.13 max: 5.69 95th percentile: 0.19 sum: 9961.81Threads fairness: events (avg/stddev): 73827.0000/0.00 execution time (avg/stddev): 9.9618/0.00 内存测试123456789sysbench memory helpsysbench 1.0.7 (using bundled LuaJIT 2.1.0-beta2)memory options: --memory-block-size=SIZE size of memory block for test [1K] 测试时内存块大小。默认是1K --memory-total-size=SIZE total size of data to transfer [100G] 传输数据的总大小。默认是100G --memory-scope=STRING memory access scope &#123;global,local&#125; [global] 内存访问范围&#123;global,local&#125;。默认是global --memory-oper=STRING type of memory operations &#123;read, write, none&#125; [write] 内存操作类型。&#123;read, write, none&#125; 默认是write --memory-access-mode=STRING memory access mode &#123;seq,rnd&#125; [seq] 存储器存取方式&#123;seq,rnd&#125; 默认是seq 测试结果 12345678910111213141516171819202122232425262728293031323334353637sysbench memory --memory-block-size=8k --memory-total-size=1G runsysbench 1.0.7 (using bundled LuaJIT 2.1.0-beta2)Running the test with following options:Number of threads: 1Initializing random number generator from current timeRunning memory speed test with the following options: block size: 8KiB total size: 1024MiB operation: write scope: globalInitializing worker threads...Threads started!Total operations: 131072 (940750.90 per second)1024.00 MiB transferred (7349.62 MiB/sec)General statistics: total time: 0.1369s total number of events: 131072Latency (ms): min: 0.00 avg: 0.00 max: 1.18 95th percentile: 0.00 sum: 100.88Threads fairness: events (avg/stddev): 131072.0000/0.00 execution time (avg/stddev): 0.1009/0.00 I/O测试12345678910111213141516sysbench fileio helpsysbench 1.0.7 (using bundled LuaJIT 2.1.0-beta2)fileio options: --file-num=N number of files to create [128] 创建测试文件的数量。默认是128 --file-block-size=N block size to use in all IO operations [16384] 测试时文件块的大小。默认是16384(16K) --file-total-size=SIZE total size of files to create [2G] 测试文件的总大小。默认是2G --file-test-mode=STRING test mode &#123;seqwr, seqrewr, seqrd, rndrd, rndwr, rndrw&#125; 文件测试模式&#123;seqwr(顺序写), seqrewr(顺序读写), seqrd(顺序读), rndrd(随机读), rndwr(随机写), rndrw(随机读写)&#125; --file-io-mode=STRING file operations mode &#123;sync,async,mmap&#125; [sync] 文件操作模式&#123;sync(同步),async(异步),fastmmap(快速map映射),slowmmap(慢map映射)&#125;。默认是sync --file-extra-flags=STRING additional flags to use on opening files &#123;sync,dsync,direct&#125; [] 使用额外的标志来打开文件&#123;sync,dsync,direct&#125; 。默认为空 --file-fsync-freq=N do fsync() after this number of requests (0 - don't use fsync()) [100] 执行fsync()的频率。(0 – 不使用fsync())。默认是100 --file-fsync-all[=on|off] do fsync() after each write operation [off] 每执行完一次写操作就执行一次fsync。默认是off --file-fsync-end[=on|off] do fsync() at the end of test [on] 在测试结束时才执行fsync。默认是on --file-fsync-mode=STRING which method to use for synchronization &#123;fsync, fdatasync&#125; [fsync]使用哪种方法进行同步&#123;fsync, fdatasync&#125;。默认是fsync --file-merged-requests=N merge at most this number of IO requests if possible (0 - don't merge) [0]如果可以，合并最多的IO请求数(0 – 表示不合并)。默认是0 --file-rw-ratio=N reads/writes ratio for combined test [1.5] 测试时的读写比例。默认是1.5 1，prepare阶段，生成需要的测试文件，完成后会在当前目录下生成很多小文件。 1sysbench fileio --threads=16 --file-total-size=2G --file-test-mode=rndrw prepare 2，run阶段 1sysbench fileio --threads=20 --file-total-size=2G --file-test-mode=rndrw run 3，清理测试时生成的文件 1sysbench fileio --threads=20 --file-total-size=2G --file-test-mode=rndrw cleanup 执行过程如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188sysbench fileio --threads=16 --file-total-size=2G --file-test-mode=rndrw preparesysbench 1.0.7 (using bundled LuaJIT 2.1.0-beta2)128 files, 16384Kb each, 2048Mb totalCreating files for the test...Extra file open flags: 0Creating file test_file.0Creating file test_file.1Creating file test_file.2Creating file test_file.3Creating file test_file.4Creating file test_file.5Creating file test_file.6Creating file test_file.7Creating file test_file.8Creating file test_file.9Creating file test_file.10Creating file test_file.11Creating file test_file.12Creating file test_file.13Creating file test_file.14Creating file test_file.15Creating file test_file.16Creating file test_file.17Creating file test_file.18Creating file test_file.19Creating file test_file.20Creating file test_file.21Creating file test_file.22Creating file test_file.23Creating file test_file.24Creating file test_file.25Creating file test_file.26Creating file test_file.27Creating file test_file.28Creating file test_file.29Creating file test_file.30Creating file test_file.31Creating file test_file.32Creating file test_file.33Creating file test_file.34Creating file test_file.35Creating file test_file.36Creating file test_file.37Creating file test_file.38Creating file test_file.39Creating file test_file.40Creating file test_file.41Creating file test_file.42Creating file test_file.43Creating file test_file.44Creating file test_file.45Creating file test_file.46Creating file test_file.47Creating file test_file.48Creating file test_file.49Creating file test_file.50Creating file test_file.51Creating file test_file.52Creating file test_file.53Creating file test_file.54Creating file test_file.55Creating file test_file.56Creating file test_file.57Creating file test_file.58Creating file test_file.59Creating file test_file.60Creating file test_file.61Creating file test_file.62Creating file test_file.63Creating file test_file.64Creating file test_file.65Creating file test_file.66Creating file test_file.67Creating file test_file.68Creating file test_file.69Creating file test_file.70Creating file test_file.71Creating file test_file.72Creating file test_file.73Creating file test_file.74Creating file test_file.75Creating file test_file.76Creating file test_file.77Creating file test_file.78Creating file test_file.79Creating file test_file.80Creating file test_file.81Creating file test_file.82Creating file test_file.83Creating file test_file.84Creating file test_file.85Creating file test_file.86Creating file test_file.87Creating file test_file.88Creating file test_file.89Creating file test_file.90Creating file test_file.91Creating file test_file.92Creating file test_file.93Creating file test_file.94Creating file test_file.95Creating file test_file.96Creating file test_file.97Creating file test_file.98Creating file test_file.99Creating file test_file.100Creating file test_file.101Creating file test_file.102Creating file test_file.103Creating file test_file.104Creating file test_file.105Creating file test_file.106Creating file test_file.107Creating file test_file.108Creating file test_file.109Creating file test_file.110Creating file test_file.111Creating file test_file.112Creating file test_file.113Creating file test_file.114Creating file test_file.115Creating file test_file.116Creating file test_file.117Creating file test_file.118Creating file test_file.119Creating file test_file.120Creating file test_file.121Creating file test_file.122Creating file test_file.123Creating file test_file.124Creating file test_file.125Creating file test_file.126Creating file test_file.1272147483648 bytes written in 2.48 seconds (826.62 MiB/sec).➜ ~➜ ~➜ ~ sysbench fileio --threads=20 --file-total-size=2G --file-test-mode=rndrw runsysbench 1.0.7 (using bundled LuaJIT 2.1.0-beta2)Running the test with following options:Number of threads: 20Initializing random number generator from current timeExtra file open flags: 0128 files, 16MiB each2GiB total file sizeBlock size 16KiBNumber of IO requests: 0Read/Write ratio for combined random IO test: 1.50Periodic FSYNC enabled, calling fsync() each 100 requests.Calling fsync() at the end of test, Enabled.Using synchronous I/O modeDoing random r/w testInitializing worker threads...Threads started!File operations: reads/s: 15512.76 writes/s: 10341.51 fsyncs/s: 33093.17Throughput: read, MiB/s: 242.39 written, MiB/s: 161.59General statistics: total time: 10.0005s total number of events: 589605Latency (ms): min: 0.00 avg: 0.22 max: 6.39 95th percentile: 0.50 sum: 130617.03Threads fairness: events (avg/stddev): 29480.2500/81.36 execution time (avg/stddev): 6.5309/0.01➜ ~ sysbench fileio --threads=20 --file-total-size=2G --file-test-mode=rndrw cleanupsysbench 1.0.7 (using bundled LuaJIT 2.1.0-beta2)Removing test files... 线程测试123456sysbench threads helpsysbench 1.0.7 (using bundled LuaJIT 2.1.0-beta2)threads options: --thread-yields=N number of yields to do per request [1000] 每个请求产生多少个线程。默认是1000 --thread-locks=N number of locks per thread [8] 每个线程的锁的数量。默认是8 12345678910111213141516171819202122232425262728sysbench threads --num-threads=500 --thread-yields=100 --thread-locks=4 runWARNING: --num-threads is deprecated, use --threads insteadsysbench 1.0.7 (using bundled LuaJIT 2.1.0-beta2)Running the test with following options:Number of threads: 500Initializing random number generator from current timeInitializing worker threads...Threads started!General statistics: total time: 10.0902s total number of events: 25095Latency (ms): min: 78.56 avg: 200.33 max: 258.32 95th percentile: 235.74 sum: 5027387.63Threads fairness: events (avg/stddev): 50.1900/0.40 execution time (avg/stddev): 10.0548/0.02 mutex测试1234567sysbench mutex helpsysbench 1.0.7 (using bundled LuaJIT 2.1.0-beta2)mutex options: --mutex-num=N total size of mutex array [4096] 数组互斥的总大小。默认是4096 --mutex-locks=N number of mutex locks to do per thread [50000] 每个线程互斥锁的数量。默认是50000 --mutex-loops=N number of empty loops to do outside mutex lock [10000] 内部互斥锁的空循环数量。默认是10000 执行过程 123456789101112131415161718192021222324252627282930sysbench mutex --num-threads=100 --mutex-num=1000 --mutex-locks=100000 --mutex-loops=10000 runWARNING: --num-threads is deprecated, use --threads insteadsysbench 1.0.7 (using bundled LuaJIT 2.1.0-beta2)Running the test with following options:Number of threads: 100Initializing random number generator from current timeInitializing worker threads...Threads started!General statistics: total time: 17.9762s total number of events: 100Latency (ms): min: 15479.16 avg: 17200.68 max: 17910.48 95th percentile: 17752.80 sum: 1720067.67Threads fairness: events (avg/stddev): 1.0000/0.00 execution time (avg/stddev): 17.2007/0.59 参考sysbench 安装、使用和测试 https://github.com/akopytov/sysbench]]></content>
      <categories>
        <category>MySQL</category>
        <category>性能测试</category>
      </categories>
      <tags>
        <tag>Sysbench</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sysbench压力测试工具的安装和使用]]></title>
    <url>%2F2017%2F05%2F21%2FMySQL%2F%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%2Fsysbench%20%E7%AE%80%E4%BB%8B%E3%80%81%E5%AE%89%E8%A3%85%E3%80%81%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[本文主要介绍了sysbench的安装和使用。 1. sysbench简介sysbench is a scriptable multi-threaded benchmark tool based on LuaJIT. It is most frequently used for database benchmarks, but can also be used to create arbitrarily complex workloads that do not involve a database server. sysbench 支持如下的基准测试： oltp_*.lua: a collection of OLTP-like database benchmarks （OLTP数据库 如MySQL、Oracle、PostgreSQL） fileio: a filesystem-level benchmark (文件I/O性能） cpu: a simple CPU benchmark （CPU性能测试） memory: a memory access benchmark （内存访问） threads: a thread-based scheduler benchmark （基于线程的调度性能） mutex: a POSIX mutex benchmark 2. 特点 extensive statistics about rate(速率) and latency(延迟) is available, including latency percentiles（统计） and histograms（直方图）; low overhead even with thousands of concurrent threads. sysbench is capable of generating and tracking hundreds of millions of events per second; new benchmarks can be easily created by implementing pre-defined hooks in user-provided Lua scripts; 3. 安装3.1 二进制安装 Debian/Ubuntu 12curl -s https://packagecloud.io/install/repositories/akopytov/sysbench/script.deb.sh | sudo bashsudo apt -y install sysbench RHEL/CentOS: 12curl -s https://packagecloud.io/install/repositories/akopytov/sysbench/script.rpm.sh | sudo bashsudo yum -y install sysbench Fedora: 12curl -s https://packagecloud.io/install/repositories/akopytov/sysbench/script.rpm.sh | sudo bash sudo dnf -y install sysbench macOS: 12# Add --with-postgresql if you need PostgreSQL supportbrew install sysbench 3.2 源码构建推荐使用二进制安装 3.2.1 Build RequirementsDebian/Ubuntu 12345apt -y install make automake libtool pkg-config libaio-dev vim-common# For MySQL supportapt -y install libmysqlclient-dev# For PostgreSQL supportapt -y install libpq-dev RHEL/CentOS 12345yum -y install make automake libtool pkgconfig libaio-devel vim-common# For MySQL support, replace with mysql-devel on RHEL/CentOS 5yum -y install mariadb-devel# For PostgreSQL supportyum -y install postgresql-devel Fedora 12345dnf -y install make automake libtool pkgconfig libaio-devel vim-common# For MySQL supportdnf -y install mariadb-devel# For PostgreSQL supportdnf -y install postgresql-devel macOS **Assuming you have Xcode (or Xcode Command Line Tools) and Homebrew installed: 12345brew install automake pkg-config# For MySQL supportbrew install mysql# For PostgreSQL supportbrew install postgresql 3.2.2 Build and Install1234567git clone https://github.com/akopytov/sysbench.gitcd sysbench./autogen.sh# Add --with-pgsql to build with PostgreSQL support./configuremakemake install The above will build sysbench with MySQL support by default. If you have MySQL headers and libraries in non-standard locations (and no mysql_config can be found in the PATH), you can specify them explicitly with --with-mysql-includes and --with-mysql-libs options to ./configure. To compile sysbench without MySQL support, use --without-mysql. If no database drivers are available database-related scripts will not work, but other benchmarks will be functional. See README-Oracle.md for instructions on building with Oracle client libraries. 4. 语法说明4.1 sysbench –help12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879[root@localhost ~]# sysbench --helpUsage: sysbench [options]... [testname] [command]Commands implemented by most tests: prepare run cleanup helpGeneral options: --threads=N number of threads to use [1] --events=N limit for total number of events [0] --time=N limit for total execution time in seconds [10] --forced-shutdown=STRING number of seconds to wait after the --time limit before forcing shutdown, or 'off' to disable [off] --thread-stack-size=SIZE size of stack per thread [64K] --rate=N average transactions rate. 0 for unlimited rate [0] --report-interval=N periodically report intermediate statistics with a specified interval in seconds. 0 disables intermediate reports [0] --report-checkpoints=[LIST,...] dump full statistics and reset all counters at specified points in time. The argument is a list of comma-separated values representing the amount of time in seconds elapsed from start of test when report checkpoint(s) must be performed. Report checkpoints are off by default. [] --debug[=on|off] print more debugging info [off] --validate[=on|off] perform validation checks where possible [off] --help[=on|off] print help and exit [off] --version[=on|off] print version and exit [off] --config-file=FILENAME File containing command line options --tx-rate=N deprecated alias for --rate [0] --max-requests=N deprecated alias for --events [0] --max-time=N deprecated alias for --time [0] --num-threads=N deprecated alias for --threads [1]Pseudo-Random Numbers Generator options: --rand-type=STRING random numbers distribution &#123;uniform,gaussian,special,pareto&#125; [special] --rand-spec-iter=N number of iterations used for numbers generation [12] --rand-spec-pct=N percentage of values to be treated as 'special' (for special distribution) [1] --rand-spec-res=N percentage of 'special' values to use (for special distribution) [75] --rand-seed=N seed for random number generator. When 0, the current time is used as a RNG seed. [0] --rand-pareto-h=N parameter h for pareto distibution [0.2]Log options: --verbosity=N verbosity level &#123;5 - debug, 0 - only critical messages&#125; [3] --percentile=N percentile to calculate in latency statistics (1-100). Use the special value of 0 to disable percentile calculations [95] --histogram[=on|off] print latency histogram in report [off]General database options: --db-driver=STRING specifies database driver to use ('help' to get list of available drivers) --db-ps-mode=STRING prepared statements usage mode &#123;auto, disable&#125; [auto] --db-debug[=on|off] print database-specific debug information [off]Compiled-in database drivers: mysql - MySQL driver pgsql - PostgreSQL drivermysql options: --mysql-host=[LIST,...] MySQL server host [localhost] --mysql-port=[LIST,...] MySQL server port [3306] --mysql-socket=[LIST,...] MySQL socket --mysql-user=STRING MySQL user [sbtest] --mysql-password=STRING MySQL password [] --mysql-db=STRING MySQL database name [sbtest] --mysql-ssl[=on|off] use SSL connections, if available in the client library [off] --mysql-ssl-cipher=STRING use specific cipher for SSL connections [] --mysql-compression[=on|off] use compression, if available in the client library [off] --mysql-debug[=on|off] trace all client library calls [off] --mysql-ignore-errors=[LIST,...] list of errors to ignore, or "all" [1213,1020,1205] --mysql-dry-run[=on|off] Dry run, pretend that all MySQL client API calls are successful without executing them [off]pgsql options: --pgsql-host=STRING PostgreSQL server host [localhost] --pgsql-port=N PostgreSQL server port [5432] --pgsql-user=STRING PostgreSQL user [sbtest] --pgsql-password=STRING PostgreSQL password [] --pgsql-db=STRING PostgreSQL database name [sbtest]Compiled-in tests: fileio - File I/O test cpu - CPU performance test memory - Memory functions speed test threads - Threads subsystem performance test mutex - Mutex performance testSee 'sysbench &lt;testname&gt; help' for a list of options for each test. 4.2 命令说明通用语法 1sysbench [options]... [testname] [command] 4.2.1 testname testname is an optional name of a built-in test (e.g. fileio, memory, cpu, etc.), or a name of one of the bundled Lua scripts (e.g. oltp_read_only), or a path to a custom Lua script. If no test name is specified on the command line (and thus, there is no command too, as in that case it would be parsed as a testname), or the test name is a dash (“-“), then sysbench expects a Lua script to execute on its standard input. testname 可以是一个内置的测试 ( 当前支持5种 fileio,memory, cpu,threads, mutex.), 也可以是一个内置的lua脚本名 (e.g. oltp_read_only), a path to a custom Lua script. 不指定的情况, then sysbench expects a Lua script to execute on its standard input. 4.2.2 command command is an optional argument that will be passed by sysbench to the built-in test or script specified with testname. command defines the action that must be performed by the test. The list of available commands depends on a particular test. Some tests also implement their own custom commands. Below is a description of typical test commands and their purpose: prepare: performs preparative actions for those tests which need them, e.g. creating the necessary files on disk for the fileio test, or filling the test database for database benchmarks. run: runs the actual test specified with the testname argument. This command is provided by all tests. cleanup: removes temporary data after the test run in those tests which create one. help: displays usage information for the test specified with the testname argument. This includes the full list of commands provided by the test, so it should be used to get the available commands. 4.2.3 optionsoptions 包括通用的选项，另外不同的testname也包含特定的option，如mysql测试包含的数据库连接信息。特定测试的option可以通过sysbench testname help 查看。sysbench --help可以查看通用的option 通用命令行选项The table below lists the supported common options, their descriptions and default values: Option Description Default value --threads The total number of worker threads to create 创建测试线程的数目。默认为1. 1 --events Limit for total number of requests. 0 (the default) means no limit 请求的最大数目。0代表不限制 0 --time Limit for total execution time in seconds. 0 means no limit 最大执行时间，单位是s。 10 –forced-shutdown=STRING number of seconds to wait after the –time limit before forcing shutdown, or ‘off’ to disable [off] 超过–time强制中断。默认是off off --thread-stack-size Size of stack for each thread 每个线程的堆栈大小。 64K --rate Average transactions rate. The number specifies how many events (transactions) per seconds should be executed by all threads on average. 0 (default) means unlimited rate, i.e. events are executed as fast as possible 0 --report-interval periodically report intermediate statistics with a specified interval in seconds. 0 disables intermediate reports [0] 执行过程中，显示执行结果的时间间隔 0 --debug Print more debug info 是否显示debug信息 off --validate Perform validation of test results where possible 在可能情况下执行验证检查。 off --help Print help on general syntax or on a specified test, and exit 查看帮助 off --verbosity verbosity level {5 - debug, 0 - only critical messages} [3] 日志详细级别 3 --percentile percentile to calculate in latency statistics (1-100). Use the special value of 0 to disable percentile calculations [95] 表示设定采样比例，默认是 95%，即丢弃5%的长请求，在剩余的99%里取最大值 95 –histogram[=on\ off] print latency histogram in report [off] report延迟直方图 off --luajit-cmd perform a LuaJIT control command. This option is equivalent to luajit -j. See LuaJIT documentation for more information 特定测试相关的选项可以通过sysbench testname help 查看 sysbench fileio help 12345678910111213141516sysbench fileio helpsysbench 1.0.7 (using bundled LuaJIT 2.1.0-beta2)fileio options: --file-num=N number of files to create [128]创建测试文件的数量。默认是128 --file-block-size=N block size to use in all IO operations [16384]测试时文件块的大小。默认是16384(16K) --file-total-size=SIZE total size of files to create [2G]测试文件的总大小。默认是2G --file-test-mode=STRING test mode &#123;seqwr, seqrewr, seqrd, rndrd, rndwr, rndrw&#125;文件测试模式&#123;seqwr(顺序写), seqrewr(顺序读写), seqrd(顺序读), rndrd(随机读), rndwr(随机写), rndrw(随机读写)&#125; --file-io-mode=STRING file operations mode &#123;sync,async,mmap&#125; [sync] 文件操作模式&#123;sync(同步),async(异步),fastmmap(快速map映射),slowmmap(慢map映射)&#125;。默认是sync --file-extra-flags=STRING additional flags to use on opening files &#123;sync,dsync,direct&#125; []使用额外的标志来打开文件&#123;sync,dsync,direct&#125; 。默认为空 --file-fsync-freq=N do fsync() after this number of requests (0 - don't use fsync()) [100]执行fsync()的频率。(0 – 不使用fsync())。默认是100 --file-fsync-all[=on|off] do fsync() after each write operation [off]每执行完一次写操作就执行一次fsync。默认是off --file-fsync-end[=on|off] do fsync() at the end of test [on]在测试结束时才执行fsync。默认是on --file-fsync-mode=STRING which method to use for synchronization &#123;fsync, fdatasync&#125; [fsync]使用哪种方法进行同步&#123;fsync, fdatasync&#125;。默认是fsync --file-merged-requests=N merge at most this number of IO requests if possible (0 - don't merge) [0]如果可以，合并最多的IO请求数(0 – 表示不合并)。默认是0 --file-rw-ratio=N reads/writes ratio for combined test [1.5] 测试时的读写比例。默认是1.5 sysbench cpu help 12345sysbench cpu helpsysbench 1.0.7 (using bundled LuaJIT 2.1.0-beta2)cpu options: --cpu-max-prime=N upper limit for primes generator [10000] 最大质数发生器数量。默认是10000 sysbench memory help 12345--memory-block-size=SIZE size of memory block for test [1K] 测试时内存块大小。默认是1K--memory-total-size=SIZE total size of data to transfer [100G] 传输数据的总大小。默认是100G--memory-scope=STRING memory access scope &#123;global,local&#125; [global] 内存访问范围&#123;global,local&#125;。默认是global--memory-oper=STRING type of memory operations &#123;read, write, none&#125; [write] 内存操作类型。&#123;read, write, none&#125; 默认是write--memory-access-mode=STRING memory access mode &#123;seq,rnd&#125; [seq] 存储器存取方式&#123;seq,rnd&#125; 默认是seq sysbench threads help 123456sysbench threads helpsysbench 1.0.7 (using bundled LuaJIT 2.1.0-beta2)threads options: --thread-yields=N number of yields to do per request [1000] 每个请求产生多少个线程。默认是1000 --thread-locks=N number of locks per thread [8] 每个线程的锁的数量。默认是8 sysbench mutex help 1234567sysbench mutex helpsysbench 1.0.7 (using bundled LuaJIT 2.1.0-beta2)mutex options: --mutex-num=N total size of mutex array [4096] 数组互斥的总大小。默认是4096 --mutex-locks=N number of mutex locks to do per thread [50000] 每个线程互斥锁的数量。默认是50000 --mutex-loops=N number of empty loops to do outside mutex lock [10000] 内部互斥锁的空循环数量。默认是10000 1234567891011121314151617181920212223242526272829303132333435363738394041[root@localhost ~]# sysbench --test=cpu helpsysbench 1.0.7 (using bundled LuaJIT 2.1.0-beta2)cpu options: --cpu-max-prime=N upper limit for primes generator [10000][root@localhost ~]# sysbench fileio helpsysbench 1.0.7 (using bundled LuaJIT 2.1.0-beta2)fileio options: --file-num=N number of files to create [128] --file-block-size=N block size to use in all IO operations [16384] --file-total-size=SIZE total size of files to create [2G] --file-test-mode=STRING test mode &#123;seqwr, seqrewr, seqrd, rndrd, rndwr, rndrw&#125; --file-io-mode=STRING file operations mode &#123;sync,async,mmap&#125; [sync] --file-async-backlog=N number of asynchronous operatons to queue per thread [128] --file-extra-flags=STRING additional flags to use on opening files &#123;sync,dsync,direct&#125; [] --file-fsync-freq=N do fsync() after this number of requests (0 - don't use fsync()) [100] --file-fsync-all[=on|off] do fsync() after each write operation [off] --file-fsync-end[=on|off] do fsync() at the end of test [on] --file-fsync-mode=STRING which method to use for synchronization &#123;fsync, fdatasync&#125; [fsync] --file-merged-requests=N merge at most this number of IO requests if possible (0 - don't merge) [0] --file-rw-ratio=N reads/writes ratio for combined test [1.5][root@localhost ~]# sysbench memory helpsysbench 1.0.7 (using bundled LuaJIT 2.1.0-beta2)memory options: --memory-block-size=SIZE size of memory block for test [1K] --memory-total-size=SIZE total size of data to transfer [100G] --memory-scope=STRING memory access scope &#123;global,local&#125; [global] --memory-hugetlb[=on|off] allocate memory from HugeTLB pool [off] --memory-oper=STRING type of memory operations &#123;read, write, none&#125; [write] --memory-access-mode=STRING memory access mode &#123;seq,rnd&#125; [seq][root@localhost ~]# sysbench threads helpsysbench 1.0.7 (using bundled LuaJIT 2.1.0-beta2)threads options: --thread-yields=N number of yields to do per request [1000] --thread-locks=N number of locks per thread [8] 参考sysbench 安装、使用和测试 https://github.com/akopytov/sysbench]]></content>
      <categories>
        <category>MySQL</category>
        <category>性能测试</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>sysbench</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rmdir命令]]></title>
    <url>%2F2017%2F05%2F20%2FLinux%2F%E6%AF%8F%E5%A4%A9%E4%B8%80%E4%B8%AALinux%E5%91%BD%E4%BB%A4%2Frmdir%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[摘要: rmdir (Remove Directory删除目录): 用来删除空目录 1、命令简介rmdir (Remove Directory删除目录): 用来删除空目录，删除某目录时也必须具有对父目录的写权限。 2、用法1用法：rmdir [选项]... 目录... 3、选项123--ignore-fail-on-non-empty 忽略仅由目录非空产生的所有错误-p, –parents 删除指定目录及其上级文件夹，例如"rmdir -p a/b/c'" 与"rmdir a/b/c a/b a'" 基本相同-v, –verbose 输出处理的目录详情 4、实例实例1：删除一个空目录1[root@oracledb study]# rmdir dir1 实例2：删除空目录显示信息12[root@oracledb study]# rmdir -v dir3rmdir: 正在删除目录 "dir3" 实例3：删除一个非空目录123[root@oracledb study]# rmdir -v dir2rmdir: 正在删除目录 "dir2"rmdir: 删除 "dir2" 失败: 目录非空 实例4：若父目录为空，则递归删除父目录1234[root@oracledb study]# rmdir -pv dir1/sub1/sub2rmdir: 正在删除目录 "dir1/sub1/sub2"rmdir: 正在删除目录 "dir1/sub1"rmdir: 正在删除目录 "dir1"]]></content>
      <categories>
        <category>Linux</category>
        <category>每天一个Linux命令</category>
      </categories>
      <tags>
        <tag>每天一个Linux命令</tag>
        <tag>rmdir</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mkdir命令]]></title>
    <url>%2F2017%2F05%2F19%2FLinux%2F%E6%AF%8F%E5%A4%A9%E4%B8%80%E4%B8%AALinux%E5%91%BD%E4%BB%A4%2Fmkdir%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[摘要: mkdir(Make Directory 创建目录): 若指定目录不存在则创建目录。 1、命令简介mkdir (Make Directory 创建目录): 若指定目录不存在则创建目录。在创建目录时，要求创建目录的用户具有写权限，并应保证新建的目录没有重名。 2、用法1用法：mkdir [选项]... 目录... 3、选项1234-m, --mode=模式 设置权限模式(类似chmod)，而不是rwxrwxrwx 减umask-p, --parents 需要时创建目标目录的上层目录，但即使这些目录已存在也不当作错误处理-v, --verbose 每次创建新目录都显示信息-Z, --context=CTX 将每个创建的目录的SELinux 安全环境设置为CTX 4、实例实例1：创建一个空目录123[root@oracledb study]# mkdir dir1[root@oracledb study]# lsdir1 实例2：一次创建多个目录123[root@oracledb study]# mkdir dir1 dir2 dir3[root@oracledb study]# lsdir1 dir2 dir3 实例3：递归创建多个目录12345678[root@oracledb study]# mkdir -p dir1/sub1/sub2[root@oracledb study]# tree.└── dir1 └── sub1 └── sub23 directories, 0 files 实例4：创建权限为755的目录123[root@oracledb study]# mkdir -m 755 dir1[root@oracledb study]# lsdrwxr-xr-x 2 root root 4096 4月 16 15:03 dir1 实例5：创建新目录都显示信息12[root@oracledb study]# mkdir -v dir3mkdir: 已创建目录 "dir3" 实例6：一个命令创建项目的目录结构123456789101112131415161718192021[root@oracledb study]# mkdir -vp tomcat/&#123;bin,lib,conf,logs,webapps/&#123;examples,docs&#125;,work&#125;mkdir: 已创建目录 "tomcat"mkdir: 已创建目录 "tomcat/bin"mkdir: 已创建目录 "tomcat/lib"mkdir: 已创建目录 "tomcat/conf"mkdir: 已创建目录 "tomcat/logs"mkdir: 已创建目录 "tomcat/webapps"mkdir: 已创建目录 "tomcat/webapps/examples"mkdir: 已创建目录 "tomcat/webapps/docs"mkdir: 已创建目录 "tomcat/work"[root@oracledb study]# tree.└── tomcat ├── bin ├── conf ├── lib ├── logs ├── webapps │ ├── docs │ └── examples └── work]]></content>
      <categories>
        <category>Linux</category>
        <category>每天一个Linux命令</category>
      </categories>
      <tags>
        <tag>每天一个Linux命令</tag>
        <tag>mkdir</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Playbook 角色(Roles) 和 Include 语句]]></title>
    <url>%2F2017%2F05%2F18%2F%E8%BF%90%E7%BB%B4%E7%9B%B8%E5%85%B3%2FAnsible%2FPlaybook%20%E8%A7%92%E8%89%B2(Roles)%20%E5%92%8C%20Include%20%E8%AF%AD%E5%8F%A5%2F</url>
    <content type="text"><![CDATA[简介当我们刚开始学习运用 playbook 时，可能会把 playbook 写成一个很大的文件，到后来可能你会希望这些文件是可以方便去重用的，所以需要重新去组织这些文件。 Include 语句基本上，使用 include 语句引用 task 文件的方法，可允许你将一个配置策略分解到更小的文件中。使用 include 语句引用 tasks 是将 tasks 从其他文件拉取过来。因为 handlers 也是 tasks，所以你也可以使用 include 语句去引用 handlers 文件。 Playbook 同样可以使用 include 引用其他 playbook 文件中的 play。这时被引用的 play 会被插入到当前的 playbook 中，当前的 playbook 中就有了一个更长的的 play 列表。Include 指令看起来像下面这样，在一个 playbook 中，Include 指令可以跟普通的 task 混合在一起使用: 123tasks: - include: tasks/foo.yml 你也可以给 include 传递变量。我们称之为 ‘参数化的 include’。 12tasks: - include: wordpress.yml wp_user=timmy Playbook 角色(Roles)那怎样组织 playbook 才是最好的方式呢？简单的回答就是：使用 roles ! Roles 的概念来自于这样的想法：通过 include 包含文件并将它们组合在一起，组织成一个简洁、可重用的抽象对象。这种方式可使你将注意力更多地放在大局上，只有在需要时才去深入了解细节。Roles 基于一个已知的文件结构，去自动的加载某些 vars_files，tasks 以及 handlers。基于 roles 对内容进行分组，使得我们可以容易地与其他用户分享 roles 。 这个 playbook 为一个角色 ‘x’ 指定了如下的行为： 如果 roles/x/tasks/main.yml 存在, 其中列出的 tasks 将被添加到 play 中 如果 roles/x/handlers/main.yml 存在, 其中列出的 handlers 将被添加到 play 中 如果 roles/x/vars/main.yml 存在, 其中列出的 variables 将被添加到 play 中 如果 roles/x/meta/main.yml 存在, 其中列出的 “角色依赖” 将被添加到 roles 列表中 (1.3 and later) 所有 copy tasks 可以引用 roles/x/files/ 中的文件，不需要指明文件的路径。 所有 script tasks 可以引用 roles/x/files/ 中的脚本，不需要指明文件的路径。 所有 template tasks 可以引用 roles/x/templates/ 中的文件，不需要指明文件的路径。 所有 include tasks 可以引用 roles/x/tasks/ 中的文件，不需要指明文件的路径。 角色依赖(Role Dependencies)“角色依赖” 使你可以自动地将其他 roles 拉取到现在使用的 role 中。”角色依赖” 保存在 roles 目录下的 meta/main.yml 文件中。这个文件应包含一列 roles 和 为之指定的参数，]]></content>
      <categories>
        <category>运维相关</category>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible Playbook]]></title>
    <url>%2F2017%2F05%2F17%2F%E8%BF%90%E7%BB%B4%E7%9B%B8%E5%85%B3%2FAnsible%2FAnsilbe%20Playbook%2F</url>
    <content type="text"><![CDATA[Playbooks 是 Ansible的配置,部署,编排语言.他们可以被描述为一个需要希望远程主机执行命令的方案,或者一组IT程序运行的命令集合. Playbooks 的格式是YAML 语法做到最小化,意在避免 playbooks 成为一种编程语言或是脚本 playbook 由一个或多个 ‘plays’ 组成.它的内容是一个以 ‘plays’ 为元素的列表.play 的内容,被称为 tasks,即任务.在基本层次的应用中,一个任务是一个对 ansible 模块的调用。playbook命令根据自上而下的顺序依次执行。‘plays’ 好似音符,playbook 好似由 ‘plays’ 构成的曲谱,通过 playbook,可以编排步骤进行多机器的部署,比如在 webservers 组的所有机器上运行一定的步骤, 然后在 database server 组运行一些步骤,最后回到 webservers 组,再运行一些步骤,诸如此类.使得你可以实现一些复杂的部署机制,这是ansible命令无法实现的。 playbook通过ansible-playbook命令使用,它的参数和ansible命令类似,ansible-playbook的简单使用方法: 1ansible-playbook example-play.yml 一、一个简单的示例下面是一个简单的ansible-playbook示例，可以了解其构成: 123456789101112131415161718---- hosts: webservers vars: http_port: 80 max_clients: 200 remote_user: root tasks: - name: ensure apache is at the latest version yum: pkg=httpd state=latest - name: write the apache config file template: src=/srv/httpd.j2 dest=/etc/httpd.conf notify: - restart apache - name: ensure apache is running service: name=httpd state=started handlers: - name: restart apache service: name=httpd state=restarted 二、playbook的构成playbook 由一个或多个 ‘plays’ 组成.它的内容是一个以 ‘plays’ 为元素的列表.play 的内容,被称为 tasks,即任务.在基本层次的应用中,一个任务是一个对 ansible 模块的调用。将多个play组织在一个playbook中即可以让它们联同起来按事先编排的机制同唱一台大戏。其主要有以下四部分构成: 12345playbooks组成： Target section： 定义将要执行 playbook 的远程主机组 Variable section： 定义 playbook 运行时需要使用的变量 Task section： 定义将要在远程主机上执行的任务列表 Handler section： 定义 task 执行完成以后需要调用的任务 而其对应的目录层为五个，如下： 123456一般所需的目录层有：(视情况可变化) vars 变量层 tasks 任务层 handlers 触发条件 files 文件 template 模板 1、Hosts和Usersplaybook中的每一个play的目的都是为了让某个或某些主机以某个指定的用户身份执行任务。 hosts：用于指定要执行指定任务的主机其可以是一个或多个由冒号分隔主机组。 remote_user ：用于指定远程主机上的执行任务的用户。不过remote_user也可用于各task中。也可以通过指定其通过sudo的方式在远程主机上执行任务其可用于play全局或某任务。此外甚至可以在sudo时使用sudo_user指定sudo时切换的用户。 user：于remote_user相同 sudo：如果设置为yes，执行该任务组的用户在执行任务的时候，获取root权限 sudo_user：如果设置user为breeze，sudo为yes，sudo_user为bernie时，则breeze用户在执行任务时会获得bernie用户的权限 gather_facts：除非明确说明不需要在远程主机上执行setup模块，否则默认自动执行。如果确实不需要setup模块传递过来的变量，则可以将该选项设置为False 2、任务列表和actionplay的主体部分是任务列表。任务列表中的各任务按次序逐个在hosts中指定的所有主机上执行即在所有主机上完成第一个任务后再开始第二个。在自上而下运行某playbook时如果中途发生错误，所有已执行任务都将回滚因此在更正playbook后重新执行一次即可。 ​ task的目的是使用指定的参数执行模块，而在模块参数中可以使用变量。模块执行是幂等的，这意味着多次执行是安全的，因为其结果均一致。module 具有”幂等”性,所以当远端系统被人改动时,可以重放 playbooks 达到恢复的目的. playbooks 本身可以识别这种改动,并且有一个基本的 event system（事件系统）,可以响应这种改动. 每个task都应该有其name用于playbook的执行结果输出，建议其内容尽可能清晰地描述任务执行步骤。如果未提供name则action的结果将用于输出。 123tasks: - name: make sure apache is running service: name=httpd state=running 如果命令或脚本的退出码不为零可以使用如下方式替代 123tasks: - name: run this command and ignore the result shell: /usr/bin/somecommand || /bin/true 使用ignore_errors来忽略错误信息 1234tasks: - name: run this command and ignore the result shell: /usr/bin/somecommand ignore_errors: True 3、handlers： 在发生改变时执行的操作“notify”这个action可用于在每个play的最后被触发，这样可以避免多次有改变发生时每次都执行指定的操作，取而代之仅在所有的变化发生完成后一次性地执行指定操作。在notify中列出的操作称为handler也即notify中调用handler中定义的操作。 注意：在notify中定义内容一定要和tasks中定义的 - name 内容一样，这样才能达到触发的效果，否则会不生效。 12345- name: template configuration file template: src=template.j2 dest=/etc/foo.conf notify: - restart memcached - restart apache 123456#handler是task列表这些task与前述的task并没有本质上的不同。handlers: - name: restart memcached service: name=memcached state=restarted - name: restart apache service: name=apache state=restarted 4、tagstags用于让用户选择运行或略过playbook中的部分代码。ansible具有幂等性，因此会自动跳过没有变化的部分，即便如此，有些代码为测试其确实没有发生变化的时间依然会非常地长。此时如果确信其没有变化就可以通过tags跳过这些代码片断。 三、列出影响的主机在执行一个 playbook 之前,想看看这个 playbook 的执行会影响到哪些 hosts,你可以这样做: 1ansible-playbook playbook.yml --list-hosts 执行一个 playbook如何运行一个 playbook 呢？这很简单,这里的示例是并行的运行 playbook,并行的级别 是10 1ansible-playbook playbook.yml -f 10]]></content>
      <categories>
        <category>运维相关</category>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ad-hoc命令]]></title>
    <url>%2F2017%2F05%2F16%2F%E8%BF%90%E7%BB%B4%E7%9B%B8%E5%85%B3%2FAnsible%2FAd-hoc%E4%B8%8E%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[本文主要介绍了ansible的Ad-hoc命令。 Ansible提供两种方式去完成任务,一是 ad-hoc 命令,一是写 Ansible playbook.前者可以解决一些简单的任务, 后者解决较复杂的任务. ad-hoc 是相对于写 Ansible playbook 来说的.类似于在命令行敲入shell命令和 写shell scripts两者之间的关系。 Ad-Hoc 是指ansible下临时执行的一条命令，并且不需要保存的命令，对于复杂的命令会使用playbook。那我们会在什么情境下去使用ad-hoc 命令呢?比如说因为圣诞节要来了,想要把所有实验室的电源关闭,我们只需要执行一行命令 就可以达成这个任务,而不需要写 playbook 来做这个任务.至于说做配置管理或部署这种事,还是要借助 playbook 来完成,即使用 ‘/usr/bin/ansible-playbook’ 这个命令. Ad-hoc的执行依赖于模块，ansible官方提供了大量的模块。 如：command、raw、shell、file、cron等，具体可以通过ansible-doc -l 进行查看 。 一、Ad-hoc命令1.1、命令格式说明一个ad-hoc命令的执行，需要按以下格式进行执行： 1ansible 主机或组 -m 模块名 -a '模块参数' ansible参数 主机和组，是在/etc/ansible/hosts 里进行指定的部分，当然动态Inventory 使用的是脚本从外部应用里获取的主机； 模块名，可以通过ansible-doc -l 查看目前安装的模块，默认不指定时，使用的是command模块，具体可以查看/etc/ansible/ansible.cfg 的module_name = command 部分，默认模块可以在该配置文件中进行修改； 模块参数，可以通过 “ansible-doc -s 模块名” 查看具体的用法及后面的参数； ansible参数，可以通过ansible命令的帮助信息里查看到，这里有很多参数可以供选择，如是否需要输入密码、是否sudo等。 123456ansible all -m pingansible all -m command -a 'uptime'ansible all -m yum -a 'name=nginx state=latest'ansible all -m service -a "name=nginx state=started enabled=yes“ansible all -m shell -a 'systemctl status nginx'ansible all -m shell -a 'systemctl list-unit-files|grep nginx' 1.2、后台执行当命令执行时间比较长时，也可以放到后台执行，使用-B、-P参数，如下： 123ansible all -B 3600 -a "/usr/bin/long_running_operation --do-stuff" #后台执行命令3600s，-B 表示后台执行的时间, 命令会返回一个jidansible all -m async_status -a "jid=123456789" #检查任务的状态ansible all -B 1800 -P 60 -a "/usr/bin/long_running_operation --do-stuff" #后台执行命令最大时间是1800s即30分钟，-P 每60s检查下状态，默认15s 1.3、查看所有模块12[root@ansible ~]# ansible-doc -l |wc -l773 二、使用ansible-doc 查看模块使用方法可以使用ansible-doc -s module来查看某个模块的参数，也可以使用ansible-doc help module来查看该模块更详细的信息。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546[root@ansible ansible]# ansible-doc command&gt; COMMAND The [command] module takes the command name followed by a list of space-delimited arguments. The given command will be executed on all selected nodes. It will not be processed through the shell, so variables like `$HOME' and operations like `"&lt;"', `"&gt;"', `"|"', `";"' and `"&amp;"' will not work (use the [shell] module if you need these features).Options (= is mandatory):- chdir cd into this directory before running the command [Default: None]- creates a filename or (since 2.0) glob pattern, when it already exists, this step will *not* be run. [Default: None]- executable change the shell used to execute the command. Should be an absolute path to the executable. [Default: None]= free_form the command module takes a free form command to run. There is no parameter actually named 'free form'. See the examples! [Default: None]- removes a filename or (since 2.0) glob pattern, when it does not exist, this step will *not* be run. [Default: None]- warn if command warnings are on in ansible.cfg, do not warn about this particular line if set to no/false. [Default: True]Notes: * If you want to run a command through the shell (say you are using `&lt;', `&gt;', `|', etc), you actually want the [shell] module instead. The [command] module is much more secure as it's not affected by the user's environment. * `creates', `removes', and `chdir' can be specified after the command. For instance, if you only want to run a command if a certain file does not exist, use this.EXAMPLES:# Example from Ansible Playbooks.- command: /sbin/shutdown -t now# Run the command if the specified file does not exist.- command: /usr/bin/make_database.sh arg1 arg2 creates=/path/to/database# You can also use the 'args' form to provide the options. This command# will change the working directory to somedir/ and will only run when# /path/to/database doesn't exist.- command: /usr/bin/make_database.sh arg1 arg2 args: chdir: somedir/ creates: /path/to/database 三、命令执行模块命令执行模块包含如下 四个模块： command模块：该模块通过-a跟上要执行的命令可以直接执行 shell 模块：用法基本和command一样，不过其是通过/bin/sh进行执行，所以shell 模块可以执行任何命令，就像在本机执行一样； raw模块：用法和shell 模块一样 ，其也可以执行任意命令，就像在本机执行一样； script模块：其是将管理端的shell 在被管理主机上执行，其原理是先将shell 复制到远程主机，再在远程主机上执行，原理类似于raw模块。 注：raw模块和comand、shell 模块不同的是其没有chdir、creates、removes参数，chdir参数的作用就是先切到chdir指定的目录后，再执行后面的命令，这在后面很多模块里都会有该参数 。]]></content>
      <categories>
        <category>运维相关</category>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible参数配置文件ansible.cfg]]></title>
    <url>%2F2017%2F05%2F15%2F%E8%BF%90%E7%BB%B4%E7%9B%B8%E5%85%B3%2FAnsible%2FAnsible%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6ansible.cfg%2F</url>
    <content type="text"><![CDATA[Ansible默认安装好后有一个配置文件/etc/ansible/ansible.cfg，该配置文件中定义了ansible的主机的默认配置部分，如默认是否需要输入密码、是否开启sudo认证、action_plugins插件的位置、hosts主机组的位置、是否开启log功能、默认端口、key文件位置等等。 Ansible的一些的设置可以通过配置文件完成.在大多数场景下默认的配置就能满足大多数用户的需求,在一些特殊场景下,用户还是需要自行修改这些配置文件。 用户可以修改一下配置文件来修改设置,他们的被读取的顺序如下: 1234* ANSIBLE_CONFIG (一个环境变量)* ansible.cfg (位于当前目录中)* .ansible.cfg (位于家目录中)* /etc/ansible/ansible.cfg Ansible 将会按以上顺序逐个查询这些文件,直到找到一个为止,并且使用第一个寻找到个配置文件的配置,这些配置将不会被叠加. ask_pass 这个可以控制,Ansible 剧本playbook 是否会自动默认弹出弹出密码.默认为no:: ask_pass=True 如果使用SSH 密钥匙做身份认证.可能需要修改这一参数 ask_sudo_pass类似 ask_pass,用来控制Ansible playbook 在执行sudo之前是否询问sudo密码.默认为no: 1ask_sudo_pass=True 如果用户使用的系统平台开启了sudo 密码的话,应该开绿这一参数 forks这个选项设置在与主机通信时的默认并行进程数.从Ansible 1.3开始,fork数量默认自动设置为主机数量或者潜在的主机数量, 这将直接控制有多少网络资源活着cpu可以被使用.很多用户把这个设置为50,有些设置为500或者更多.如果你有很多的主机, 高数值将会使得跨主机行为变快.默认值比较保守: 1_forks=5 gathering1.6版本中的新特性,这个设置控制默认facts收集（远程系统变量）. 默认值为’implicit’, 每一次play,facts都会被手机,除非设置’gather_facts: False’. 选项‘explicit’正好相反,facts不会被收集,直到play中需要. ‘smart’选项意思是,没有facts的新hosts将不会被扫描, 但是如果同样一个主机,在不同的plays里面被记录地址,在playbook运行中将不会通信.这个选项当有需求节省fact收集时比较有用. inventory这个事默认库文件位置,脚本,或者存放可通信主机的目录: 1inventory = /etc/ansible/hosts log_path如果出现在ansible.cfg文件中.Ansible 将会在选定的位置登陆执行信息.请留意用户运行的Ansible对于logfile有权限: 1log_path=/var/log/ansible.log 这个特性不是默认开启的.如果不设置,ansible将会吧模块加载纪录在系统日志系统中.不包含用密码. 对于需要了解更多日志系统的企业及用户,你也许对:doc:tower 感兴趣. module_name这个是/usr/bin/ansible的默认模块名（-m）. 默认是’command’模块. 之前提到过,command模块不支持shell变量,管道,配额. 所以也许你希望把这个参数改为’shell’: 1module_name = command poll_interval对于Ansible中的异步任务(详见 异步操作和轮询）, 这个是设置定义,当具体的poll interval 没有定义时,多少时间回查一下这些任务的状态, 默认值是一个折中选择15秒钟.这个时间是个回查频率和任务完成叫回频率和当任务完成时的回转频率的这种: 1poll_interval=15 private_key_file如果你是用pem密钥文件而不是SSH 客户端或秘密啊认证的话,你可以设置这里的默认值,来避免每一次提醒设置密钥文件位置–ansible-private-keyfile: 1private_key_file=/path/to/file.pem remote_port这个设置是你系统默认的远程SSH端口,如果不指定,默认为22号端口: 1remote_port = 22 remote_tmpAnsible 通过远程传输模块到远程主机,然后远程执行,执行后在清理现场.在有些场景下,你也许想使用默认路径希望像更换补丁一样使用, 这时候你可以使用这个选项.: 1remote_tmp = $HOME/.ansible/tmp 默认路径是在用户家目录下属的目录.Ansible 会在这个目录中使用一个随机的文件夹名称. remote_user这是个ansible使用/usr/bin/ansible-playbook链接的默认用户名. 注意如果不指定,/usr/bin/ansible默认使用当前用户名称: 1remote_user = root roles_pathroles 路径指的是’roles/’下的额外目录,用于playbook搜索Ansible roles.比如, 如果我们有个用于common roles源代码控制仓库和一个不同的 playbooks仓库,你也许会建立一个惯例去在 /opt/mysite/roles 里面查找roles.: 1roles_path = /opt/mysite/roles 多余的路径可以用冒号分隔,类似于其他path字符串: 1roles_path = /opt/mysite/roles:/opt/othersite/roles Roles将会在playbook目录中开始搜索.如果role没有找到,这个参数指定了其它可能的搜索路径. sudo_user这个是sudo使用的默认用户,如果–sudo-user 没有特指或者’sudo_user’ 在Ansible playbooks中没有特指,在大多数的逻辑中 默认为: ‘root’ 1sudo_user=root timeout这个事默认SSH链接尝试超市时间: 1timeout = 10 vault_password_fileNew in version 1.7. 这个用来设置密码文件,也可以通过命令行指定–vault-password-file: 1vault_password_file = /path/to/vault_password_file 在1.7版本中,这个文件也可以称为一个脚本的形式.如果你使用脚本而不是单纯文件的话,请确保它可以执行并且密码可以在标准输出上打印出来.如果你的脚本需要提示请求数据,请求将会发到标准错误输出中. record_host_keys默认设置会记录并验证通过在用户hostfile中新发现的的主机（如果host key checking 被激活的话）. 这个选项在有很多主机的时候将会性能很差.在 这种情况下,建议使用SSH传输代替. 当设置为False时, 性能将会提升,在hostkey checking 被禁用时候,建议使用.: 1record_host_keys=True host_key_checking如果有台被管节点重新安装系统并在known_hosts中有了与之前不同的密钥信息，就会提示一个密钥不匹配的错误信息，直到被纠正为止，在使用Ansible时，如果有台被管理节点没有在known_hosts中被初始化，将会在使用Ansible或定时执行Ansible时提示对key信息的确认。如果你不想出现这种情况，并且你明白禁用此项行为的含义，只要修改该参数为False即可 1host_key_checking=True]]></content>
      <categories>
        <category>运维相关</category>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible主机清单Inventory文件hosts]]></title>
    <url>%2F2017%2F05%2F14%2F%E8%BF%90%E7%BB%B4%E7%9B%B8%E5%85%B3%2FAnsible%2FAnsible%E4%B8%BB%E6%9C%BA%E6%B8%85%E5%8D%95Inventory%E6%96%87%E4%BB%B6hosts%2F</url>
    <content type="text"><![CDATA[Ansible 通过读取默认的主机清单配置,可以同时连接到多个远程主机上执行任务组和主机之间的关系通过 inventory 文件配置. 默认的文件路径为 /etc/ansible/hosts。默认路径可以通过修改 ansible.cfg 的 hostfile 参数指定路径。 除默认文件外,你还可以同时使用多个 inventory 文件(后面会讲到),也可以从动态源,或云上拉取 inventory 配置信息.详见 动态 Inventory. 1.主机与组/etc/ansible/hosts 文件的格式与windows的ini配置文件类似: 12345678910mail.example.com[webservers]foo.example.combar.example.com[dbservers]one.example.comtwo.example.comthree.example.com 方括号[]中是组名,用于对系统进行分类,便于对不同系统进行个别的管理.可以根据自己的需求将庞大的主机分成具有标识的组，如上面分了两个组webservers和dbservers组； 一个主机可以属于不同的组,比如一台服务器可以同时属于 webserver组 和 dbserver组.这时属于两个组的变量都可以为这台主机所用, 如果有主机的SSH端口不是标准的22端口,可在主机名之后加上端口号,用冒号分隔. 1badwolf.example.com:5309 4.假设你有一些静态IP地址,希望设置一些别名,但不是在系统的 host 文件中设置,那么可以设置如下: 1jumper ansible_ssh_port=5555 ansible_ssh_host=192.168.1.50 可以按照范围指定主机，一组相似的 hostname , 可简写如下: 12345[webservers]www[01:50].example.com[databases]db-[a:f].example.com 2.主机变量前面已经提到过,分配变量给主机很容易做到,这些变量定义后可在 playbooks 中使用: 对于每一个 host,你还可以选择连接类型和连接用户名: 12345[targets]localhost ansible_connection=localother1.example.com ansible_connection=ssh ansible_ssh_user=mpdehaanother2.example.com ansible_connection=ssh ansible_ssh_user=mdehaan 定义其他变量 123[atlanta]host1 http_port=80 maxRequestsPerChild=808host2 http_port=303 maxRequestsPerChild=909 3.组的变量也可以定义属于整个组的变量，应用到组内的所有成员： 1234567[atlanta]host1host2[atlanta:vars]ntp_server=ntp.atlanta.example.comproxy=proxy.atlanta.example.com 上面atlanta组中包含两台主机，通过对atlanta组指定vars变更，相应的host1和host2相当于相应的指定了ntp_server和proxy变量参数值 。 4.把一个组作为另一个组的子成员可以把一个组作为另一个组的子成员,以及分配变量给整个组使用. 这些变量可以给 /usr/bin/ansible-playbook 使用,但不能给 /usr/bin/ansible 使用: 1234567891011121314151617181920212223[atlanta]host1host2[raleigh]host2host3[southeast:children]atlantaraleigh[southeast:vars]some_server=foo.southeast.example.comhalon_system_timeout=30self_destruct_countdown=60escape_pods=2[usa:children]southeastnortheastsouthwestnorthwest 5、分文件定义 Host 和 Group 变量在 inventory 主文件中保存所有的变量并不是最佳的方式.还可以保存在独立的文件中,这些独立文件与 inventory 文件保持关联. 不同于 inventory 文件(INI 格式),这些独立文件的格式为 YAML.详见 YAML 语法 . 假设 inventory 文件的路径为: 1/etc/ansible/hosts 假设有一个主机名为 ‘foosball’, 主机同时属于两个组,一个是 ‘raleigh’, 另一个是 ‘webservers’. 那么以下配置文件(YAML 格式)中的变量可以为 ‘foosball’ 主机所用.依次为 ‘raleigh’ 的组变量,’webservers’ 的组变量,’foosball’ 的主机变量: 123/etc/ansible/group_vars/raleigh/etc/ansible/group_vars/webservers/etc/ansible/host_vars/foosball 6.Inventory 参数的说明如同前面提到的,通过设置下面的参数,可以控制 ansible 与远程主机的交互方式,其中一些我们已经讲到过: 1234567891011121314151617181920212223242526272829303132ansible_ssh_host 将要连接的远程主机名.与你想要设定的主机的别名不同的话,可通过此变量设置.ansible_ssh_port ssh端口号.如果不是默认的端口号,通过此变量设置.ansible_ssh_user 默认的 ssh 用户名ansible_ssh_pass ssh 密码(这种方式并不安全,我们强烈建议使用 --ask-pass 或 SSH 密钥)ansible_sudo_pass sudo 密码(这种方式并不安全,我们强烈建议使用 --ask-sudo-pass)ansible_sudo_exe (new in version 1.8) sudo 命令路径(适用于1.8及以上版本)ansible_connection 与主机的连接类型.比如:local, ssh 或者 paramiko. Ansible 1.2 以前默认使用 paramiko.1.2 以后默认使用 'smart','smart' 方式会根据是否支持 ControlPersist, 来判断'ssh' 方式是否可行.ansible_ssh_private_key_file ssh 使用的私钥文件.适用于有多个密钥,而你不想使用 SSH 代理的情况.ansible_shell_type 目标系统的shell类型.默认情况下,命令的执行使用 'sh' 语法,可设置为 'csh' 或 'fish'.ansible_python_interpreter 目标主机的 python 路径.适用于的情况: 系统中有多个 Python, 或者命令路径不是"/usr/bin/python",比如 \*BSD, 或者 /usr/bin/python 不是 2.X 版本的 Python.我们不使用 "/usr/bin/env" 机制,因为这要求远程用户的路径设置正确,且要求 "python" 可执行程序名不可为 python以外的名字(实际有可能名为python26). 与 ansible_python_interpreter 的工作方式相同,可设定如 ruby 或 perl 的路径.... 7.一个主机文件的例子:12345678910111213141516171819202122232425262728293031323334353637383940414243# This is the default ansible 'hosts' file.## It should live in /etc/ansible/hosts## - Comments begin with the '#' character# - Blank lines are ignored# - Groups of hosts are delimited by [header] elements# - You can enter hostnames or ip addresses# - A hostname/ip can be a member of multiple groups# Ex 1: Ungrouped hosts, specify before any group headers.## green.example.com## blue.example.com## 192.168.100.1## 192.168.100.10# Ex 2: A collection of hosts belonging to the 'webservers' group## [webservers]## alpha.example.org## beta.example.org## 192.168.1.100## 192.168.1.110# If you have multiple hosts following a pattern you can specify# them like this:## www[001:006].example.com# Ex 3: A collection of database servers in the 'dbservers' group## [dbservers]## ## db01.intranet.mydomain.net## db02.intranet.mydomain.net## 10.25.1.56## 10.25.1.57# Here's another example of host ranges, this time there are no# leading 0s:## db-[99:101]-node.example.com]]></content>
      <categories>
        <category>运维相关</category>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible安装]]></title>
    <url>%2F2017%2F05%2F13%2F%E8%BF%90%E7%BB%B4%E7%9B%B8%E5%85%B3%2FAnsible%2FAnsible%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[本文主要记录了ansible的安装方法。 一、安装前准备需要安装些什么Ansible默认通过 SSH 协议管理机器.目前,只要机器上安装了 Python 2.6 或 Python 2.7 (windows系统不可以做控制主机),都可以运行Ansible. 主机的系统可以是 Red Hat, Debian, CentOS, OS X, BSD的各种版本,等等. 安装Ansible之后,不需要启动或运行一个后台进程,或是添加一个数据库.只要在一台电脑(可以是一台笔记本)上安装好,就可以通过这台电脑管理一组远程的机器.在远程被管理的机器上,不需要安装运行任何软件,因此升级Ansible版本不会有太多问题. 版本及安装方式选择?因为Ansible可以很简单的从源码运行,且不必在远程被管理机器上安装任何软件,很多Ansible用户会跟进使用开发版本. Ansible一般每两个月出一个发行版本.小bugs一般在下一个发行版本中修复,并在稳定分支中做backports.大bugs会在必要时出一个维护版本,不过这不是很频繁. 若你希望使用Ansible的最新版本,并且你使用的操作系统是 Red Hat Enterprise Linux (TM), CentOS, Fedora, Debian, Ubuntu,我们建议使用系统的软件包管理器. 另有一种选择是通过”pip”工具安装,”pip”是一个安装和管理Python包的工具. 若你希望跟进开发版本,想使用和测试最新的功能特性,我们会分享如何从源码运行Ansible的方法.从源码运行程序不需要进行软件安装. 二、安装2.1 通过Yum安装最新发布版本RHEL或CentOS用户,需要 配置 EPEL 123# install the epel-release RPM if needed on CentOS, RHEL, or Scientific Linux$ sudo yum install epel-release$ sudo yum install ansible 2.2 自己创建RPM软件包你也可以自己创建RPM软件包.在Ansible项目的checkout的根目录下,或是在一个tarball中,使用 make rpm 命令创建RPM软件包. 然后可分发这个软件包或是使用它来安装Ansible.在创建之前,先确定你已安装了 rpm-build, make, and python2-devel . 1234$ git clone git://github.com/ansible/ansible.git$ cd ./ansible$ make rpm$ sudo rpm -Uvh ~/rpmbuild/ansible-*.noarch.rpm 2.3 通过Apt (Ubuntu)安装最新发布版本配置PPA及安装ansible,执行如下命令: 1234$ sudo apt-get install software-properties-common$ sudo apt-add-repository ppa:ansible/ansible$ sudo apt-get update$ sudo apt-get install ansible 2.4 通过 Pip 安装最新发布版本Ansible可通过 “pip” 安装(安装和管理Python包的工具),若你还没有安装 pip,可执行如下命令安装: 1$ sudo easy_install pip 然后安装Ansible: 1$ sudo pip install ansible 如果你是在 OS X Mavericks 上安装,编译器可能或告警或报错,可通过如下设置避免这种情况: 1$ sudo CFLAGS=-Qunused-arguments CPPFLAGS=-Qunused-arguments pip install ansible 2.5 发行版的Tarball不想通过git checkout 创建Ansible的软件包？在这里可获取Tarball Ansible downloads 2.6 在Mac OSX 上安装最新发布版本在 Mac 上安装 ansible，最好是通过 pip 安装，参照 通过 Pip 安装最新发布版本 .]]></content>
      <categories>
        <category>运维相关</category>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初识Ansible]]></title>
    <url>%2F2017%2F05%2F12%2F%E8%BF%90%E7%BB%B4%E7%9B%B8%E5%85%B3%2FAnsible%2F%E5%88%9D%E8%AF%86Ansible%2F</url>
    <content type="text"><![CDATA[初识ansible。 Ansible是什么？官方的描述如下 1Simple, agentless and powerful open source IT automation Ansible是近年越来越火的一款基于Python开发的运维自动化工具，2012.02月出现至今，已成为排名前10的python项目。 其主要功能是帮助运维实现IT工作的自动化、降低人为操作失误、提高业务自动化率、提升运维工作效率，常用于软件部署自动化、配置自动化、管理自动化、系统化系统任务、持续集成、零宕机平滑升级等。 Ansible名字来源？Ansible名字其实是来源于作者喜欢的一本书——奥森·斯科特·卡特的《安德的游戏》，该书中Ansible是一种能跨越时空的即时通信工具，使用Ansible可以在相距数光年的距离远程实时控制前线的舰队战斗。Michael DeHaan希望借这个名词比喻控制远端大量的服务器，因此便将自己的这款产品命名为Ansible。 为什么选择Ansible？ noagents：不需要在被管控主机上安装任何客户端 noserver：无服务器daemon进程 基于SSH工作 安装简单 Redhat收购 Ansible galaxy 支持docker的模块管理 Ansible架构 Ansible没有客户端，因此底层通信依赖于系统软件，Linux系统下基于OpenSSH通信，Windows系统下基于PowerShell，管理端必须是Linux系统，使用者认证通过后在管理节点通过Ansible工具调用各应用模块将指令推送至被管理端执行，并在执行完毕后自动删除产生的临时文件。 ansible是基于模块工作的，本身没有批量部署的能力。真正具有批量部署的是ansible所运行的模块，ansible只是提供一种框架。主要包括： (1)、连接插件connectionplugins：负责和被监控端实现通信； (2)、host inventory：指定操作的主机，是一个配置文件里面定义监控的主机； (3)、各种模块核心模块、command模块、自定义模块； (4)、借助于插件完成记录日志邮件等功能； (5)、playbook：剧本执行多个任务 Ansible任务执行流程]]></content>
      <categories>
        <category>运维相关</category>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ls命令]]></title>
    <url>%2F2017%2F05%2F11%2FLinux%2F%E6%AF%8F%E5%A4%A9%E4%B8%80%E4%B8%AALinux%E5%91%BD%E4%BB%A4%2Fls%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[摘要: ls （list 列出目录内容），用来列出显示指定目录里的文件及文件夹清单，缺省下ls用来打印出当前目录的清单. 1、命令简介ls（list 列出目录内容）命令用来列出显示指定目录里的文件及文件夹清单，缺省下ls用来打印出当前目录的清单。通过ls 命令不仅可以查看linux文件夹包含的文件，而且可以查看文件权限、大小、更改时间等等 2、用法1ls [OPTION]... [FILE]... 3、选项123456789101112131415161718192021222324252627282930313233343536-a 列出目录下的所有文件，包括以 . 开头的隐含文件。-A 显示除“.”和“..”外的所有文件。 -b 把文件名中不可输出的字符用反斜杠加字符编号(就象在C语言里一样)的形式列出。 -B 不输出以“~”结尾的备份文件。-c 与“-lt”选项连用时，按照文件状态时间排序输出目录内容，排序的依据是文件的索引节点中的ctime字段。与“-l”选项连用时，则显示状态改变时间，并以名称排序；其他根据ctime排揎-C 多列显示输出结果，纵向排序，这是默认选项。--color显示彩色文件名 [always|never|auto] -d 将目录像文件一样显示，而不是显示其下的文件。 -e 输出时间的全部信息，而不是输出简略信息。 -f 此参数的效果和同时指定“aU”参数相同，并关闭“lst”参数的效果；-F 在文件名后附上一个字符以说明该文件的类型，“*”表示可执行的普通 文件；“/”表示目录；“@”表示符号链接；“|”表示FIFOs；“=”表示套接字---g 类似于-l 但是不列出owner。 -G 输出文件的组的信息。-h 和-l一起，以human-readable的格式输出大小信息-i --inode输出文件节点的索引信息。 -k 以 k 字节的形式表示文件的大小。 -l 列出文件的详细信息。 -L 列出链接文件名而不是链接到的文件。 -m 横向输出文件名，并以“，”作分格符。 -n 用数字的 UID,GID 代替名称。 -N 不限制文件长度。-o 显示文件的除组信息外的详细信息。 -p 文件夹后添加/-q 用?代替不可输出的字符。-Q 把输出的文件名用双引号括起来。 -r 对目录反向排序。 -R 列出所有子目录下的文件。-s 在每个文件名后输出该文件的大小,单位为block。-S 以文件大小排序。 -t 以时间排序。 -u 与“-lt”选项连用时，按照访问时间排序输出目录内容。与“-l”选项连用时，则显示访问时间，并以名称排序；其他根据访问时间排序-U 对输出的文件不排序。-x 按列输出，横向排序。 -X 以文件的扩展名(最后一个 . 后的字符)排序。 -1 一行只输出一个文件。 --help 在标准输出上显示帮助信息。 --version 在标准输出上输出版本信息并退出。 4、实例1. 不带任何选项列出文件 不带选项的ls命令来光秃秃地列出文件和目录，我们是不能看到像文件类型、大小、修改日期和时间、权限以及链接这样具体的信息的。 12[root@cent6 tmp]# lshsperfdata_root nginx_log_stat pulse-IhiwHnejlPBk tomcat-redis-session-manager 2. 带–l 选项列出文件列表 123456[root@cent6 tmp]# ls -ltotal 16drwxr-xr-x 2 root root 4096 Apr 9 09:01 hsperfdata_root-rw-r--r--. 1 root root 4 Mar 22 17:58 nginx_log_statdrwx------. 2 cloud cloud 4096 Feb 16 2015 pulse-IhiwHnejlPBkdrwxr-xr-x. 3 root root 4096 Feb 24 21:32 tomcat-redis-session-manager 可以看到，用ls -l命令查看某一个目录会得到一个7个字段的列表。 第1行:总计(total) Total后面的数字是指当前目录下所有文件所占用的空间总和,单位kb。可以使用ls –lh查看， 第1字段: 文件属性字段 文件属性字段总共有10个字母组成；第一个字符代表文件的类型。 1234567“-”表示该文件是一个普通文件“d”表示该文件是一个目录，字母"d"，是dirtectory(目录)的缩写“l”表示该文件是一个链接文件。字母"l"是link(链接)的缩写，类似于windows下的快捷方式“b”的表示块设备文件(block)，一般置于/dev目录下，设备文件是普通文件和程序访问硬件设备的入口，是很特殊的文件。，如硬盘、光盘等。最小数据传输单位为一个数据块(通常一个数据块的大小为512字节) 12345“c”表示该文件是一个字符设备文件(character)，一般置于/dev目录下，一次传输一个字节的设备被称为字符设备，如键盘、字符终端等，传输数据的最小单位为一个字节。“p”表示该文件为命令管道文件。与shell编程有关的文件。“s”表示该文件为sock文件。与shell编程有关的文件。 第2字段：如果是一个文件，此时这一字段表示这个文件所具有的硬链接数；如果是一个目录，则第2字段表示该目录所含子目录的个数。新建一个空目录，这个目录的第二字段就是2，表示该目录下有两个子目录。为什么新建的目录下面会有两个子目录呢?因为每一个目录都有一个指向它本身的子目录”。” 和指向它上级目录的子目录”。。”， 第3字段：文件（目录）拥有者 第4字段：文件（目录）拥有者所在的组 第5字段: 文件所占用的空间(以字节为单位) 第6字段：文件（目录）最近访问（修改）时间 第7字段：文件名 3. 计算当前目录下的文件数和目录数 1234[root@zabbix zabbix]# ls -l |grep "^d"|wc -l 3[root@zabbix zabbix]# ls -l |grep "^-"|wc -l6 4. 用 -lh 选项来以易读方式列出文件 1234[root@cent6 ~]# ls -lhtotal 16K-rwxr-xr-x. 1 root root 1.3K Feb 16 2015 anaconda-ks.cfg-rwxr-xr-x. 1 root root 9.0K Feb 16 2015 install.log.syslog 5. 浏览隐藏文件 列出所有文件包括以‘.’开头的隐藏文件。 12[root@cent6 ~]# ls -a. anaconda-ks.cfg .bash_logout .bashrc .cshrc .gconfd install.log.syslog 6. 列出目录信息 用ls -l命令列出/tmp目录下的文件，其中-ld参数可以只显示/tmp目录的信息。 12[root@cent6 ~]# ls -ld /tmpdrwxrwxrwt. 7 root root 4096 Apr 12 20:34 /tmp 7. 以尾部以‘/’字符结尾的方式列出文件和目录 使用 ls 命令的 -F 选项，会在每个目录的末尾添加“/”字符显示。 12[root@cent6 ~]# ls -Fanaconda-ks.cfg* directory/ install.log.syslog* 8. 只列出文件下的子目录 利用使用-F选项时，目录以/结尾 1234[root@zabbix zabbix]# ls -F |grep /$alertscripts/web/zabbix_agentd.d/ 利用使用-l选项时，目录以d开头 1234[root@zabbix zabbix]# ls -l |grep "^d"drwxrwxrwx 2 root root 97 Jan 28 09:23 alertscriptsdrwxr-x--- 2 apache apache 54 Feb 17 21:10 webdrwxr-xr-x 2 root root 45 Feb 17 21:10 zabbix_agentd.d 9. 按文件大小排序 带-lS组合选项能按文件从大到小的次序显示。 12345[root@cent6 ~]# ls -lStotal 20-rwxr-xr-x. 1 root root 9154 Feb 16 2015 install.log.syslogdrwxr-xr-x 2 root root 4096 Apr 12 21:25 directory-rwxr-xr-x. 1 root root 1264 Feb 16 2015 anaconda-ks.cfg 10.列出当前目录中所有以“zabbix”开头的目录和文件的详细内容 12345[root@zabbix zabbix]# ls zabbix*zabbix_agentd.conf zabbix_java_gateway.conf zabbix_java_gateway_logback.xml zabbix_server.conf zabbix_server.conf_bak zabbix_server.conf.rpmnew_bakzabbix_agentd.d:userparameter_mysql.conf 11. 倒序列出文件 ls -r 选项能以倒序方式显示文件和目录。 12[root@cent6 ~]# ls -rinstall.log.syslog directory anaconda-ks.cfg 12. 以修改时间列出，最近修改的在上面 12345[root@cent6 ~]# ls -lttotal 20drwxr-xr-x 2 root root 4096 Apr 12 21:25 directory-rwxr-xr-x. 1 root root 1264 Feb 16 2015 anaconda-ks.cfg-rwxr-xr-x. 1 root root 9154 Feb 16 2015 install.log.syslog 13. 以修改时间倒序列出 带-ltr组合选项能以文件或目录的最新修改时间的次序来显示它们。 12345[root@cent6 ~]# ls -ltrtotal 20-rwxr-xr-x. 1 root root 9154 Feb 16 2015 install.log.syslog-rwxr-xr-x. 1 root root 1264 Feb 16 2015 anaconda-ks.cfgdrwxr-xr-x 2 root root 4096 Apr 12 21:25 directory 14.指定文件时间输出格式 1234567891011[root@zabbix zabbix]# ls -lt --time-style=long-isototal 68-rw-r--r-- 1 root root 14938 2016-04-14 11:48 zabbix_server.confdrwxr-xr-x 2 root root 45 2016-02-17 21:10 zabbix_agentd.ddrwxr-x--- 2 apache apache 54 2016-02-17 21:10 web-rw-r--r-- 1 root root 10341 2016-02-16 00:16 zabbix_agentd.conf-rw-r--r-- 1 root root 813 2016-02-16 00:16 zabbix_java_gateway.conf-rw-r--r-- 1 root root 770 2016-02-16 00:16 zabbix_java_gateway_logback.xml-rw-r----- 1 root zabbix 14912 2016-02-16 00:16 zabbix_server.conf.rpmnew_bak-rw-r----- 1 root zabbix 13657 2016-02-04 10:19 zabbix_server.conf_bakdrwxrwxrwx 2 root root 97 2016-01-28 09:23 alertscripts 更详细的时间 1234567891011[root@zabbix zabbix]# ls -tl --time-style=full-isototal 68-rw-r--r-- 1 root root 14938 2016-04-14 11:48:26.231666438 +0800 zabbix_server.confdrwxr-xr-x 2 root root 45 2016-02-17 21:10:03.471004045 +0800 zabbix_agentd.ddrwxr-x--- 2 apache apache 54 2016-02-17 21:10:00.024943223 +0800 web-rw-r--r-- 1 root root 10341 2016-02-16 00:16:47.000000000 +0800 zabbix_agentd.conf-rw-r--r-- 1 root root 813 2016-02-16 00:16:47.000000000 +0800 zabbix_java_gateway.conf-rw-r--r-- 1 root root 770 2016-02-16 00:16:47.000000000 +0800 zabbix_java_gateway_logback.xml-rw-r----- 1 root zabbix 14912 2016-02-16 00:16:47.000000000 +0800 zabbix_server.conf.rpmnew_bak-rw-r----- 1 root zabbix 13657 2016-02-04 10:19:44.837012771 +0800 zabbix_server.conf_bakdrwxrwxrwx 2 root root 97 2016-01-28 09:23:44.034478732 +0800 alertscripts 15. **递归列出子目录** ls -R 选项能递归列出子目录 12345678910[root@cent6 ~]# ls -lR.:total 20-rwxr-xr-x. 1 root root 1264 Feb 16 2015 anaconda-ks.cfgdrwxr-xr-x 2 root root 4096 Apr 12 21:25 directory-rwxr-xr-x. 1 root root 9154 Feb 16 2015 install.log.syslog./directory:total 0-rw-r--r-- 1 root root 0 Apr 12 21:25 subtext.txt 16.列出当前目录下的所有文件（包括隐藏文件）的绝对路径， 对目录不做递归 1234567891011[root@zabbix zabbix]# find $PWD -maxdepth 1 | xargs ls -lddrwxr-xr-x 5 root root 4096 Apr 14 11:48 /etc/zabbixdrwxrwxrwx 2 root root 97 Jan 28 09:23 /etc/zabbix/alertscriptsdrwxr-x--- 2 apache apache 54 Feb 17 21:10 /etc/zabbix/web-rw-r--r-- 1 root root 10341 Feb 16 00:16 /etc/zabbix/zabbix_agentd.confdrwxr-xr-x 2 root root 45 Feb 17 21:10 /etc/zabbix/zabbix_agentd.d-rw-r--r-- 1 root root 813 Feb 16 00:16 /etc/zabbix/zabbix_java_gateway.conf-rw-r--r-- 1 root root 770 Feb 16 00:16 /etc/zabbix/zabbix_java_gateway_logback.xml-rw-r--r-- 1 root root 14938 Apr 14 11:48 /etc/zabbix/zabbix_server.conf-rw-r----- 1 root zabbix 13657 Feb 4 10:19 /etc/zabbix/zabbix_server.conf_bak-rw-r----- 1 root zabbix 14912 Feb 16 00:16 /etc/zabbix/zabbix_server.conf.rpmnew_bak 17.递归列出当前目录下的所有文件（包括隐藏文件）的绝对路径 123456789101112131415161718[root@zabbix zabbix]# find $PWD | xargs ls -ld drwxr-xr-x 5 root root 4096 Apr 14 11:48 /etc/zabbixdrwxrwxrwx 2 root root 97 Jan 28 09:23 /etc/zabbix/alertscripts-rwxrwxrwx 1 root root 2924 Jan 28 09:23 /etc/zabbix/alertscripts/sendim.py-rwxrwxrwx 1 root root 835 Jan 27 06:51 /etc/zabbix/alertscripts/sendmail.py-rwxrwxrwx 1 root root 611 Jan 27 06:51 /etc/zabbix/alertscripts/sendsms.sh-rwxrwxrwx 1 root root 2930 Jan 27 06:51 /etc/zabbix/alertscripts/sendwechat.pydrwxr-x--- 2 apache apache 54 Feb 17 21:10 /etc/zabbix/web-rw-r--r-- 1 root root 1036 Feb 15 20:25 /etc/zabbix/web/maintenance.inc.php-rw-r--r-- 1 apache apache 431 Jan 27 06:27 /etc/zabbix/web/zabbix.conf.php-rw-r--r-- 1 root root 10341 Feb 16 00:16 /etc/zabbix/zabbix_agentd.confdrwxr-xr-x 2 root root 45 Feb 17 21:10 /etc/zabbix/zabbix_agentd.d-rw-r--r-- 1 root root 1517 Feb 16 00:16 /etc/zabbix/zabbix_agentd.d/userparameter_mysql.conf-rw-r--r-- 1 root root 813 Feb 16 00:16 /etc/zabbix/zabbix_java_gateway.conf-rw-r--r-- 1 root root 770 Feb 16 00:16 /etc/zabbix/zabbix_java_gateway_logback.xml-rw-r--r-- 1 root root 14938 Apr 14 11:48 /etc/zabbix/zabbix_server.conf-rw-r----- 1 root zabbix 13657 Feb 4 10:19 /etc/zabbix/zabbix_server.conf_bak-rw-r----- 1 root zabbix 14912 Feb 16 00:16 /etc/zabbix/zabbix_server.conf.rpmnew_bak 18. 显示文件或目录的索引节点号 带-i选项能列出文件或目录的索引节点号。索引节点（index inode简称为“inode”）是Linux中一个特殊的概念，具有相同的索引节点号的两个文本本质上是同一个文件（除文件名不同外）。 12[root@cent6 ~]# ls -i1058854 anaconda-ks.cfg 1061385 directory 1048579 install.log.syslog 19. 显示文件的UID和GID 用ls -n命令来显示文件和目录的UID和GID（root的均为0） 12345[root@cent6 ~]# ls -ntotal 20-rwxr-xr-x. 1 0 0 1264 Feb 16 2015 anaconda-ks.cfgdrwxr-xr-x 2 0 0 4096 Apr 12 21:25 directory-rwxr-xr-x. 1 0 0 9154 Feb 16 2015 install.log.syslog 20. 水平输出文件列表，以逗号分隔 12[root@cent6 ~]# ls -manaconda-ks.cfg, directory, install.log.syslog 21. 列出文件并标记颜色分类 12[root@cent6 ~]# ls --color=autoanaconda-ks.cfg directory install.log.syslog 22.在ls中列出文件的绝对路径 12345678910[root@zabbix zabbix]# ls | sed "s:^:`pwd`/:"/etc/zabbix/alertscripts/etc/zabbix/web/etc/zabbix/zabbix_agentd.conf/etc/zabbix/zabbix_agentd.d/etc/zabbix/zabbix_java_gateway.conf/etc/zabbix/zabbix_java_gateway_logback.xml/etc/zabbix/zabbix_server.conf/etc/zabbix/zabbix_server.conf_bak/etc/zabbix/zabbix_server.conf.rpmnew_bak 23. ls命令和它的别名 我们给ls命令设置如下别名之后，当我们执行ls命令的时候它会默认执行-l选项并且像上文提到的那样显示长列表。 12alias ls="ls -l --color" unalias ls]]></content>
      <categories>
        <category>Linux</category>
        <category>每天一个Linux命令</category>
      </categories>
      <tags>
        <tag>每天一个Linux命令</tag>
        <tag>ls</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cd命令]]></title>
    <url>%2F2017%2F05%2F10%2FLinux%2F%E6%AF%8F%E5%A4%A9%E4%B8%80%E4%B8%AALinux%E5%91%BD%E4%BB%A4%2Fcd%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[摘要: cd（Change Directory 改变目录）命令用来切换工作目录至dirname。 1、作用cd（Change Directory 改变目录）命令用来切换工作目录至dirname。 其中dirName表示法可为绝对路径或相对路径。若目录名称省略，则变换至使用者的home directory(也就是刚login时所在的目录)。另外，~也表示为home directory的意思，.则是表示目前所在的目录，..则表示目前目录位置的上一层目录。 2、用法1cd (选项) (参数) 3、选项123-p 如果要切换到的目标目录是一个符号连接，直接切换到符号连接指向的目标目录-L 如果要切换的目标目录是一个符号的连接，直接切换到字符连接名代表的目录，而非符号连接所指向的目标目录。 - 当仅实用"-"一个选项时，当前工作目录将被切换到环境变量"OLDPWD"所表示的目录。每当你更改目录时，shell都会将上一个目录位置记录在环境变量OLDPWD中 4、实例1、cd 进入用户主目录；123[root@cent6 init.d]# cd[root@cent6 ~]# pwd/root 2、cd ~ 进入用户主目录；1234[root@cent6 ~]# cd ~[root@cent6 ~]# pwd/root[root@cent6 ~]# 3、cd - 返回进入此目录之前所在的目录1234567[root@cent6 ~]# pwd/root[root@cent6 ~]# cd /home[root@cent6 home]# cd -/root[root@cent6 ~]# pwd/root 4、cd .. 返回上级目录（若当前目录为“/“，则执行完后还在“/“；”..”为上级目录的意思）； 12345[root@cent6 init.d]# pwd/etc/init.d[root@cent6 init.d]# cd ..[root@cent6 etc]# pwd/etc 5、cd ../.. 返回上两级目录；12345[root@cent6 init.d]# pwd/etc/init.d[root@cent6 init.d]# cd ../..[root@cent6 /]# pwd/ 6、cd !$ 把上个命令的参数作为cd参数使用123456[root@cent6 /]# ls -ld /media/drwxr-xr-x. 2 root root 4096 Sep 23 2011 /media/[root@cent6 /]# cd !$cd /media/[root@cent6 media]# pwd/media 1select * from table]]></content>
      <categories>
        <category>Linux</category>
        <category>每天一个Linux命令</category>
      </categories>
      <tags>
        <tag>每天一个Linux命令</tag>
        <tag>cd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pwd命令]]></title>
    <url>%2F2017%2F05%2F09%2FLinux%2F%E6%AF%8F%E5%A4%A9%E4%B8%80%E4%B8%AALinux%E5%91%BD%E4%BB%A4%2Fpwd%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[摘要: pwd（print work directory 打印当前目录）命令以绝对路径的方式显示用户当前工作目录。 1、命令简介pwd（print work directory 打印当前目录）命令以绝对路径的方式显示用户当前工作目录。 2、用法1pwd [-LP] 3、选项12-L --logical 当目录为连接路径时，显示连接路径-P --physical 显示实际物理路径，而非使用连接（link）路径 4、实例4.1 显示当前目录所在路径 pwd12[root@cent6 ~]# pwd/root 4.2 显示当前目录的物理路径 pwd –P123[root@cent6 ~]# cd /etc/init.d [root@cent6 init.d]# pwd -P/etc/rc.d/init.d 4.3 显示当前目录的连接路径：pwd -L123[root@cent6 init.d]# cd /etc/init.d [root@cent6 init.d]# pwd -L/etc/init.d]]></content>
      <categories>
        <category>Linux</category>
        <category>每天一个Linux命令</category>
      </categories>
      <tags>
        <tag>每天一个Linux命令</tag>
        <tag>pwd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从已有的组复制搭建InnoDB Cluster环境]]></title>
    <url>%2F2017%2F05%2F08%2FMySQL%2FMySQL%20HA%2FInnoDB%20Cluster%2F%E4%BB%8E%E5%B7%B2%E6%9C%89%E7%9A%84%E7%BB%84%E5%A4%8D%E5%88%B6%E6%90%AD%E5%BB%BAInnoDB%20Cluster%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[本文描述了如何基于已有的MySQL Group Replication，创建一个 Innodb cluster。 1. 已有的MySQL Group Replication 环境信息 ip地址 主机名 server_id 172.17.84.71 mysql001 1 172.17.84.72 mysql002 2 172.17.84.73 mysql003 3 查看组复制当前状态 1234567mysql&gt; SELECT * FROM performance_schema.replication_group_members;+---------------------------+--------------------------------------+-------------+-------------+--------------+| CHANNEL_NAME | MEMBER_ID | MEMBER_HOST | MEMBER_PORT | MEMBER_STATE |+---------------------------+--------------------------------------+-------------+-------------+--------------+| group_replication_applier | 80af8598-1520-11e7-a8b9-08002730b4d8 | mysql001 | 3306 | ONLINE || group_replication_applier | 8abf4eab-1521-11e7-9cc9-080027b95fc4 | mysql002 | 3306 | ONLINE || group_replication_applier | dcd3068d-15bc-11e7-b264-080027dad0d6 | mysql003 | 3306 | ONLINE | 2. Yum 安装MySQL Shellwget https://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpm rpm -ivh mysql57-community-release-el7-10.noarch.rpm yum install mysql-shell -y 3. 创建cluster通过指定 adoptFromGR option，使用dba.createCluster() 12345678910mysqlsh --uri root@172.17.84.71:3306mysql-js&gt; var cluster = dba.createCluster('prodCluster', &#123;adoptFromGR: true&#125;);A new InnoDB cluster will be created on instance 'root@172.17.84.7:3306'.Creating InnoDB cluster 'prodCluster' on 'root@172.17.84.72:3306'...Adding Seed Instance...Cluster successfully created. Use Cluster.addInstance() to add MySQL instances.At least 3 instances are needed for the cluster to be able to withstand up toone server failure. 查看cluster状态 12345678910111213141516171819202122232425262728293031323334mysql-js&gt; var cluster=dba.getCluster()mysql-js&gt; cluster.status()&#123; "clusterName": "prodCluster", "defaultReplicaSet": &#123; "name": "default", "primary": "172.17.84.71:3306", "status": "OK", "statusText": "Cluster is ONLINE and can tolerate up to ONE failure.", "topology": &#123; "172.17.84.71:3306": &#123; "address": "172.17.84.71:3306", "mode": "R/W", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125;, "mysql002:3306": &#123; "address": "mysql002:3306", "mode": "R/O", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125;, "mysql003:3306": &#123; "address": "mysql003:3306", "mode": "R/O", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125; &#125; &#125;&#125; 4. 持久化配置文件对于已经在cluster中的实例，可以持久化cluster的配置 1dba.configureLocalInstance(root@localhost:3306) 查看配置文件的变化my.cnf 5.简单测试Failover关闭mysql001实例 1systemctl stop mysqld 重启mysql001实例 1systemctl start mysqld 查看cluster状态,发现Primary Master已经切换到mysql002 123456789101112131415161718192021222324252627282930313233mysql-js&gt; cluster.status()&#123; "clusterName": "prodCluster", "defaultReplicaSet": &#123; "name": "default", "primary": "172.17.84.72:3306", "status": "OK", "statusText": "Cluster is ONLINE and can tolerate up to ONE failure.", "topology": &#123; "172.17.84.72:3306": &#123; "address": "172.17.84.72:3306", "mode": "R/W", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125;, "mysql001:3306": &#123; "address": "mysql001:3306", "mode": "R/O", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125;, "mysql003:3306": &#123; "address": "mysql003:3306", "mode": "R/O", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125; &#125; &#125;&#125; 6.createCluster语法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061mysql-js&gt; dba.help(createCluster());ReferenceError: createCluster is not definedmysql-js&gt; dba.help('createCluster');Creates a MySQL InnoDB cluster.SYNTAX &lt;Dba&gt;.createCluster(name[, options])WHERE name: The name of the cluster object to be created. options: Dictionary with options that modify the behavior of this function.DESCRIPTIONCreates a MySQL InnoDB cluster taking as seed instance the active globalsession.The options dictionary can contain the next values: - clusterAdminType: defines the type of management to be done on the cluster instances. - multiMaster: boolean value used to define an InnoDB cluster with multiple writable instances. - force: boolean, confirms that the multiMaster option must be applied. - adoptFromGR: boolean value used to create the InnoDB cluster based on existing replication group. - memberSslMode: SSL mode used to configure the members of the cluster. - ipWhitelist: The list of hosts allowed to connect to the instance for group replication.The values for clusterAdminType options include: local, manual, guided or ssh,however, at the moment only local is supported and is used as default value ifthis attribute is not specified.A InnoDB cluster may be setup in two ways: - Single Master: One member of the cluster allows write operations while the rest are in read only mode. - Multi Master: All the members in the cluster support both read and write operations.By default this function create a Single Master cluster, use the multiMasteroption set to true if a Multi Master cluster is required.The memberSslMode option supports these values: - REQUIRED: if used, SSL (encryption) will be enabled for the instances to communicate with other members of the cluster - DISABLED: if used, SSL (encryption) will be disabled - AUTO: if used, SSL (encryption) will be enabled if supported by the instance, otherwise disabledIf memberSslMode is not specified AUTO will be used by default.The ipWhitelist format is a comma separated list of IP addresses or subnet CIDRnotation, for example: 192.168.1.0/24,10.0.0.1. By default the value is set toAUTOMATIC, allowing addresses from the instance private network to beautomatically set for the whitelist. 参考 Creating an InnoDB Cluster From an Existing Group Replication Deployment https://ronniethedba.wordpress.com/2017/04/23/creating-an-innodb-cluster-router-from-an-existing-group-replication-deployment/]]></content>
      <categories>
        <category>MySQL</category>
        <category>MySQL HA</category>
        <category>InnoDB Cluster</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>InnoDB Cluster</tag>
        <tag>Group Replication</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL Group Replication 部署中遇到的错误]]></title>
    <url>%2F2017%2F05%2F07%2FMySQL%2FGroup%20Replication%2FMySQL%20Group%20Replication%20%E9%83%A8%E7%BD%B2%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[本文主要描述了MySQL Group Replication 部署中遇到的错误 错误一 未设置白名单导致的无法启动group_replication错误信息1234567891011121314151617181920212223242526272017-04-24T06:23:09.971308Z 3 [Note] Plugin group_replication reported: '[GCS] Added automatically IP ranges 127.0.0.1/8 to the whitelist'2017-04-24T06:23:09.971480Z 3 [Note] Plugin group_replication reported: '[GCS] SSL was not enabled'2017-04-24T06:23:09.971513Z 3 [Note] Plugin group_replication reported: 'Initialized group communication with configuration: group_replication_group_name: "aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa"; group_replication_local_address: "172.17.84.71:33061"; group_replication_group_seeds: "172.17.84.71:33061,172.17.84.72:33061,172.17.84.73:33061"; group_replication_bootstrap_group: true; group_replication_poll_spin_loops: 0; group_replication_compression_threshold: 1000000; group_replication_ip_whitelist: "AUTOMATIC"'2017-04-24T06:23:09.972386Z 12 [Note] 'CHANGE MASTER TO FOR CHANNEL 'group_replication_applier' executed'. Previous state master_host='&lt;NULL&gt;', master_port= 0, master_log_file='', master_log_pos= 4, master_bind=''. New state master_host='&lt;NULL&gt;', master_port= 0, master_log_file='', master_log_pos= 4, master_bind=''.2017-04-24T06:23:09.982442Z 15 [Note] Slave SQL thread for channel 'group_replication_applier' initialized, starting replication in log 'FIRST' at position 0, relay log './mysql001-relay-bin-group_replication_applier.000001' position: 42017-04-24T06:23:09.982441Z 3 [Note] Plugin group_replication reported: 'Group Replication applier module successfully initialized!'2017-04-24T06:23:09.982618Z 3 [Note] Plugin group_replication reported: 'auto_increment_increment is set to 7'2017-04-24T06:23:09.982637Z 3 [Note] Plugin group_replication reported: 'auto_increment_offset is set to 1'2017-04-24T06:23:09.982841Z 0 [Note] Plugin group_replication reported: 'state 4257 action xa_init'2017-04-24T06:23:09.982957Z 0 [Note] Plugin group_replication reported: 'Successfully bound to 0.0.0.0:33061 (socket=80).'2017-04-24T06:23:09.983104Z 0 [Note] Plugin group_replication reported: 'Successfully set listen backlog to 32 (socket=80)!'2017-04-24T06:23:09.983149Z 0 [Note] Plugin group_replication reported: 'Successfully unblocked socket (socket=80)!'2017-04-24T06:23:09.983232Z 0 [Note] Plugin group_replication reported: 'Ready to accept incoming connections on 0.0.0.0:33061 (socket=80)!'2017-04-24T06:23:09.983302Z 0 [Note] Plugin group_replication reported: 'connecting to 172.17.84.71 33061'2017-04-24T06:23:09.983432Z 0 [Note] Plugin group_replication reported: 'client connected to 172.17.84.71 33061 fd 83'2017-04-24T06:23:09.983524Z 0 [Warning] Plugin group_replication reported: '[GCS] Connection attempt from IP address 172.17.84.71 refused. Address is not in the IP whitelist.'2017-04-24T06:23:09.983620Z 0 [ERROR] Plugin group_replication reported: '[GCS] Error connecting to the local group communication engine instance.'2017-04-24T06:23:09.983647Z 0 [Note] Plugin group_replication reported: 'state 4257 action xa_exit'2017-04-24T06:23:09.983926Z 0 [Note] Plugin group_replication reported: 'Exiting xcom thread'2017-04-24T06:23:11.014814Z 0 [ERROR] Plugin group_replication reported: '[GCS] The member was unable to join the group. Local port: 33061'2017-04-24T06:24:09.991677Z 3 [ERROR] Plugin group_replication reported: 'Timeout on wait for view after joining group'2017-04-24T06:24:09.991847Z 3 [Note] Plugin group_replication reported: 'Requesting to leave the group despite of not being a member'2017-04-24T06:24:09.991903Z 3 [ERROR] Plugin group_replication reported: '[GCS] The member is leaving a group without being on one.'2017-04-24T06:24:09.992323Z 3 [Note] Plugin group_replication reported: 'auto_increment_increment is reset to 1'2017-04-24T06:24:09.992354Z 3 [Note] Plugin group_replication reported: 'auto_increment_offset is reset to 1'2017-04-24T06:24:09.992922Z 15 [Note] Error reading relay log event for channel 'group_replication_applier': slave SQL thread was killed2017-04-24T06:24:09.993527Z 12 [Note] Plugin group_replication reported: 'The group replication applier thread was killed' 解决办法基于网段或者IP 指定白名单，可以在线动态修改 12set global group_replication_ip_whitelist = '172.17.84.71,172.17.84.72,172.17.84.73';set global group_replication_ip_whitelist = '172.17.84.71/24'; 或者添加到my.cnf中 1loose-group_replication_ip_whitelist='172.17.84.71,172.17.84.72,172.17.84.73' 错误二 无法解析主机名导致member状态一直未recoving错误信息通过SELECT * FROM performance_schema.replication_group_members;查询，发现MEMBER_STATE一直是recoving 1234567891011121314151617181920212017-04-24T07:01:19.864784Z 0 [Note] Plugin group_replication reported: 'Starting group replication recovery with view_id 14930159987057432:2'2017-04-24T07:01:19.865335Z 19 [Note] Plugin group_replication reported: 'Establishing group recovery connection with a possible donor. Attempt 1/10'2017-04-24T07:01:19.871742Z 19 [Note] 'CHANGE MASTER TO FOR CHANNEL 'group_replication_recovery' executed'. Previous state master_host='', master_port= 3306, master_log_file='', master_log_pos= 4, master_bind=''. New state master_host='mysql001', master_port= 3306, master_log_file='', master_log_pos= 4, master_bind=''.2017-04-24T07:01:19.881203Z 19 [Note] Plugin group_replication reported: 'Establishing connection to a group replication recovery donor 60b61f19-289f-11e7-b97d-08002730b4d8 at mysql001 port: 3306.'2017-04-24T07:01:19.881586Z 21 [Warning] Storing MySQL user name or password information in the master info repository is not secure and is therefore not recommended. Please consider using the USER and PASSWORD connection options for START SLAVE; see the 'START SLAVE Syntax' in the MySQL Manual for more information.2017-04-24T07:01:19.882339Z 22 [Note] Slave SQL thread for channel 'group_replication_recovery' initialized, starting replication in log 'FIRST' at position 0, relay log './mysql002-relay-bin-group_replication_recovery.000001' position: 42017-04-24T07:01:19.883547Z 21 [ERROR] Slave I/O for channel 'group_replication_recovery': error connecting to master 'rpl_user@mysql001:3306' - retry-time: 60 retries: 1, Error_code: 20052017-04-24T07:01:19.883573Z 21 [Note] Slave I/O thread for channel 'group_replication_recovery' killed while connecting to master2017-04-24T07:01:19.883582Z 21 [Note] Slave I/O thread exiting for channel 'group_replication_recovery', read up to log 'FIRST', position 42017-04-24T07:01:19.883861Z 19 [ERROR] Plugin group_replication reported: 'There was an error when connecting to the donor server. Check group replication recovery's connection credentials.'2017-04-24T07:01:19.884138Z 19 [Note] Plugin group_replication reported: 'Retrying group recovery connection with another donor. Attempt 2/10'2017-04-24T07:01:55.338092Z 0 [Note] Plugin group_replication reported: 'getstart group_id 4317e324'2017-04-24T07:01:57.362663Z 0 [Note] Plugin group_replication reported: 'Marking group replication view change with view_id 14930159987057432:3'2017-04-24T07:01:57.422909Z 0 [Note] Plugin group_replication reported: 'The member with address mysql003:3306 was declared online within the replication group'2017-04-24T07:02:19.884808Z 19 [Note] 'CHANGE MASTER TO FOR CHANNEL 'group_replication_recovery' executed'. Previous state master_host='mysql001', master_port= 3306, master_log_file='', master_log_pos= 4, master_bind=''. New state master_host='mysql003', master_port= 3306, master_log_file='', master_log_pos= 4, master_bind=''.2017-04-24T07:02:19.890519Z 19 [Note] Plugin group_replication reported: 'Establishing connection to a group replication recovery donor 164b8061-28ba-11e7-9a51-080027dad0d6 at mysql003 port: 3306.'2017-04-24T07:02:19.891514Z 26 [Warning] Storing MySQL user name or password information in the master info repository is not secure and is therefore not recommended. Please consider using the USER and PASSWORD connection options for START SLAVE; see the 'START SLAVE Syntax' in the MySQL Manual for more information.2017-04-24T07:02:19.893156Z 26 [ERROR] Slave I/O for channel 'group_replication_recovery': error connecting to master 'rpl_user@mysql003:3306' - retry-time: 60 retries: 1, Error_code: 20052017-04-24T07:02:19.893186Z 26 [Note] Slave I/O thread for channel 'group_replication_recovery' killed while connecting to master2017-04-24T07:02:19.893194Z 26 [Note] Slave I/O thread exiting for channel 'group_replication_recovery', read up to log 'FIRST', position 42017-04-24T0 解决办法方法一 配置hosts 123172.17.84.71 mysql001172.17.84.72 msyql002172.17.84.73 mysql003 方法二 或者在配置文件my.cnf使用report_host=ip，显示指定使用IP，而非默认的主机名 错误三：mysql初始化，修改root密码，没有禁用日志，导致各节点Executed_Gtid_Set不同错误信息修改密码操作必须设置binlog不记录，执行后再打开，否则会引起START GROUP_REPLICATION执行报错: 12[ERROR] Plugin group_replication reported: 'The member contains transactions not present in the group. The member will now exit the group.'[Note] Plugin group_replication reported: 'To force this member into the group you can use the group_replication_allow_local_disjoint_gtids_join option' 解决办法方法一： 1234567891011121314151617181920mysql&gt; SET SQL_LOG_BIN=0;Query OK, 0 rows affected (0.00 sec)mysql&gt; set password=password('admin_123');Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec)mysql&gt; SET SQL_LOG_BIN=1;Query OK, 0 rows affected (0.00 sec)mysql&gt; show master status \G;*************************** 1. row *************************** File: mysql-bin.000002 Position: 150 Binlog_Do_DB: Binlog_Ignore_DB:Executed_Gtid_Set:1 row in set (0.00 sec) 方法二1set global group_replication_allow_local_disjoint_gtids_join=ON; 方法三 如果是全新的实例，可以通过reset master清空Executed_Gtid_Set 123456789mysql&gt;reset mastermysql&gt; show master status \G;*************************** 1. row *************************** File: mysql-bin.000010 Position: 1486 Binlog_Do_DB: Binlog_Ignore_DB:Executed_Gtid_Set: aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa:1-101 row in set (0.00 sec)]]></content>
      <categories>
        <category>MySQL</category>
        <category>Group Replication</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Deploying Group Replication in Single-Primary Mode]]></title>
    <url>%2F2017%2F05%2F06%2FMySQL%2FGroup%20Replication%2FDeploying%20Group%20Replication%20in%20Single-Primary%20Mode%2F</url>
    <content type="text"><![CDATA[本文描述了3实例MySQL Group Replication的搭建过程 一、环境信息 ip地址 主机名 server_id 172.17.84.71 mysql001 1 172.17.84.72 mysql002 2 172.17.84.73 mysql003 3 二、搭建前准备 关闭selinux(略) 开启端口3306 33061 12345678910111213##Addfirewall-cmd --permanent --zone=public --add-port=3306/tcpfirewall-cmd --permanent --zone=public --add-port=33061/tcp##Reloadfirewall-cmd --reload ## 检查是否生效firewall-cmd --zone=public --query-port=3306/tcpfirewall-cmd --zone=public --query-port=33061/tcp ## 列出所有的开放端口firewall-cmd --list-all 配置/etc/hosts ip和主机名对应关系 1234[root@mysql003 ~]# cat /etc/hosts172.17.84.71 mysql001172.17.84.72 msyql002172.17.84.73 mysql003 三、初始化三个数据库实例3.1 初始化3个mysql实例mysql001配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657[root@mysql001 ~]# cat /usr/local/mysql/etc/my.cnf[client]port = 3306socket = /usr/local/mysql/run/mysql.sock[mysqld]port = 3306socket = /usr/local/mysql/run/mysql.sockpid_file = /usr/local/mysql/run/mysql.piddatadir = /usr/local/mysql/datadefault_storage_engine = InnoDBmax_allowed_packet = 512Mmax_connections = 2048open_files_limit = 65535lower_case_table_names=1character-set-server = utf8mb4collation-server = utf8mb4_unicode_ciinit_connect='SET NAMES utf8mb4'innodb_buffer_pool_size = 1024Minnodb_log_file_size = 2048Minnodb_file_per_table = 1innodb_flush_log_at_trx_commit = 0key_buffer_size = 64Mlog-error = /usr/local/mysql/log/mysql_error.loglog-bin = /usr/local/mysql/binlogs/mysql-binslow_query_log = 1slow_query_log_file = /usr/local/mysql/log/mysql_slow_query.loglong_query_time = 5tmp_table_size = 32Mmax_heap_table_size = 32Mquery_cache_type = 0query_cache_size = 0server-id=1gtid_mode = ONenforce_gtid_consistency = ONbinlog_checksum=NONElog_slave_updates = ONmaster_info_repository = TABLErelay_log_info_repository = TABLEtransaction_write_set_extraction=XXHASH64loose-group_replication_group_name="aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa"loose-group_replication_start_on_boot=offloose-group_replication_local_address= "172.17.84.71:33061"loose-group_replication_group_seeds= "172.17.84.71:33061,172.17.84.72:33061,172.17.84.73:33061"loose-group_replication_bootstrap_group= offloose-group_replication_ip_whitelist='172.17.84.71,172.17.84.72,172.17.84.73' 参数说明见Group Replication System Variables 初始化实例 并启动 12mysqld --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/datasystemctl start mysqld 到错误日志文件中找到临时密码进行登录，登录后修改临时密码12[root@mysql001 /]# grep 'temporary password' /usr/local/mysql/log/mysql_error.log2017-04-24T03:37:44.558511Z 1 [Note] A temporary password is generated for root@localhost: 3yFK,#qtjAl; 修改root密码1234567891011121314151617181920212223mysql&gt; SET SQL_LOG_BIN=0;Query OK, 0 rows affected (0.00 sec)mysql&gt; set password=password('admin_123');Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec)mysql&gt; SET SQL_LOG_BIN=1;Query OK, 0 rows affected (0.00 sec)mysql&gt; show master status \G;*************************** 1. row *************************** File: mysql-bin.000002 Position: 150 Binlog_Do_DB: Binlog_Ignore_DB:Executed_Gtid_Set:1 row in set (0.00 sec)ERROR:No query specified 修改密码操作必须设置binlog不记录，执行后再打开，否则会引起START GROUP_REPLICATION执行报错。全新的环境可以通过reset master解决这个问题。12[ERROR] Plugin group_replication reported: 'The member contains transactions not present in the group. The member will now exit the group.'[Note] Plugin group_replication reported: 'To force this member into the group you can use the group_replication_allow_local_disjoint_gtids_join option' 四、配置MGR4.1 创建复制账号1234567891011121314mysql&gt; SET SQL_LOG_BIN=0;Query OK, 0 rows affected (0.00 sec)mysql&gt; CREATE USER rpl_user@'%';Query OK, 0 rows affected (0.01 sec)mysql&gt; GRANT REPLICATION SLAVE ON *.* TO rpl_user@'%' IDENTIFIED BY 'rpl_pass';Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; FLUSH PRIVILEGES;Query OK, 0 rows affected (0.00 sec)mysql&gt; SET SQL_LOG_BIN=1;Query OK, 0 rows affected (0.00 sec) 4.2 使用change master命令配置server在下次需要从其他成员恢复其状态时，使用group_replication_recovery复制通道的给定凭据12mysql&gt; CHANGE MASTER TO MASTER_USER='rpl_user', MASTER_PASSWORD='rpl_pass' FOR CHANNEL 'group_replication_recovery';Query OK, 0 rows affected, 2 warnings (0.02 sec) 4.3 安装复制组插件12mysql&gt; install plugin group_replication soname 'group_replication.so';Query OK, 0 rows affected (0.26 sec) 4.4 查看插件是否安装成功1234567891011mysql&gt; show plugins;+----------------------------+----------+--------------------+----------------------+---------+| Name | Status | Type | Library | License |+----------------------------+----------+--------------------+----------------------+---------+| binlog | ACTIVE | STORAGE ENGINE | NULL | GPL || mysql_native_password | ACTIVE | AUTHENTICATION | NULL | GPL |...| group_replication | ACTIVE | GROUP REPLICATION | group_replication.so | GPL |+----------------------------+----------+--------------------+----------------------+---------+ 4.5、配置引导组，并启动GROUP_REPLICATION此引导应仅有单个server独立完成，该server启动组并且只启动一次123456#### 设置group_replication_bootstrap_group 只需要在mysql001上执行一次，另外两个实例不执行这句mysql&gt; SET GLOBAL group_replication_bootstrap_group=ON; Query OK, 0 rows affected (0.00 sec)mysql&gt; START GROUP_REPLICATION;ERROR 3092 (HY000): The server is not configured properly to be an active member of the group. Please see more details on error log. 查看log，发现是白名单问题导致的，my.cnf添加白名单后重新启动组复制12345678mysql&gt; set global group_replication_ip_whitelist = '172.17.84.71,172.17.84.72,172.17.84.73';Query OK, 0 rows affected (0.00 sec)mysql&gt; START GROUP_REPLICATION;Query OK, 0 rows affected (1.02 sec)mysql&gt; SET GLOBAL group_replication_bootstrap_group=OFF;Query OK, 0 rows affected (0.00 sec) 直接添加白名单到my.cnf,防止下次启动再重新问题 1loose-group_replication_ip_whitelist='172.17.84.71,172.17.84.72,172.17.84.73' 4.6 查看状态12345678910111213141516mysql&gt; SELECT * FROM performance_schema.replication_group_members;+---------------------------+--------------------------------------+-------------+-------------+--------------+| CHANNEL_NAME | MEMBER_ID | MEMBER_HOST | MEMBER_PORT | MEMBER_STATE |+---------------------------+--------------------------------------+-------------+-------------+--------------+| group_replication_applier | 60b61f19-289f-11e7-b97d-08002730b4d8 | mysql001 | 3306 | ONLINE |+---------------------------+--------------------------------------+-------------+-------------+--------------+1 row in set (0.01 sec)mysql&gt; show master status \G;*************************** 1. row *************************** File: mysql-bin.000003 Position: 434 Binlog_Do_DB: Binlog_Ignore_DB:Executed_Gtid_Set: aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa:11 row in set (0.00 sec) 4.7 向组中添加实例mysql002 mysql003mysql002 mysql003的操作和mysql001相同，除了不需要SET GLOBAL group_replication_bootstrap_group=ON; 12mysql&gt; START GROUP_REPLICATION;Query OK, 0 rows affected (1.02 sec) 查看最终状态123456789mysql&gt; SELECT * FROM performance_schema.replication_group_members;+---------------------------+--------------------------------------+-------------+-------------+--------------+| CHANNEL_NAME | MEMBER_ID | MEMBER_HOST | MEMBER_PORT | MEMBER_STATE |+---------------------------+--------------------------------------+-------------+-------------+--------------+| group_replication_applier | 80af8598-1520-11e7-a8b9-08002730b4d8 | mysql001 | 3306 | ONLINE || group_replication_applier | 8abf4eab-1521-11e7-9cc9-080027b95fc4 | mysql002 | 3306 | ONLINE || group_replication_applier | dcd3068d-15bc-11e7-b264-080027dad0d6 | mysql003 | 3306 | ONLINE |+---------------------------+--------------------------------------+-------------+-------------+--------------+3 rows in set (0.00 sec) 4.8 修改 group_replication_start_on_boot=on1loose-group_replication_start_on_boot=on 参考 Deploying Group Replication in Single-Primary Mode http://www.niugebbs.com/HRT152/1244148.html http://blog.csdn.net/dbaxiaosa/article/details/70226540 MySQL Group Replication多机多实例安装配置 MySQL Group Replication 9节点快速部署]]></content>
      <categories>
        <category>MySQL</category>
        <category>Group Replication</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[多节点3实例搭建InnoDB Cluster环境]]></title>
    <url>%2F2017%2F05%2F05%2FMySQL%2FMySQL%20HA%2FInnoDB%20Cluster%2FInnoDB%20Cluster%20%E5%A4%9A%E6%9C%BA3%E5%AE%9E%E4%BE%8B%E8%8A%82%E7%82%B9%E6%90%AD%E5%BB%BA%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[本文描述了如何通过单机三个msyql实例，创建一个Single-Primary Innodb cluster，并通过mysql Router对connections实现路由，实现高可用性。 ip地址 主机名 server_id 192.168.0.101 mysql001 1 192.168.0.102 mysql002 2 192.168.0.103 mysql003 3 192.168.0.104 mysql-router 主要步骤如图所示 1. 安装3个mysql实例注意：修改root密码时候设置SQL_LOG_BIN=0;此步骤主要是避免Executed_Gtid_Set不一致 1234567891011121314mysql&gt; SET SQL_LOG_BIN=0;Query OK, 0 rows affected (0.00 sec)mysql&gt; set password=password('admin_123');Query OK, 0 rows affected, 1 warning (0.01 sec)mysql&gt; GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'admin_123' WITH GRANT OPTION;Query OK, 0 rows affected, 1 warning (0.01 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.01 sec)mysql&gt; SET SQL_LOG_BIN=1;Query OK, 0 rows affected (0.00 sec) 一句话执行 1mysql -uroot -padmin_123 -e "SET SQL_LOG_BIN=0;GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'admin_123' WITH GRANT OPTION; flush privileges; SET SQL_LOG_BIN=1" 2. Yum 安装MySQL Shell123wget https://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpmrpm -ivh mysql57-community-release-el7-10.noarch.rpmyum install mysql-shell -y 3. Configuring the Instance检查并配置3个数据库实例 123mysql-js&gt; \connect root@localhost:3306mysql-js&gt; dba.checkInstanceConfiguration('root@localhost:3306')mysql-js&gt; dba.configureLocalInstance('root@localhost:3306') 详细过程如下所示 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127mysql-js&gt; dba.checkInstanceConfiguration('root@localhost:3306')Please provide the password for 'root@localhost:3306': Validating instance...The instance 'localhost:3306' is not valid for Cluster usage.The following issues were encountered: - Some configuration options need to be fixed.+----------------------------------+---------------+----------------+--------------------------------------------------+| Variable | Current Value | Required Value | Note |+----------------------------------+---------------+----------------+--------------------------------------------------+| binlog_checksum | CRC32 | NONE | Update the server variable or restart the server || enforce_gtid_consistency | OFF | ON | Restart the server || gtid_mode | OFF | ON | Restart the server || log_slave_updates | 0 | ON | Restart the server || master_info_repository | FILE | TABLE | Restart the server || relay_log_info_repository | FILE | TABLE | Restart the server || transaction_write_set_extraction | OFF | XXHASH64 | Restart the server |+----------------------------------+---------------+----------------+--------------------------------------------------+Please fix these issues , restart the serverand try again.&#123; "config_errors": [ &#123; "action": "server_update", "current": "CRC32", "option": "binlog_checksum", "required": "NONE" &#125;, &#123; "action": "restart", "current": "OFF", "option": "enforce_gtid_consistency", "required": "ON" &#125;, &#123; "action": "restart", "current": "OFF", "option": "gtid_mode", "required": "ON" &#125;, &#123; "action": "restart", "current": "0", "option": "log_slave_updates", "required": "ON" &#125;, &#123; "action": "restart", "current": "FILE", "option": "master_info_repository", "required": "TABLE" &#125;, &#123; "action": "restart", "current": "FILE", "option": "relay_log_info_repository", "required": "TABLE" &#125;, &#123; "action": "restart", "current": "OFF", "option": "transaction_write_set_extraction", "required": "XXHASH64" &#125; ], "errors": [], "restart_required": true, "status": "error"&#125;mysql-js&gt; dba.configureLocalInstance('root@localhost:3306')Please provide the password for 'root@localhost:3306': Detecting the configuration file...Default file not found at the standard locations.Please specify the path to the MySQL configuration file: /usr/local/mysql/mysql_3306/etc/my.cnfValidating instance...The configuration has been updated but it is required to restart the server.&#123; "config_errors": [ &#123; "action": "restart", "current": "OFF", "option": "enforce_gtid_consistency", "required": "ON" &#125;, &#123; "action": "restart", "current": "OFF", "option": "gtid_mode", "required": "ON" &#125;, &#123; "action": "restart", "current": "0", "option": "log_slave_updates", "required": "ON" &#125;, &#123; "action": "restart", "current": "FILE", "option": "master_info_repository", "required": "TABLE" &#125;, &#123; "action": "restart", "current": "FILE", "option": "relay_log_info_repository", "required": "TABLE" &#125;, &#123; "action": "restart", "current": "OFF", "option": "transaction_write_set_extraction", "required": "XXHASH64" &#125; ], "errors": [], "restart_required": true, "status": "error"&#125; 重启3个数据库实例 1shell&gt; systemctl restart mysqld 重新检查3个实例，确保结果ok 12345678mysql-js&gt; dba.checkInstanceConfiguration('root@localhost:3306')Please provide the password for 'root@localhost:3306': Validating instance...The instance 'localhost:3306' is valid for Cluster usage&#123; "status": "ok"&#125; 4. 创建 InnoDB ClusterConnect MySQL Shell to the seed instance, in this case the one at port 3306: 123mysql-js&gt; \connect root@192.168.0.101:3306或者mysql-js&gt; shell.connect('root@192.168.0.101:3306') Use the createCluster() method to create the InnoDB cluster with the currently connected instance as the seed: 1mysql-js&gt; var cluster = dba.createCluster('testCluster') 5.添加 Instances 至 InnoDB Cluster配置/etc/hosts 123192.168.0.101 mysql001192.168.0.102 mysql002192.168.0.103 mysql003 Obtaining the cluster Instance Variable 12mysql-js&gt; \connect root@192.168.0.101:3306mysql-js&gt; var cluster = dba.getCluster("testCluster") Add the second instance to the InnoDB cluster: 1mysql-js&gt; cluster.addInstance('root@192.168.0.102:3306') Add the third instance: 1mysql-js&gt; cluster.addInstance('root@192.168.0.103:3306') 查看cluster 状态 123456789101112131415161718192021222324252627282930313233mysql-js&gt; cluster.status()&#123; "clusterName": "devCluster", "defaultReplicaSet": &#123; "name": "default", "primary": "192.168.0.101:3306", "status": "OK", "statusText": "Cluster is ONLINE and can tolerate up to ONE failure.", "topology": &#123; "192.168.0.101:3306": &#123; "address": "192.168.0.101:3306", "mode": "R/W", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125;, "192.168.0.102:3306": &#123; "address": "192.168.0.102:3306", "mode": "R/O", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125;, "192.168.0.103:3306": &#123; "address": "192.168.0.103:3306", "mode": "R/O", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125; &#125; &#125;&#125; 6. 持久化配置文件已经在cluster中的实例，第二次运行dba.configureLocalInstance(‘root@localhost:3306’)，会将配置cluster的配置持久化到my.cnf 必须使用localhost连接后在每个实例单独执行 123456mysql-js&gt; \connect root@localhost:3306mysql-js&gt; dba.configureLocalInstance('root@localhost:3306')mysql-js&gt; \connect root@localhost:3306mysql-js&gt; dba.configureLocalInstance('root@localhost:3306')mysql-js&gt; \connect root@localhost:3306mysql-js&gt; dba.configureLocalInstance('root@localhost:3306') 7. 安装配置 MySQL RouterYum安装 123wget https://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpmrpm -ivh mysql57-community-release-el7-10.noarch.rpmyum install mysql-router -y bootstrap 生成配置文件 1shell&gt; mysqlrouter --bootstrap root@192.168.0.103:3306 --user=mysqlrouter 配置文件/etc/mysqlrouter/mysqlrouter.conf内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445shell &gt; cat /etc/mysqlrouter/mysqlrouter.conf# File automatically generated during MySQL Router bootstrap[DEFAULT]name=systemuser=mysqlrouterkeyring_path=/var/lib/mysqlrouter/keyringmaster_key_path=/etc/mysqlrouter/mysqlrouter.key[logger]level = INFO[metadata_cache:devCluster]router_id=1bootstrap_server_addresses=mysql://192.168.0.101:3306,mysql://192.168.0.102:3306,mysql://192.168.0.103:3306user=mysql_router1_m55oiq8bjdrymetadata_cluster=devClusterttl=300[routing:devCluster_default_rw]bind_address=0.0.0.0bind_port=6446destinations=metadata-cache://devCluster/default?role=PRIMARYmode=read-writeprotocol=classic[routing:devCluster_default_ro]bind_address=0.0.0.0bind_port=6447destinations=metadata-cache://devCluster/default?role=SECONDARYmode=read-onlyprotocol=classic[routing:devCluster_default_x_rw]bind_address=0.0.0.0bind_port=64460destinations=metadata-cache://devCluster/default?role=PRIMARYmode=read-writeprotocol=x[routing:devCluster_default_x_ro]bind_address=0.0.0.0bind_port=64470destinations=metadata-cache://devCluster/default?role=SECONDARYmode=read-onlyprotocol=x 启动mysqlrouter(记得修改下权限 默认权限不对) 12chown mysqlrouter.mysqlrouter /var/lib/mysqlroutersystemctl start mysqlrouter 测试连接 12345678910shell&gt; mysqlsh --uri root@localhost:6446mysql-js&gt; \sqlSwitching to SQL mode... Commands end with ;mysql-sql&gt; select @@port;+--------+| @@port |+--------+| 3306 |+--------+1 row in set (0.00 sec) 8. Testing Failoverkilling the PRIMARY instance 192.168.0.101:3306 1systemctl stop mysqld@3301 测试连接（第一次失败，第二次成功） 1234567891011121314mysql-js&gt; \sqlSwitching to SQL mode... Commands end with ;mysql-sql&gt; SELECT @@port;ERROR: 2013 (HY000): Lost connection to MySQL server during queryThe global session got disconnected.Attempting to reconnect to 'root@localhost:6446'...The global session was successfully reconnected.mysql-sql&gt; select @@port;+--------+| @@port |+--------+| 3306 |+--------+1 row in set (0.00 sec) 查看cluster状态, 可以发现192.168.0.102:3306已经变成Primary 123456789101112131415161718192021222324252627282930313233mysql-js&gt; cluster.status()&#123; "clusterName": "devCluster", "defaultReplicaSet": &#123; "name": "default", "primary": "192.168.0.102:3306", "status": "OK_NO_TOLERANCE", "statusText": "Cluster is NOT tolerant to any failures. 1 member is not active", "topology": &#123; "192.168.0.101:3306": &#123; "address": "192.168.0.101:3306", "mode": "R/O", "readReplicas": &#123;&#125;, "role": "HA", "status": "(MISSING)" &#125;, "192.168.0.102:3306": &#123; "address": "192.168.0.102:3306", "mode": "R/W", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125;, "192.168.0.103:3306": &#123; "address": "192.168.0.103:3306", "mode": "R/O", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125; &#125; &#125;&#125; bring the instance that you killed back online. 123systemctl start mysqldmysql-js&gt; cluster.rejoinInstance('root@192.168.0.101:3306')mysql-js&gt; cluster.status() 重新查看cluster状态 123456789101112131415161718192021222324252627282930313233mysql-js&gt; cluster.status()&#123; "clusterName": "devCluster", "defaultReplicaSet": &#123; "name": "default", "primary": "192.168.0.102:3306", "status": "OK", "statusText": "Cluster is ONLINE and can tolerate up to ONE failure.", "topology": &#123; "192.168.0.101:3306": &#123; "address": "192.168.0.103:3306", "mode": "R/O", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125;, "192.168.0.102:3306": &#123; "address": "192.168.0.103:3306", "mode": "R/W", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125;, "192.168.0.103:3306": &#123; "address": "192.168.0.103:3306", "mode": "R/O", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125; &#125; &#125;&#125; 参考 Working with a Production Deployment MySQL InnoDB Cluster – Real-World Cluster Tutorial for OEL, Fedora, RHEL and CentOS]]></content>
      <categories>
        <category>MySQL</category>
        <category>MySQL HA</category>
        <category>InnoDB Cluster</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>InnoDB Cluster</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单机3实例搭建InnoDB Cluster环境]]></title>
    <url>%2F2017%2F05%2F04%2FMySQL%2FMySQL%20HA%2FInnoDB%20Cluster%2F%E5%8D%95%E6%9C%BA3%E5%AE%9E%E4%BE%8B%E6%90%AD%E5%BB%BAInnoDB%20Cluster%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[本文描述了如何通过单机三个msyql实例，创建一个Single-Primary Innodb cluster，并通过mysql Router对connections实现路由，实现高可用性。 This section explains how to set up a single-primary InnoDB cluster and configure MySQL Router to achieve high availability. This tutorial shows how to use MySQL Shell to create an InnoDB cluster consisting of a MySQL Server instance which provides the seed instance of the InnoDB cluster and holds the initial data set. Two more MySQL server instances are created and added to the InnoDB cluster. Then MySQL Router is deployed and used to route connections to the InnoDB cluster, and high availability is tested. 1. 安装3个mysql实例注意：修改root密码时候设置SQL_LOG_BIN=0; 1234567891011121314mysql&gt; SET SQL_LOG_BIN=0;Query OK, 0 rows affected (0.00 sec)mysql&gt; set password=password('admin_123');Query OK, 0 rows affected, 1 warning (0.01 sec)mysql&gt; GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'admin_123' WITH GRANT OPTION;Query OK, 0 rows affected, 1 warning (0.01 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.01 sec)mysql&gt; SET SQL_LOG_BIN=1;Query OK, 0 rows affected (0.00 sec) 2. Yum 安装MySQL Shell123wget https://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpmrpm -ivh mysql57-community-release-el7-10.noarch.rpmyum install mysql-shell -y 3. Configuring the Instance检查并配置3个数据库实例 123mysql-js&gt; \connect root@localhost:3301mysql-js&gt; dba.checkInstanceConfiguration('root@localhost:3301')mysql-js&gt; dba.configureLocalInstance('root@localhost:3301') 详细过程如下所示 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127mysql-js&gt; dba.checkInstanceConfiguration('root@localhost:3301')Please provide the password for 'root@localhost:3301': Validating instance...The instance 'localhost:3301' is not valid for Cluster usage.The following issues were encountered: - Some configuration options need to be fixed.+----------------------------------+---------------+----------------+--------------------------------------------------+| Variable | Current Value | Required Value | Note |+----------------------------------+---------------+----------------+--------------------------------------------------+| binlog_checksum | CRC32 | NONE | Update the server variable or restart the server || enforce_gtid_consistency | OFF | ON | Restart the server || gtid_mode | OFF | ON | Restart the server || log_slave_updates | 0 | ON | Restart the server || master_info_repository | FILE | TABLE | Restart the server || relay_log_info_repository | FILE | TABLE | Restart the server || transaction_write_set_extraction | OFF | XXHASH64 | Restart the server |+----------------------------------+---------------+----------------+--------------------------------------------------+Please fix these issues , restart the serverand try again.&#123; "config_errors": [ &#123; "action": "server_update", "current": "CRC32", "option": "binlog_checksum", "required": "NONE" &#125;, &#123; "action": "restart", "current": "OFF", "option": "enforce_gtid_consistency", "required": "ON" &#125;, &#123; "action": "restart", "current": "OFF", "option": "gtid_mode", "required": "ON" &#125;, &#123; "action": "restart", "current": "0", "option": "log_slave_updates", "required": "ON" &#125;, &#123; "action": "restart", "current": "FILE", "option": "master_info_repository", "required": "TABLE" &#125;, &#123; "action": "restart", "current": "FILE", "option": "relay_log_info_repository", "required": "TABLE" &#125;, &#123; "action": "restart", "current": "OFF", "option": "transaction_write_set_extraction", "required": "XXHASH64" &#125; ], "errors": [], "restart_required": true, "status": "error"&#125;mysql-js&gt; dba.configureLocalInstance('root@localhost:3301')Please provide the password for 'root@localhost:3301': Detecting the configuration file...Default file not found at the standard locations.Please specify the path to the MySQL configuration file: /usr/local/mysql/mysql_3301/etc/my.cnfValidating instance...The configuration has been updated but it is required to restart the server.&#123; "config_errors": [ &#123; "action": "restart", "current": "OFF", "option": "enforce_gtid_consistency", "required": "ON" &#125;, &#123; "action": "restart", "current": "OFF", "option": "gtid_mode", "required": "ON" &#125;, &#123; "action": "restart", "current": "0", "option": "log_slave_updates", "required": "ON" &#125;, &#123; "action": "restart", "current": "FILE", "option": "master_info_repository", "required": "TABLE" &#125;, &#123; "action": "restart", "current": "FILE", "option": "relay_log_info_repository", "required": "TABLE" &#125;, &#123; "action": "restart", "current": "OFF", "option": "transaction_write_set_extraction", "required": "XXHASH64" &#125; ], "errors": [], "restart_required": true, "status": "error"&#125; 重启3个数据库实例 123shell&gt; systemctl restart mysqld@3301shell&gt; systemctl restart mysqld@3302shell&gt; systemctl restart mysqld@3303 重新检查3个实例，确保结果ok 12345678mysql-js&gt; dba.checkInstanceConfiguration('root@localhost:3301')Please provide the password for 'root@localhost:3301': Validating instance...The instance 'localhost:3301' is valid for Cluster usage&#123; "status": "ok"&#125; 4. Creating the InnoDB ClusterConnect MySQL Shell to the seed instance, in this case the one at port 3301: 123mysql-js&gt; \connect root@192.168.0.103:3301或者mysql-js&gt; shell.connect('root@192.168.0.103:3301') Use the createCluster() method to create the InnoDB cluster with the currently connected instance as the seed: 1mysql-js&gt; var cluster = dba.createCluster('testCluster') 5. Adding Instances to an InnoDB Cluster配置/etc/hosts 1127.0.0.1 mysql001 Obtaining the cluster Instance Variable 12mysql-js&gt; \connect root@192.168.0.103:3301mysql-js&gt; var cluster = dba.getCluster("testCluster") Add the second instance to the InnoDB cluster: 1mysql-js&gt; cluster.addInstance('root@192.168.0.103:3302') Add the third instance: 1mysql-js&gt; cluster.addInstance('root@192.168.0.103:3303') 查看cluster 状态 123456789101112131415161718192021222324252627282930313233mysql-js&gt; cluster.status()&#123; "clusterName": "devCluster", "defaultReplicaSet": &#123; "name": "default", "primary": "192.168.0.103:3301", "status": "OK", "statusText": "Cluster is ONLINE and can tolerate up to ONE failure.", "topology": &#123; "192.168.0.103:3301": &#123; "address": "192.168.0.103:3301", "mode": "R/W", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125;, "192.168.0.103:3302": &#123; "address": "192.168.0.103:3302", "mode": "R/O", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125;, "192.168.0.103:3303": &#123; "address": "192.168.0.103:3303", "mode": "R/O", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125; &#125; &#125;&#125; 6. 持久化配置文件已经在cluster中的实例，第二次运行dba.configureLocalInstance(‘root@localhost:3301’)，会将配置cluster的配置持久化到my.cnf 必须使用localhost连接后在每个实例单独执行 123456mysql-js&gt; \connect root@localhost:3301mysql-js&gt; dba.configureLocalInstance('root@localhost:3301')mysql-js&gt; \connect root@localhost:3302mysql-js&gt; dba.configureLocalInstance('root@localhost:3302')mysql-js&gt; \connect root@localhost:3303mysql-js&gt; dba.configureLocalInstance('root@localhost:3303') 7. 安装配置 MySQL RouterYum安装 123wget https://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpmrpm -ivh mysql57-community-release-el7-10.noarch.rpmyum install mysql-router -y bootstrap 生成配置文件 1shell&gt; mysqlrouter --bootstrap root@localhost:3301 --user=mysqlrouter 配置文件/etc/mysqlrouter/mysqlrouter.conf内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445shell &gt; cat /etc/mysqlrouter/mysqlrouter.conf# File automatically generated during MySQL Router bootstrap[DEFAULT]name=systemuser=mysqlrouterkeyring_path=/var/lib/mysqlrouter/keyringmaster_key_path=/etc/mysqlrouter/mysqlrouter.key[logger]level = INFO[metadata_cache:devCluster]router_id=1bootstrap_server_addresses=mysql://192.168.0.103:3301,mysql://192.168.0.103:3302,mysql://192.168.0.103:3303user=mysql_router1_m55oiq8bjdrymetadata_cluster=devClusterttl=300[routing:devCluster_default_rw]bind_address=0.0.0.0bind_port=6446destinations=metadata-cache://devCluster/default?role=PRIMARYmode=read-writeprotocol=classic[routing:devCluster_default_ro]bind_address=0.0.0.0bind_port=6447destinations=metadata-cache://devCluster/default?role=SECONDARYmode=read-onlyprotocol=classic[routing:devCluster_default_x_rw]bind_address=0.0.0.0bind_port=64460destinations=metadata-cache://devCluster/default?role=PRIMARYmode=read-writeprotocol=x[routing:devCluster_default_x_ro]bind_address=0.0.0.0bind_port=64470destinations=metadata-cache://devCluster/default?role=SECONDARYmode=read-onlyprotocol=x 启动mysqlrouter(记得修改下权限 默认权限不对) 12chown mysqlrouter.mysqlrouter /var/lib/mysqlroutersystemctl start mysqlrouter 测试连接 12345678910shell&gt; mysqlsh --uri root@localhost:6446mysql-js&gt; \sqlSwitching to SQL mode... Commands end with ;mysql-sql&gt; select @@port;+--------+| @@port |+--------+| 3301 |+--------+1 row in set (0.00 sec) 8. Testing Failoverkilling the PRIMARY instance 3301 1systemctl stop mysqld@3301 测试连接（第一次失败，第二次成功） 1234567891011121314mysql-js&gt; \sqlSwitching to SQL mode... Commands end with ;mysql-sql&gt; SELECT @@port;ERROR: 2013 (HY000): Lost connection to MySQL server during queryThe global session got disconnected.Attempting to reconnect to 'root@localhost:6446'...The global session was successfully reconnected.mysql-sql&gt; select @@port;+--------+| @@port |+--------+| 3302 |+--------+1 row in set (0.00 sec) 查看cluster状态, 可以发现3302实例已经变成Primary 123456789101112131415161718192021222324252627282930313233mysql-js&gt; cluster.status()&#123; "clusterName": "devCluster", "defaultReplicaSet": &#123; "name": "default", "primary": "192.168.0.103:3302", "status": "OK_NO_TOLERANCE", "statusText": "Cluster is NOT tolerant to any failures. 1 member is not active", "topology": &#123; "192.168.0.103:3301": &#123; "address": "192.168.0.103:3301", "mode": "R/O", "readReplicas": &#123;&#125;, "role": "HA", "status": "(MISSING)" &#125;, "192.168.0.103:3302": &#123; "address": "192.168.0.103:3302", "mode": "R/W", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125;, "192.168.0.103:3303": &#123; "address": "192.168.0.103:3303", "mode": "R/O", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125; &#125; &#125;&#125; bring the instance that you killed back online. 123systemctl start mysqld@3301mysql-js&gt; cluster.rejoinInstance('root@192.168.0.103:3301')mysql-js&gt; cluster.status() 重新查看cluster状态 123456789101112131415161718192021222324252627282930313233mysql-js&gt; cluster.status()&#123; "clusterName": "devCluster", "defaultReplicaSet": &#123; "name": "default", "primary": "192.168.0.103:3302", "status": "OK", "statusText": "Cluster is ONLINE and can tolerate up to ONE failure.", "topology": &#123; "192.168.0.103:3301": &#123; "address": "192.168.0.103:3301", "mode": "R/O", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125;, "192.168.0.103:3302": &#123; "address": "192.168.0.103:3302", "mode": "R/W", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125;, "192.168.0.103:3303": &#123; "address": "192.168.0.103:3303", "mode": "R/O", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125; &#125; &#125;&#125; 参考 Working with a Production Deployment]]></content>
      <categories>
        <category>MySQL</category>
        <category>MySQL HA</category>
        <category>InnoDB Cluster</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>InnoDB Cluster</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[沙盒实例搭建InnoDB Cluster环境]]></title>
    <url>%2F2017%2F05%2F03%2FMySQL%2FMySQL%20HA%2FInnoDB%20Cluster%2F3%E6%B2%99%E7%9B%92%E5%AE%9E%E4%BE%8B%E6%90%AD%E5%BB%BAInnoDB%20Cluster%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[本文描述了如何通过三个沙盒msyql实例，创建一个Single-Primary Innodb cluster，并通过mysql Router对connections实现路由，实现高可用性。 This section explains how to set up a single-primary InnoDB cluster and configure MySQL Router to achieve high availability. This tutorial shows how to use MySQL Shell to create an InnoDB cluster consisting of a MySQL Server instance which provides the seed instance of the InnoDB cluster and holds the initial data set. Two more sandbox MySQL server instances are created and added to the InnoDB cluster. Then MySQL Router is deployed and used to route connections to the InnoDB cluster, and high availability is tested. 1. Yum 安装MySQL Shell123wget https://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpmrpm -ivh mysql57-community-release-el7-10.noarch.rpmyum install mysql-shell -y 2. 创建三个沙盒实例Start MySQL Shell 1shell&gt; mysqlsh MySQL Shell provides two scripting languages: JavaScript and Python. Throughout this guide MySQL Shell is used primarily in JavaScript mode . When MySQL Shell starts it is in JavaScript mode by default. You switch into JavaScript mode, Python mode and SQL mode using the commands \js, \py, and \sql. Ensure you are in JavaScript mode by issuing the \js command, then execute: 123mysql-js&gt; dba.deploySandboxInstance(3310)mysql-js&gt; dba.deploySandboxInstance(3320)mysql-js&gt; dba.deploySandboxInstance(3330) 3. Creating the InnoDB ClusterConnect MySQL Shell to the seed instance, in this case the one at port 3310: 123mysql-js&gt; \connect root@localhost:3310或者mysql-js&gt; shell.connect('root@localhost:3310') Use the createCluster() method to create the InnoDB cluster with the currently connected instance as the seed: 1mysql-js&gt; var cluster = dba.createCluster('testCluster') 4. Adding Instances to an InnoDB Cluster配置/etc/hosts 1127.0.0.1 mysql001 Obtaining the cluster Instance Variable 1mysql-js&gt; var cluster = dba.getCluster("testCluster") Add the second instance to the InnoDB cluster: 1mysql-js&gt; cluster.addInstance('root@localhost:3320') Add the third instance: 1mysql-js&gt; cluster.addInstance('root@localhost:3330') 查看cluster 状态 123456789101112131415161718192021222324252627282930313233mysql-js&gt; cluster.status()&#123; "clusterName": "testCluster", "defaultReplicaSet": &#123; "name": "default", "primary": "localhost:3310", "status": "OK", "statusText": "Cluster is ONLINE and can tolerate up to ONE failure.", "topology": &#123; "localhost:3310": &#123; "address": "localhost:3310", "mode": "R/W", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125;, "localhost:3320": &#123; "address": "localhost:3320", "mode": "R/O", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125;, "localhost:3330": &#123; "address": "localhost:3330", "mode": "R/O", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125; &#125; &#125;&#125; 5. 安装配置 MySQL RouterYum安装 123wget https://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpmrpm -ivh mysql57-community-release-el7-10.noarch.rpmyum install mysql-router -y bootstrap 生成配置文件 1shell&gt; mysqlrouter --bootstrap root@localhost:3310 --user=mysqlrouter 配置文件/etc/mysqlrouter/mysqlrouter.conf内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445shell &gt; cat /etc/mysqlrouter/mysqlrouter.conf# File automatically generated during MySQL Router bootstrap[DEFAULT]name=systemuser=mysqlrouterkeyring_path=/var/lib/mysqlrouter/keyringmaster_key_path=/etc/mysqlrouter/mysqlrouter.key[logger]level = INFO[metadata_cache:testCluster]router_id=3bootstrap_server_addresses=mysql://localhost:3310,mysql://localhost:3320,mysql://localhost:3330user=mysql_router3_c3j5z9t7rjgkmetadata_cluster=testClusterttl=300[routing:testCluster_default_rw]bind_address=0.0.0.0bind_port=6446destinations=metadata-cache://testCluster/default?role=PRIMARYmode=read-writeprotocol=classic[routing:testCluster_default_ro]bind_address=0.0.0.0bind_port=6447destinations=metadata-cache://testCluster/default?role=SECONDARYmode=read-onlyprotocol=classic[routing:testCluster_default_x_rw]bind_address=0.0.0.0bind_port=64460destinations=metadata-cache://testCluster/default?role=PRIMARYmode=read-writeprotocol=x[routing:testCluster_default_x_ro]bind_address=0.0.0.0bind_port=64470destinations=metadata-cache://testCluster/default?role=SECONDARYmode=read-onlyprotocol=x 启动mysqlrouter(记得修改下权限 默认权限不对) 12chown mysqlrouter.mysqlrouter /var/lib/mysqlroutersystemctl start mysqlrouter 测试连接 12345678910shell&gt; mysqlsh --uri root@localhost:6446mysql-js&gt; \sqlSwitching to SQL mode... Commands end with ;mysql-sql&gt; select @@port;+--------+| @@port |+--------+| 3310 |+--------+1 row in set (0.00 sec) 6. Testing Failoverkilling the PRIMARY instance 3310 1mysql-js&gt; dba.killSandboxInstance(3310) 测试连接（第一次失败，第二次成功） 1234567891011121314mysql-js&gt; \sqlSwitching to SQL mode... Commands end with ;mysql-sql&gt; SELECT @@port;ERROR: 2013 (HY000): Lost connection to MySQL server during queryThe global session got disconnected.Attempting to reconnect to 'root@localhost:6446'...The global session was successfully reconnected.mysql-sql&gt; select @@port;+--------+| @@port |+--------+| 3330 |+--------+1 row in set (0.00 sec) 查看cluster状态, 可以发现3320实例已经变成Primary 123456789101112131415161718192021222324252627282930313233mysql-js&gt; cluster.status()&#123; "clusterName": "testCluster", "defaultReplicaSet": &#123; "name": "default", "primary": "localhost:3320", "status": "OK_NO_TOLERANCE", "statusText": "Cluster is NOT tolerant to any failures. 1 member is not active", "topology": &#123; "localhost:3310": &#123; "address": "localhost:3310", "mode": "R/O", "readReplicas": &#123;&#125;, "role": "HA", "status": "(MISSING)" &#125;, "localhost:3320": &#123; "address": "localhost:3320", "mode": "R/W", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125;, "localhost:3330": &#123; "address": "localhost:3330", "mode": "R/O", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125; &#125; &#125;&#125; bring the instance that you killed back online. 123mysql-js&gt; dba.startSandboxInstance(3310)mysql-js&gt; cluster.rejoinInstance('root@localhost:3310')mysql-js&gt; cluster.status() 重新查看cluster状态 123456789101112131415161718192021222324252627282930313233mysql-js&gt; cluster.status()&#123; "clusterName": "testCluster", "defaultReplicaSet": &#123; "name": "default", "primary": "localhost:3320", "status": "OK", "statusText": "Cluster is ONLINE and can tolerate up to ONE failure.", "topology": &#123; "localhost:3310": &#123; "address": "localhost:3310", "mode": "R/O", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125;, "localhost:3320": &#123; "address": "localhost:3320", "mode": "R/W", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125;, "localhost:3330": &#123; "address": "localhost:3330", "mode": "R/O", "readReplicas": &#123;&#125;, "role": "HA", "status": "ONLINE" &#125; &#125; &#125;&#125; 参考 Getting Started with InnoDB Cluster]]></content>
      <categories>
        <category>MySQL</category>
        <category>MySQL HA</category>
        <category>InnoDB Cluster</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>InnoDB Cluster</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[InnoDB Cluster简介]]></title>
    <url>%2F2017%2F05%2F02%2FMySQL%2FMySQL%20HA%2FInnoDB%20Cluster%2FInnoDB%20Cluster%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[一、InnoDB Cluster简介前几天 Mysql 团队愉快的发布了 InnoDB Cluster 的 GA（General Availability 正式发布） 版本 InnoDB Cluster 是 Mysql 的一套完整的高可用解决方案 MySQL InnoDB cluster is a collection of products that work together to provide a complete High Availability solution for MySQL. InnoDB Cluster 由下面3个核心组件构成： MySQL Shell 通过内置的 AdminAPI 来创建和管理整个 InnoDB Clusters Includes the AdminAPI, which enables you to script the creation and administration of an InnoDB cluster, using either JavaScript or Python. MySQL Router 缓存 InnoDB cluster 的元数据，负责把 client 的 read/write 请求路由到当前的主数据库节点，还可以对 client 的请求进行负载均衡，并且在主数据库节点出现故障时，保证 client 的请求被路由到新的主服务器节点 Caches the metadata of the InnoDB cluster and routes read/write client requests to the current primary. If the primary instance becomes unavailable, MySQL Router automatically routes client requests to a promoted secondary (the new primary). Group Replication MySQL Server 5.7.17 or higher. 可以把数据同步到集群内的所有成员中，并支持 容错 、 自动故障转移 、 灵活扩展 等重要特性 This provides the MySQL Group Replication mechanism to allow data to be replicated within the cluster, with built-in failover. Group Replication ​]]></content>
      <categories>
        <category>MySQL</category>
        <category>MySQL HA</category>
        <category>InnoDB Cluster</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>InnoDB Cluster</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F05%2F01%2Fhello-world%2F</url>
    <content type="text"><![CDATA[今天是五一劳动节，我的新Blog诞生了。希望在新的一年里，能在此认认真真的记录自己的成长！ 目标：每天一篇学习笔记]]></content>
  </entry>
</search>